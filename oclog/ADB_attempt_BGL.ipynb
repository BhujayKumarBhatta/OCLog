{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54262e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bglog import BGLog, get_embedding_layer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f8246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bglog = BGLog(save_padded_num_sequences=False, load_from_pkl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d3b282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_num_seq_df loaded from data\\bgl_padded_num_seq_df.pkl\n",
      "trained tokenizer, tk, loaded from data\\bgltk.pkl\n",
      "train_0:, 800\n",
      "test_0:, 200\n",
      "train_1:, 800\n",
      "test_1:, 200\n",
      "train_2:, 800\n",
      "test_2:, 200\n",
      "train_3:, 800\n",
      "test_3:, 102\n",
      "4 class does not have 800 records, it has only 628 records\n",
      "test_4:, 0\n",
      "5 class does not have 800 records, it has only 165 records\n",
      "5 class does not have 200 records, it has only 165 records\n",
      "6 class does not have 800 records, it has only 75 records\n",
      "6 class does not have 200 records, it has only 75 records\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "<BatchDataset shapes: ((32, 32, 64), (32, 4)), types: (tf.int32, tf.float32)>\n",
      "<BatchDataset shapes: ((32, 32, 64), (32, 4)), types: (tf.int32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "train_test = bglog.get_tensor_train_test(ablation=1000)\n",
    "train_data, test_data = train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5e095cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(conv1d_set1 = 3, conv1d_set2 = 3, dense_neurons=2048, filters=64,\n",
    "            kernel_size=3,maxpool_1=True,epochs=25, dense_activation='relu'):\n",
    "    embedding_weights, vocab_size, char_onehot = get_embedding_layer(bglog)\n",
    "    B = train_data.element_spec[0].shape[0]\n",
    "#     inputs = tf.keras.layers.Input(batch_shape=(B, train_data.element_spec[0].shape[1], train_data.element_spec[0].shape[2]), dtype='float64' )\n",
    "    inputs = tf.keras.layers.Input(shape=(train_data.element_spec[0].shape[1], train_data.element_spec[0].shape[2]), dtype='float64' )\n",
    "    x = tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
    "                                    output_dim=vocab_size,\n",
    "                                    input_length=train_data.element_spec[0].shape[2],\n",
    "                                    weights = [embedding_weights],\n",
    "                                    )(inputs)\n",
    "    for _ in range(conv1d_set1):\n",
    "        x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "    if maxpool_1:\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(1, train_data.element_spec[0].shape[2]))(x)\n",
    "        x = tf.reshape(x, (B, train_data.element_spec[0].shape[1], filters))        \n",
    "        for _ in range(conv1d_set2):\n",
    "            x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "        x = tf.keras.layers.MaxPooling1D(pool_size=(train_data.element_spec[0].shape[1]) )(x)\n",
    "        x = tf.reshape(x, (B, filters))\n",
    "    if not maxpool_1:\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "    if dense_activation is None:\n",
    "        x = tf.keras.layers.Dense(dense_neurons)(x)\n",
    "    else:\n",
    "        x = tf.keras.layers.Dense(dense_neurons, activation=dense_activation)(x)\n",
    "    outputs = tf.keras.layers.Dense(train_data.element_spec[1].shape[1], activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    print(model.summary())\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    hist = model.fit(train_data, validation_data=test_data, epochs=epochs) \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5669eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we  feed  xi  to  a dense layer h to get the log-sequence representation zi∈RD:\n",
    "#     zi= h(xi) =σ(Whxi+bh) ............................(2)\n",
    "# in our case zi can be obtained from the dense layer before the softmax\n",
    "# Lets see how to ger it from the train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05519f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 32, 64)]          0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 32, 64, 50)        2550      \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 32, 64, 64)        9664      \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 32, 64, 64)        12352     \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 32, 64, 64)        12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 32, 1, 64)         0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(32, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (32, 1, 64)               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (Tenso [(32, 64)]                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (32, 2048)                133120    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (32, 4)                   8196      \n",
      "=================================================================\n",
      "Total params: 215,290\n",
      "Trainable params: 215,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 0.3127 - accuracy: 0.8500 - precision: 0.8920 - recall: 0.8078 - val_loss: 0.0138 - val_accuracy: 0.9881 - val_precision: 0.9881 - val_recall: 0.9881\n",
      "Epoch 2/6\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.0563 - accuracy: 0.9797 - precision: 0.9800 - recall: 0.9794 - val_loss: 0.0087 - val_accuracy: 0.9970 - val_precision: 0.9985 - val_recall: 0.9955\n",
      "Epoch 3/6\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0469 - accuracy: 0.9834 - precision: 0.9841 - recall: 0.9834 - val_loss: 0.0092 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 4/6\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0149 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.0090 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 5/6\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.0121 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.0070 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9985\n",
      "Epoch 6/6\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.0058 - accuracy: 0.9978 - precision: 0.9978 - recall: 0.9975 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# we pre-train the model with labeled known intent samples. \n",
    "# In order to better reflect the effectiveness of the learned decision boundary, \n",
    "# we learn the feature representation zi with the simple softmax loss Ls to perform classification:\n",
    "\n",
    "trained_model, hist = model(epochs=6,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc5979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the decision boundary of each class constraining the known labels within a ball area\n",
    "# how to get zi and how to know that zi belongs to which yi ?\n",
    "# from there we will have to calculate the Ck , centroid for the class k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eba74b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x1b2cb5147c0>,\n",
       " <tensorflow.python.keras.layers.embeddings.Embedding at 0x1b2d74eb850>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1b2cb50bb20>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1b2d74ebfa0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1b2d74dacd0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1b2d74b9460>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1b2b10bc790>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1b2d74ee160>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1b2b10bc400>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1b2b10c2e80>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling1D at 0x1b2b10c7580>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1b2b10dcd00>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1b2b10d7c10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1b2b10dcfa0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f027a3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001B2B10D7C10>\n"
     ]
    }
   ],
   "source": [
    "dense_6 = trained_model.get_layer('dense_6')\n",
    "print(dense_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5bef3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_6/Relu:0' shape=(32, 2048) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the log sequence embedding from the last layer\n",
    "# we can treat this as the features from the logs\n",
    "dense_6.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we use the pre-trained model to extract intent features for \n",
    "# learning the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d937f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_x_train.shape: (32, 32, 64)\n",
      "vocab_size: 50\n",
      "loglineEmbedding.shape: (32, 32, 64)\n",
      "Model: \"log_line_encoder_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_46 (Embedding)     multiple                  2550      \n",
      "_________________________________________________________________\n",
      "conv1d_183 (Conv1D)          multiple                  9664      \n",
      "_________________________________________________________________\n",
      "conv1d_184 (Conv1D)          multiple                  12352     \n",
      "_________________________________________________________________\n",
      "conv1d_185 (Conv1D)          multiple                  12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling multiple                  0         \n",
      "=================================================================\n",
      "Total params: 36,918\n",
      "Trainable params: 36,918\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class LogLineEncoder(tf.keras.Model):\n",
    "    def __init__(self, num_of_conv1d=3,  \n",
    "                 filters=64,\n",
    "                 kernel_size=3, ):\n",
    "        super().__init__()            \n",
    "        self.num_of_conv1d = num_of_conv1d       \n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size           \n",
    "        self.embedding_weights, self.vocab_size, self.char_onehot = get_embedding_layer(bglog)       \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size+1,\n",
    "                                    output_dim=self.vocab_size,\n",
    "                                    input_length=train_data.element_spec[0].shape[2],\n",
    "                                    weights = [self.embedding_weights],\n",
    "                                    )\n",
    "        self.conv1d_layers = [tf.keras.layers.Conv1D(filters=filters, \n",
    "                                                kernel_size=kernel_size, \n",
    "                                                padding='same')  \n",
    "                       for _ in range(self.num_of_conv1d)]\n",
    "        self.maxpool2d = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size=(1, train_data.element_spec[0].shape[2]))\n",
    "                  \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        for conv1d_layer in self.conv1d_layers:\n",
    "            x = conv1d_layer(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = tf.reshape(x, (inputs.shape[0], inputs.shape[1], self.filters))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "# \n",
    "line_encoder =   LogLineEncoder()\n",
    "# the model doesn't have a state unless it is called at least once\n",
    "# in order to initialize the model we need a sample data \n",
    "sample_train_data = next(iter(train_data))\n",
    "sample_x_train = sample_train_data[0]\n",
    "print('sample_x_train.shape:', sample_x_train.shape)\n",
    "# now we will initialize the model with the sample data\n",
    "loglineEmbedding = line_encoder(sample_x_train)\n",
    "print('loglineEmbedding.shape:', loglineEmbedding.shape)\n",
    "# Now the model have a state and can be inspected        \n",
    "line_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e166638e",
   "metadata": {},
   "source": [
    "LOG SEQUENCE EMBEDDING TAKES LOGLINE EMBEDDING AS INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "29d31023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logSeqEmbedding.shape: (32, 2048)\n",
      "Model: \"log_seq_encoder_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_180 (Conv1D)          multiple                  12352     \n",
      "_________________________________________________________________\n",
      "conv1d_181 (Conv1D)          multiple                  12352     \n",
      "_________________________________________________________________\n",
      "conv1d_182 (Conv1D)          multiple                  12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             multiple                  133120    \n",
      "=================================================================\n",
      "Total params: 170,176\n",
      "Trainable params: 170,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class LogSeqEncoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, num_of_conv1d=3,  filters=64,\n",
    "                 kernel_size=3, maxpool_1=True,\n",
    "                 dense_neurons=2048, dense_activation='relu',):\n",
    "        super().__init__()\n",
    "        self.num_of_conv1d = num_of_conv1d\n",
    "        self.dense_neurons = dense_neurons\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.maxpool_1 = maxpool_1\n",
    "        self.dense_activation = dense_activation\n",
    "        self.conv1d_layers = [tf.keras.layers.Conv1D(filters=filters, \n",
    "                                                kernel_size=kernel_size, \n",
    "                                                padding='same')  \n",
    "                       for _ in range(self.num_of_conv1d)]\n",
    "        self.maxpool1d = tf.keras.layers.MaxPooling1D(pool_size=(train_data.element_spec[0].shape[1]) )\n",
    "        \n",
    "        self.Dense = tf.keras.layers.Dense(self.dense_neurons, \n",
    "                                           activation=self.dense_activation)\n",
    "       \n",
    "        \n",
    "    def call(self, inputs):       \n",
    "        for conv1d_layer in self.conv1d_layers:\n",
    "            x = conv1d_layer(inputs)\n",
    "        x = self.maxpool1d(x)        \n",
    "        x = tf.reshape(x, (inputs.shape[0], self.filters))\n",
    "        x = self.Dense(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "logSeqencer =   LogSeqEncoder()\n",
    "# the model doesn't have a state unless it is called at least once\n",
    "logSeqEmbedding = logSeqencer(loglineEmbedding)\n",
    "print('logSeqEmbedding.shape:', logSeqEmbedding.shape)\n",
    "# Now the model have a state and can be inspected        \n",
    "logSeqencer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "562ac55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a4dd91b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       "array([[0.26594797, 0.23993689, 0.24374838, 0.25036687],\n",
       "       [0.2712713 , 0.23759408, 0.2424112 , 0.24872339],\n",
       "       [0.27049428, 0.23759227, 0.24442764, 0.24748583],\n",
       "       [0.26594797, 0.23993689, 0.24374838, 0.25036687],\n",
       "       [0.27129176, 0.23026243, 0.24704917, 0.25139663],\n",
       "       [0.27271685, 0.23522092, 0.24514192, 0.24692021],\n",
       "       [0.27256274, 0.23706135, 0.24357268, 0.24680322],\n",
       "       [0.2712713 , 0.23759408, 0.2424112 , 0.24872339],\n",
       "       [0.26936093, 0.23150212, 0.24697001, 0.25216702],\n",
       "       [0.27184606, 0.23702982, 0.24413759, 0.24698654],\n",
       "       [0.26934317, 0.2346282 , 0.24737462, 0.248654  ],\n",
       "       [0.2686097 , 0.23688017, 0.24340446, 0.25110564],\n",
       "       [0.26978517, 0.2378512 , 0.24382828, 0.2485354 ],\n",
       "       [0.26897094, 0.23215264, 0.24991204, 0.24896437],\n",
       "       [0.2728863 , 0.2351903 , 0.24460365, 0.24731976],\n",
       "       [0.27251709, 0.23248255, 0.24827993, 0.24672048],\n",
       "       [0.26945013, 0.23541771, 0.24713929, 0.2479928 ],\n",
       "       [0.27156782, 0.23094447, 0.24816792, 0.24931978],\n",
       "       [0.2735885 , 0.23656389, 0.24441738, 0.24543022],\n",
       "       [0.27043197, 0.23289219, 0.24693178, 0.24974398],\n",
       "       [0.27262342, 0.23621152, 0.2441452 , 0.24701993],\n",
       "       [0.27251476, 0.2364617 , 0.24388961, 0.24713391],\n",
       "       [0.2712713 , 0.23759408, 0.2424112 , 0.24872339],\n",
       "       [0.27215236, 0.23788574, 0.24366543, 0.24629645],\n",
       "       [0.27146935, 0.23707247, 0.24331203, 0.24814616],\n",
       "       [0.27138266, 0.23612553, 0.24511904, 0.24737282],\n",
       "       [0.27366155, 0.23602948, 0.24329741, 0.24701156],\n",
       "       [0.27126446, 0.23632407, 0.24513923, 0.24727228],\n",
       "       [0.26939192, 0.2330428 , 0.24880996, 0.24875537],\n",
       "       [0.2682201 , 0.23473606, 0.24810523, 0.24893856],\n",
       "       [0.270568  , 0.23732649, 0.2452414 , 0.2468641 ],\n",
       "       [0.27357668, 0.23624067, 0.24413969, 0.24604294]], dtype=float32)>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LogClassifier(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,  **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.log_line_encoder = LogLineEncoder()\n",
    "        self.log_seq_encoder = LogSeqEncoder()\n",
    "        self.classifier = tf.keras.layers.Dense(\n",
    "            train_data.element_spec[1].shape[1], activation='softmax')\n",
    "#         self.extract_feature = extract_feature\n",
    "    \n",
    "    def call(self, inputs, extract_feature=False,):\n",
    "#         x_data, y_data = inputs\n",
    "        x = self.log_line_encoder(inputs)\n",
    "        seq_embedding = self.log_seq_encoder(x)\n",
    "        \n",
    "        if  extract_feature:\n",
    "            output = seq_embedding\n",
    "        else:\n",
    "            output = self.classifier(seq_embedding)\n",
    "        return output\n",
    "    \n",
    "log_classifier = LogClassifier()\n",
    "log_classifier(sample_x_train)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classifier assigned low probability to all the classes since it is untrained\n",
    "# TODO: the mode should accept a single sequence. At present it is accepting only a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2fdde8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"log_classifier_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_line_encoder_58 (LogLine multiple                  36918     \n",
      "_________________________________________________________________\n",
      "log_seq_encoder_19 (LogSeqEn multiple                  170176    \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             multiple                  8196      \n",
      "=================================================================\n",
      "Total params: 215,290\n",
      "Trainable params: 215,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "log_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "21729a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier_10/log_seq_encoder_19/conv1d_249/kernel:0', 'log_classifier_10/log_seq_encoder_19/conv1d_249/bias:0', 'log_classifier_10/log_seq_encoder_19/conv1d_250/kernel:0', 'log_classifier_10/log_seq_encoder_19/conv1d_250/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier_10/log_seq_encoder_19/conv1d_249/kernel:0', 'log_classifier_10/log_seq_encoder_19/conv1d_249/bias:0', 'log_classifier_10/log_seq_encoder_19/conv1d_250/kernel:0', 'log_classifier_10/log_seq_encoder_19/conv1d_250/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier_10/log_seq_encoder_19/conv1d_249/kernel:0', 'log_classifier_10/log_seq_encoder_19/conv1d_249/bias:0', 'log_classifier_10/log_seq_encoder_19/conv1d_250/kernel:0', 'log_classifier_10/log_seq_encoder_19/conv1d_250/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier_10/log_seq_encoder_19/conv1d_249/kernel:0', 'log_classifier_10/log_seq_encoder_19/conv1d_249/bias:0', 'log_classifier_10/log_seq_encoder_19/conv1d_250/kernel:0', 'log_classifier_10/log_seq_encoder_19/conv1d_250/bias:0'] when minimizing the loss.\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2396 - accuracy: 0.9078 - precision_11: 0.9663 - recall_11: 0.8434 - val_loss: 0.0054 - val_accuracy: 0.9985 - val_precision_11: 0.9985 - val_recall_11: 0.9985\n"
     ]
    }
   ],
   "source": [
    "# This is to check that the model's built in  complile and fit is working well\n",
    "log_classifier.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "hist = log_classifier.fit(train_data, validation_data=test_data, epochs=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5fe2bc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       "array([[5.9559608e-07, 9.9999511e-01, 1.0115820e-06, 3.3967465e-06],\n",
       "       [3.3315580e-06, 5.3150663e-05, 9.9895394e-01, 9.8956109e-04],\n",
       "       [9.9981517e-01, 1.8341266e-04, 1.7208157e-07, 1.2867113e-06],\n",
       "       [5.9559608e-07, 9.9999511e-01, 1.0115820e-06, 3.3967465e-06],\n",
       "       [1.5486393e-08, 1.3062559e-06, 2.7559273e-02, 9.7243935e-01],\n",
       "       [9.9982077e-01, 1.7789275e-04, 1.7640629e-07, 1.2314774e-06],\n",
       "       [9.9979359e-01, 2.0472099e-04, 1.9793011e-07, 1.4540375e-06],\n",
       "       [3.3315580e-06, 5.3150663e-05, 9.9895394e-01, 9.8956109e-04],\n",
       "       [6.0969441e-10, 4.6309253e-08, 7.2057842e-04, 9.9927944e-01],\n",
       "       [1.0308991e-03, 9.9745423e-01, 5.1951088e-04, 9.9537824e-04],\n",
       "       [3.2217307e-09, 7.8519768e-08, 1.3213953e-03, 9.9867851e-01],\n",
       "       [7.8803737e-04, 9.9436545e-01, 8.2244060e-04, 4.0241582e-03],\n",
       "       [8.7072927e-08, 1.5266496e-05, 9.9929976e-01, 6.8481930e-04],\n",
       "       [1.0226398e-09, 7.3874865e-08, 1.5879484e-03, 9.9841201e-01],\n",
       "       [1.4527674e-07, 3.7460166e-05, 9.9977285e-01, 1.8955134e-04],\n",
       "       [2.1112394e-09, 6.1982895e-08, 1.5174688e-03, 9.9848253e-01],\n",
       "       [3.7411017e-08, 1.4170922e-05, 9.9946481e-01, 5.2108127e-04],\n",
       "       [2.0821217e-06, 2.7233726e-05, 2.3472268e-02, 9.7649843e-01],\n",
       "       [9.9981958e-01, 1.7912796e-04, 1.5886461e-07, 1.1477326e-06],\n",
       "       [3.0306959e-09, 1.2957015e-07, 1.1000527e-03, 9.9889982e-01],\n",
       "       [3.9084128e-04, 9.9957663e-01, 4.9010882e-06, 2.7671260e-05],\n",
       "       [4.5256867e-04, 9.9951184e-01, 4.7929452e-06, 3.0852952e-05],\n",
       "       [3.3315580e-06, 5.3150663e-05, 9.9895394e-01, 9.8956109e-04],\n",
       "       [9.9980181e-01, 1.9681791e-04, 1.7402154e-07, 1.2978818e-06],\n",
       "       [9.9981111e-01, 1.8741631e-04, 1.7965516e-07, 1.3055958e-06],\n",
       "       [3.9423435e-04, 9.9957556e-01, 4.1187191e-06, 2.6082596e-05],\n",
       "       [9.9978060e-01, 2.1776404e-04, 2.1740099e-07, 1.3712271e-06],\n",
       "       [9.9978739e-01, 2.1105632e-04, 1.8144901e-07, 1.3590312e-06],\n",
       "       [3.0535412e-09, 6.8817243e-08, 1.0520371e-03, 9.9894792e-01],\n",
       "       [3.1736672e-03, 9.9528593e-01, 3.5394571e-04, 1.1865272e-03],\n",
       "       [3.9066013e-04, 9.9957842e-01, 4.5177553e-06, 2.6476162e-05],\n",
       "       [3.6494154e-04, 9.9960667e-01, 4.1025901e-06, 2.4289420e-05]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now after the training the predeicitoin will show higher probability to the \n",
    "# a class and lesser probability to other classes\n",
    "log_classifier(sample_x_train)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fcf04020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 2048), dtype=float32, numpy=\n",
       "array([[0.        , 0.        , 0.4174264 , ..., 0.        , 0.        ,\n",
       "        0.2542565 ],\n",
       "       [0.01834698, 0.09165653, 0.        , ..., 0.        , 0.03006388,\n",
       "        0.        ],\n",
       "       [0.        , 0.13645807, 0.07725984, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.13265407, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.27734283, ..., 0.        , 0.        ,\n",
       "        0.02185998],\n",
       "       [0.        , 0.        , 0.28436154, ..., 0.        , 0.        ,\n",
       "        0.02117014]], dtype=float32)>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = log_classifier(sample_x_train, extract_feature=True ) \n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dc610efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d85d29cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centriods initialized: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "total_labels initialized: [0. 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,2048) (4,) (4,2048) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BHUJAY~1\\AppData\\Local\\Temp/ipykernel_15796/3628897716.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtotal_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumeric_label\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mcentroids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumeric_label\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mcentroids\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mtotal_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'centroids:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'total_labels:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,2048) (4,) (4,2048) "
     ]
    }
   ],
   "source": [
    "centroids = np.zeros((train_data.element_spec[1].shape[1],   2048))\n",
    "print('centriods initialized:', centriods)\n",
    "total_labels = np.zeros(4)\n",
    "# total_labels[2] += 1\n",
    "# total_labels[2] += 1\n",
    "print('total_labels initialized:', total_labels)\n",
    "for batch in train_data:\n",
    "    logseq_batch, label_batch = batch\n",
    "    features = log_classifier(logseq_batch, extract_feature=True )\n",
    "    for i in range(len(label_batch)):\n",
    "        label = label_batch[i]\n",
    "        numeric_label = np.argmax(label)\n",
    "        total_labels[numeric_label] += 1\n",
    "        centroids[numeric_label] += features[i]\n",
    "centroids /= total_labels\n",
    "print('centroids:',centroids)\n",
    "print('total_labels:',total_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251264cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df700d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing the training step to get centroid for each class\n",
    "class OpenSet:\n",
    "    def __init__(self, data, pretrained_model=log_classifier):\n",
    "#         super().__init__():\n",
    "        self.model = pretrained_model        \n",
    "        self.centroids = None\n",
    "        self.num_labels = train_data.element_spec[1].shape[1]\n",
    "        \n",
    "    def centroids_cal(self):\n",
    "        centriods = np.zeros(self.num_labels, embedding_size)\n",
    "        total_labels = np.empty(0, dtype=longdouble)\n",
    "        for batch in data:\n",
    "            logseq_batch, label_batch = batch\n",
    "            features = self.model(logseq_batch, extract_feature=True ) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d21510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e456e1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]\n",
      "\n",
      " [[ 7 17  8 ... 11 11 11]\n",
      "  [13  6 20 ... 11 11 11]\n",
      "  [13  6 20 ... 11 11 11]\n",
      "  ...\n",
      "  [ 7 17  8 ... 11 11 11]\n",
      "  [ 7 17  8 ... 11 11 11]\n",
      "  [ 7 17  8 ... 11 11 11]]\n",
      "\n",
      " [[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [11 25 17 ...  8  4 14]\n",
      "  [12  3  6 ... 12  6 18]\n",
      "  [ 4 11 25 ...  9  0  0]]\n",
      "\n",
      " [[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]\n",
      "\n",
      " [[ 2 19 11 ...  8 10  2]\n",
      "  [ 2 19 11 ...  8 10  2]\n",
      "  [ 2 19 11 ...  8 10  2]\n",
      "  ...\n",
      "  [ 2 19 11 ...  8 10  2]\n",
      "  [ 2 19 11 ...  8 10  2]\n",
      "  [ 2 19 11 ...  8 10  2]]], shape=(32, 32, 64), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]], shape=(32, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_data:\n",
    "    x_train, y_train = batch\n",
    "    print(x_train)\n",
    "    print(y_train)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9159a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f402bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf6a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_metric_torch(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    a = a.unsqueeze(1).expand(n, m, -1)\n",
    "    b = b.unsqueeze(0).expand(n, m, -1)\n",
    "    logits = -((a - b)**2).sum(dim=2)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9bc28247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [[0 1 2]\n",
      " [3 4 5]]\n",
      "a.shape (2, 3)\n",
      "b [ 8  9 10 11 12 13 14 15]\n",
      "b [[ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]]\n",
      "b.shape: (4, 2)\n",
      "tfa tf.Tensor(\n",
      "[[0 1 2]\n",
      " [3 4 5]], shape=(2, 3), dtype=int32)\n",
      "tfb tf.Tensor(\n",
      "[[ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]], shape=(4, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "a = np.arange(6)\n",
    "a = a.reshape((2, -1))\n",
    "print('a:', a)\n",
    "print('a.shape', a.shape)\n",
    "b = np.arange(8, 16)\n",
    "print('b',b)\n",
    "b = np.reshape(b, (4, -1))\n",
    "print('b',b)\n",
    "print('b.shape:',b.shape)\n",
    "tfa = tf.constant(a)\n",
    "tfb = tf.constant(b)\n",
    "print('tfa',tfa)\n",
    "print('tfb',tfb)\n",
    "# n = tfa.shape[0]\n",
    "# m = b.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5cf2b3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.expand_dims(tfa, 0) : tf.Tensor(\n",
      "[[[0 1 2]\n",
      "  [3 4 5]]], shape=(1, 2, 3), dtype=int32)\n",
      "\n",
      "tf.expand_dims(tfa, 1) : tf.Tensor(\n",
      "[[[0 1 2]]\n",
      "\n",
      " [[3 4 5]]], shape=(2, 1, 3), dtype=int32)\n",
      "\n",
      "tf.expand_dims(tfa, 1) : tf.Tensor(\n",
      "[[[0]\n",
      "  [1]\n",
      "  [2]]\n",
      "\n",
      " [[3]\n",
      "  [4]\n",
      "  [5]]], shape=(2, 3, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print('tf.expand_dims(tfa, 0) :',tf.expand_dims(tfa, 0))\n",
    "print()\n",
    "print('tf.expand_dims(tfa, 1) :',tf.expand_dims(tfa, 1))\n",
    "print()\n",
    "print('tf.expand_dims(tfa, 1) :',tf.expand_dims(tfa, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2ffcc9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.shape(tfa): [2 1 3]\n",
      "tf.shape(tfb): [1 4 2]\n"
     ]
    }
   ],
   "source": [
    "tfa = tf.expand_dims(tfa, 1)\n",
    "print(f'tf.shape(tfa): {tf.shape(tfa)}')\n",
    "tfb = tf.expand_dims(tfb, 0)\n",
    "print(f'tf.shape(tfb): {tf.shape(tfb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "629dff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfa_broadcast tf.Tensor(\n",
      "[[[0 1 2]\n",
      "  [0 1 2]\n",
      "  [0 1 2]\n",
      "  [0 1 2]]\n",
      "\n",
      " [[3 4 5]\n",
      "  [3 4 5]\n",
      "  [3 4 5]\n",
      "  [3 4 5]]], shape=(2, 4, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "n = a.shape[0]\n",
    "m = b.shape[0]\n",
    "tfa_broadcast = tf.broadcast_to(tfa, [2, 4, 3])\n",
    "tf.shape(tfa_broadcast)\n",
    "print('tfa_broadcast',tfa_broadcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24dc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "\n",
    "# The equivalent function for pytorch expand is tensorflow tf.broadcast_to\n",
    "\n",
    "# Docs: https://www.tensorflow.org/api_docs/python/tf/broadcast_to\n",
    "\n",
    "# Share\n",
    "# Follow\n",
    "# edited Oct 23, 2021 at 18:22\n",
    "\n",
    "# M.Innat\n",
    "# 12.2k66 gold badges3434 silver badges6767 bronze badges\n",
    "# answered Jan 4, 2019 at 9:12\n",
    "\n",
    "# funkyyyyyy\n",
    "# 6111 silver badge22 bronze badges\n",
    "# Add a comment\n",
    "\n",
    "# 0\n",
    "\n",
    "# Tensorflow automatically broadcasts, so in general you don't need to do any of this. Suppose you have a y' of shape 6x2x3 and your x is of shape 2x3, then you can already do y'*x or y'+x will already behave as if you had expanded it. But if for some other reason you really need to do it, then the command in tensorflow is tile:\n",
    "\n",
    "# y = tf.tile(tf.reshape(x, (1,2,3)), multiples=(6,1,1))\n",
    "# Docs: https://www.tensorflow.org/api_docs/python/tf/tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_metric(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    a = tf.expand_dims(a, 1)\n",
    "    b = tf.expand_dims(b, 0)\n",
    "    logits = -((a - b)**2).sum(dim=2)\n",
    "    return logits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "46d676e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenSet:\n",
    "    def __init__(self, data, pretrained_model):\n",
    "        \n",
    "        self.model = pretrained_model\n",
    "        self.best_eval_score = 0\n",
    "        self.delta = None\n",
    "        self.delta_points = []\n",
    "        self.centroids = None\n",
    "        self.test_results = None\n",
    "        self.predictions = None\n",
    "        self.true_labels = None\n",
    "        \n",
    "    def centroids_cal(self):\n",
    "        centriods = np.zeros(train_data.element_spec[1].shape[1], embedding_size)\n",
    "        total_labels = np.empty(0, dtype=longdouble)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ec585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c24b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b080ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d8cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54440bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In context of deep learning the logits layer means the layer that feeds in to softmax (or other such normalization). The output of the softmax are the probabilities for the classification task and its input is logits layer. The logits layer typically produces values from -infinity to +infinity and the softmax layer transforms it to values from 0 to 1.\n",
    "\n",
    "# Historical Context\n",
    "\n",
    "# Where does this term comes from? In 1930s and 40s, several people were trying to adapt linear regression to the problem of predicting probabilities. However linear regression produces output from -infinity to +infinity while for probabilities our desired output is 0 to 1. One way to do this is by somehow mapping the probabilities 0 to 1 to -infinity to +infinity and then use linear regression as usual. One such mapping is cumulative normal distribution that was used by Chester Ittner Bliss in 1934 and he called this \"probit\" model, short for \"probability unit\". However this function is computationally expensive while lacking some of the desirable properties for multi-class classification. In 1944 Joseph Berkson used the function log(p/(1-p)) to do this mapping and called it logit, short for \"logistic unit\". The term logistic regression derived from this as well.\n",
    "\n",
    "# The Confusion\n",
    "\n",
    "# Unfortunately the term logits is abused in deep learning. From pure mathematical perspective logit is a function that performs above mapping. In deep learning people started calling the layer \"logits layer\" that feeds in to logit function. Then people started calling the output values of this layer \"logit\" creating the confusion with logit the function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
