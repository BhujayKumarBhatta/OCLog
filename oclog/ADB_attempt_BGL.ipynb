{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49530c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bglog import BGLog, get_embedding_layer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b31481",
   "metadata": {},
   "outputs": [],
   "source": [
    "bglog = BGLog(save_padded_num_sequences=False, load_from_pkl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a500c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_num_seq_df loaded from data\\bgl_padded_num_seq_df.pkl\n",
      "trained tokenizer, tk, loaded from data\\bgltk.pkl\n",
      "train_0:, 800\n",
      "test_0:, 200\n",
      "train_1:, 800\n",
      "test_1:, 200\n",
      "train_2:, 800\n",
      "test_2:, 200\n",
      "train_3:, 800\n",
      "test_3:, 102\n",
      "4 class does not have 800 records, it has only 628 records\n",
      "test_4:, 0\n",
      "5 class does not have 800 records, it has only 165 records\n",
      "5 class does not have 200 records, it has only 165 records\n",
      "6 class does not have 800 records, it has only 75 records\n",
      "6 class does not have 200 records, it has only 75 records\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "<BatchDataset shapes: ((32, 32, 64), (32, 4)), types: (tf.int32, tf.float32)>\n",
      "<BatchDataset shapes: ((32, 32, 64), (32, 4)), types: (tf.int32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "train_test = bglog.get_tensor_train_test(ablation=1000)\n",
    "train_data, test_data = train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83e61c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(conv1d_set1 = 3, conv1d_set2 = 3, dense_neurons=2048, filters=64,\n",
    "            kernel_size=3,maxpool_1=True,epochs=25, dense_activation='relu'):\n",
    "    embedding_weights, vocab_size, char_onehot = get_embedding_layer(bglog)\n",
    "    B = train_data.element_spec[0].shape[0]\n",
    "#     inputs = tf.keras.layers.Input(batch_shape=(B, train_data.element_spec[0].shape[1], train_data.element_spec[0].shape[2]), dtype='float64' )\n",
    "    inputs = tf.keras.layers.Input(shape=(train_data.element_spec[0].shape[1], train_data.element_spec[0].shape[2]), dtype='float64' )\n",
    "    x = tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
    "                                    output_dim=vocab_size,\n",
    "                                    input_length=train_data.element_spec[0].shape[2],\n",
    "                                    weights = [embedding_weights],\n",
    "                                    )(inputs)\n",
    "    for _ in range(conv1d_set1):\n",
    "        x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "    if maxpool_1:\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(1, train_data.element_spec[0].shape[2]))(x)\n",
    "        x = tf.reshape(x, (B, train_data.element_spec[0].shape[1], filters))        \n",
    "        for _ in range(conv1d_set2):\n",
    "            x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "        x = tf.keras.layers.MaxPooling1D(pool_size=(train_data.element_spec[0].shape[1]) )(x)\n",
    "        x = tf.reshape(x, (B, filters))\n",
    "    if not maxpool_1:\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "    if dense_activation is None:\n",
    "        x = tf.keras.layers.Dense(dense_neurons)(x)\n",
    "    else:\n",
    "        x = tf.keras.layers.Dense(dense_neurons, activation=dense_activation)(x)\n",
    "    outputs = tf.keras.layers.Dense(train_data.element_spec[1].shape[1], activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    print(model.summary())\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    hist = model.fit(train_data, validation_data=test_data, epochs=epochs) \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9284dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we  feed  xi  to  a dense layer h to get the log-sequence representation zi∈RD:\n",
    "#     zi= h(xi) =σ(Whxi+bh) ............................(2)\n",
    "# in our case zi can be obtained from the dense layer before the softmax\n",
    "# Lets see how to ger it from the train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3682620f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 64)]          0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 32, 64, 50)        2550      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 32, 64, 64)        9664      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 32, 64, 64)        12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 32, 64, 64)        12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 1, 64)         0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(32, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (32, 1, 64)               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (Tenso [(32, 64)]                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 2048)                133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (32, 4)                   8196      \n",
      "=================================================================\n",
      "Total params: 215,290\n",
      "Trainable params: 215,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.3127 - accuracy: 0.8500 - precision: 0.8920 - recall: 0.8078 - val_loss: 0.0138 - val_accuracy: 0.9881 - val_precision: 0.9881 - val_recall: 0.9881\n",
      "Epoch 2/6\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.0563 - accuracy: 0.9797 - precision: 0.9800 - recall: 0.9794 - val_loss: 0.0087 - val_accuracy: 0.9970 - val_precision: 0.9985 - val_recall: 0.9955\n",
      "Epoch 3/6\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0469 - accuracy: 0.9834 - precision: 0.9841 - recall: 0.9834 - val_loss: 0.0092 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 4/6\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.0149 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.0090 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 5/6\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.0121 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.0070 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9985\n",
      "Epoch 6/6\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.0058 - accuracy: 0.9978 - precision: 0.9978 - recall: 0.9975 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# we pre-train the model with labeled known intent samples. \n",
    "# In order to better reflect the effectiveness of the learned decision boundary, \n",
    "# we learn the feature representation zi with the simple softmax loss Ls to perform classification:\n",
    "\n",
    "trained_model, hist = model(epochs=6,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "153baa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 64)]          0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 32, 64, 50)        2550      \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 32, 64, 64)        9664      \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 32, 64, 64)        12352     \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 32, 64, 64)        12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 1, 64)         0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (Tenso [(32, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (32, 1, 64)               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (Tenso [(32, 64)]                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (32, 64)                  4160      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (32, 4)                   260       \n",
      "=================================================================\n",
      "Total params: 78,394\n",
      "Trainable params: 78,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.2941 - accuracy: 0.8831 - precision_2: 0.9186 - recall_2: 0.8328 - val_loss: 0.0053 - val_accuracy: 0.9985 - val_precision_2: 0.9985 - val_recall_2: 0.9985\n",
      "Epoch 2/6\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.0407 - accuracy: 0.9869 - precision_2: 0.9872 - recall_2: 0.9862 - val_loss: 0.0019 - val_accuracy: 1.0000 - val_precision_2: 1.0000 - val_recall_2: 1.0000\n",
      "Epoch 3/6\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.0258 - accuracy: 0.9891 - precision_2: 0.9891 - recall_2: 0.9891 - val_loss: 0.0239 - val_accuracy: 0.9896 - val_precision_2: 0.9896 - val_recall_2: 0.9896\n",
      "Epoch 4/6\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 0.0250 - accuracy: 0.9906 - precision_2: 0.9906 - recall_2: 0.9903 - val_loss: 0.0022 - val_accuracy: 1.0000 - val_precision_2: 1.0000 - val_recall_2: 1.0000\n",
      "Epoch 5/6\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 0.0056 - accuracy: 0.9987 - precision_2: 0.9987 - recall_2: 0.9987 - val_loss: 0.0082 - val_accuracy: 0.9970 - val_precision_2: 0.9970 - val_recall_2: 0.9970\n",
      "Epoch 6/6\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0184 - accuracy: 0.9922 - precision_2: 0.9922 - recall_2: 0.9922 - val_loss: 0.0053 - val_accuracy: 1.0000 - val_precision_2: 1.0000 - val_recall_2: 1.0000\n"
     ]
    }
   ],
   "source": [
    "trained_model, hist = model(epochs=6, dense_neurons=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6afd5b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the decision boundary of each class constraining the known labels within a ball area\n",
    "# how to get zi and how to know that zi belongs to which yi ?\n",
    "# from there we will have to calculate the Ck , centroid for the class k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e6a1e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x1e1b9d7a9a0>,\n",
       " <tensorflow.python.keras.layers.embeddings.Embedding at 0x1e1b8238b20>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1e1b56258e0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1e1b56253d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1e1b696d520>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1e1b6973160>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1e1b86b6e20>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1e1b86a6790>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1e1b86b6d30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1e1bb679ee0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling1D at 0x1e1bb752ca0>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1e1bb7668b0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1e1bb756220>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1e1bb76a4c0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86bce152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001E1BB76A4C0>\n"
     ]
    }
   ],
   "source": [
    "dense_6 = trained_model.get_layer(index=(len(trained_model.layers)-1))\n",
    "print(dense_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff8fe762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/Softmax:0' shape=(32, 4) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the log sequence embedding from the last layer\n",
    "# we can treat this as the features from the logs\n",
    "dense_6.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1db4a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we use the pre-trained model to extract intent features for \n",
    "# learning the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4f6fc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n",
      "sample_x_train.shape: (32, 32, 64)\n",
      "loglineEmbedding.shape: (32, 32, 64)\n",
      "Model: \"log_line_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  2550      \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            multiple                  9664      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            multiple                  12352     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            multiple                  12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "=================================================================\n",
      "Total params: 36,918\n",
      "Trainable params: 36,918\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class LogLineEncoder(tf.keras.Model):\n",
    "    def __init__(self, num_of_conv1d=3,  \n",
    "                 filters=64,\n",
    "                 kernel_size=3, ):\n",
    "        super().__init__()            \n",
    "        self.num_of_conv1d = num_of_conv1d       \n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size           \n",
    "        self.embedding_weights, self.vocab_size, self.char_onehot = get_embedding_layer(bglog)       \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size+1,\n",
    "                                    output_dim=self.vocab_size,\n",
    "                                    input_length=train_data.element_spec[0].shape[2],\n",
    "                                    weights = [self.embedding_weights],\n",
    "                                    )\n",
    "        self.conv1d_layers = [tf.keras.layers.Conv1D(filters=filters, \n",
    "                                                kernel_size=kernel_size, \n",
    "                                                padding='same')  \n",
    "                       for _ in range(self.num_of_conv1d)]\n",
    "        self.maxpool2d = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size=(1, train_data.element_spec[0].shape[2]))\n",
    "                  \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        for conv1d_layer in self.conv1d_layers:\n",
    "            x = conv1d_layer(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = tf.reshape(x, (inputs.shape[0], inputs.shape[1], self.filters))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "# \n",
    "line_encoder =   LogLineEncoder()\n",
    "# the model doesn't have a state unless it is called at least once\n",
    "# in order to initialize the model we need a sample data \n",
    "sample_train_data = next(iter(train_data))\n",
    "sample_x_train = sample_train_data[0]\n",
    "print('sample_x_train.shape:', sample_x_train.shape)\n",
    "# now we will initialize the model with the sample data\n",
    "loglineEmbedding = line_encoder(sample_x_train)\n",
    "print('loglineEmbedding.shape:', loglineEmbedding.shape)\n",
    "# Now the model have a state and can be inspected        \n",
    "line_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb71a8ed",
   "metadata": {},
   "source": [
    "LOG SEQUENCE EMBEDDING TAKES LOGLINE EMBEDDING AS INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "69ac75f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logSeqEmbedding.shape: (32, 16)\n",
      "Model: \"log_seq_encoder_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           multiple                  12352     \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           multiple                  12352     \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           multiple                  12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  1040      \n",
      "=================================================================\n",
      "Total params: 38,096\n",
      "Trainable params: 38,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class LogSeqEncoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, num_of_conv1d=3,  filters=64,\n",
    "                 kernel_size=3, maxpool_1=True,\n",
    "                 dense_neurons=16, dense_activation='relu',):\n",
    "        super().__init__()\n",
    "        self.num_of_conv1d = num_of_conv1d\n",
    "        self.dense_neurons = dense_neurons\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.maxpool_1 = maxpool_1\n",
    "        self.dense_activation = dense_activation\n",
    "        self.conv1d_layers = [tf.keras.layers.Conv1D(filters=filters, \n",
    "                                                kernel_size=kernel_size, \n",
    "                                                padding='same')  \n",
    "                       for _ in range(self.num_of_conv1d)]\n",
    "        self.maxpool1d = tf.keras.layers.MaxPooling1D(pool_size=(train_data.element_spec[0].shape[1]) )\n",
    "        \n",
    "        self.Dense = tf.keras.layers.Dense(self.dense_neurons, \n",
    "                                           activation=self.dense_activation)\n",
    "       \n",
    "        \n",
    "    def call(self, inputs):       \n",
    "        for conv1d_layer in self.conv1d_layers:\n",
    "            x = conv1d_layer(inputs)\n",
    "        x = self.maxpool1d(x)        \n",
    "        x = tf.reshape(x, (inputs.shape[0], self.filters))\n",
    "        x = self.Dense(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "logSeqencer =   LogSeqEncoder()\n",
    "# the model doesn't have a state unless it is called at least once\n",
    "logSeqEmbedding = logSeqencer(loglineEmbedding)\n",
    "print('logSeqEmbedding.shape:', logSeqEmbedding.shape)\n",
    "# Now the model have a state and can be inspected        \n",
    "logSeqencer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3281f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11d25fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       "array([[0.24365869, 0.22684833, 0.24284323, 0.2866498 ],\n",
       "       [0.2387654 , 0.26823872, 0.21437998, 0.27861592],\n",
       "       [0.24500129, 0.22858903, 0.22597234, 0.30043742],\n",
       "       [0.24127483, 0.24924593, 0.23263992, 0.27683935],\n",
       "       [0.24661951, 0.23611398, 0.24892668, 0.2683398 ],\n",
       "       [0.25893798, 0.25272855, 0.23717998, 0.25115353],\n",
       "       [0.25970316, 0.25312582, 0.23949133, 0.2476798 ],\n",
       "       [0.2500926 , 0.25995392, 0.24081607, 0.2491374 ],\n",
       "       [0.2573613 , 0.2393681 , 0.24555507, 0.25771552],\n",
       "       [0.23853046, 0.23317362, 0.23815306, 0.29014286],\n",
       "       [0.25994053, 0.25003916, 0.25392714, 0.23609312],\n",
       "       [0.25100702, 0.21426399, 0.24512401, 0.289605  ],\n",
       "       [0.272541  , 0.22799456, 0.24962693, 0.2498375 ],\n",
       "       [0.25997856, 0.23823307, 0.24978384, 0.25200447],\n",
       "       [0.23672302, 0.25411123, 0.21897729, 0.29018852],\n",
       "       [0.24154194, 0.2587037 , 0.2184499 , 0.2813044 ],\n",
       "       [0.25910193, 0.2438815 , 0.23756076, 0.25945583],\n",
       "       [0.25927085, 0.2494125 , 0.25164756, 0.2396691 ],\n",
       "       [0.23973618, 0.23455405, 0.23305283, 0.29265696],\n",
       "       [0.23830064, 0.23368335, 0.23358612, 0.2944299 ],\n",
       "       [0.24787495, 0.24895884, 0.24806939, 0.25509682],\n",
       "       [0.24688984, 0.23120943, 0.23510334, 0.28679746],\n",
       "       [0.25022718, 0.21563584, 0.24704856, 0.2870884 ],\n",
       "       [0.24944147, 0.23530145, 0.24961235, 0.26564467],\n",
       "       [0.26031682, 0.2254579 , 0.25513   , 0.25909528],\n",
       "       [0.23719692, 0.24792004, 0.23029956, 0.2845835 ],\n",
       "       [0.2596413 , 0.25073358, 0.24557035, 0.24405472],\n",
       "       [0.25878823, 0.22022538, 0.26287156, 0.2581148 ],\n",
       "       [0.24016818, 0.24786842, 0.23044221, 0.2815212 ],\n",
       "       [0.23672302, 0.25411123, 0.21897729, 0.29018852],\n",
       "       [0.25513738, 0.25522774, 0.24614249, 0.24349241],\n",
       "       [0.25981432, 0.24802758, 0.24676946, 0.2453886 ]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LogClassifier(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,  **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.log_line_encoder = LogLineEncoder()\n",
    "        self.log_seq_encoder = LogSeqEncoder()\n",
    "        self.classifier = tf.keras.layers.Dense(\n",
    "            train_data.element_spec[1].shape[1], activation='softmax')\n",
    "#         self.extract_feature = extract_feature\n",
    "    \n",
    "    def call(self, inputs, extract_feature=False,):\n",
    "#         x_data, y_data = inputs\n",
    "        x = self.log_line_encoder(inputs)\n",
    "        seq_embedding = self.log_seq_encoder(x)\n",
    "        \n",
    "        if  extract_feature:\n",
    "            output = seq_embedding\n",
    "        else:\n",
    "            output = self.classifier(seq_embedding)\n",
    "        return output\n",
    "    \n",
    "log_classifier = LogClassifier()\n",
    "log_classifier(sample_x_train)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b512967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classifier assigned low probability to all the classes since it is untrained\n",
    "# TODO: the mode should accept a single sequence. At present it is accepting only a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76ab29d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"log_classifier_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_line_encoder_3 (LogLineE multiple                  36918     \n",
      "_________________________________________________________________\n",
      "log_seq_encoder_5 (LogSeqEnc multiple                  38096     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  68        \n",
      "=================================================================\n",
      "Total params: 75,082\n",
      "Trainable params: 75,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "log_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c1f0cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method LogSeqEncoder.call of <__main__.LogSeqEncoder object at 0x000001E1AD6F9D90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method LogSeqEncoder.call of <__main__.LogSeqEncoder object at 0x000001E1AD6F9D90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier_2/log_seq_encoder_5/conv1d_39/kernel:0', 'log_classifier_2/log_seq_encoder_5/conv1d_39/bias:0', 'log_classifier_2/log_seq_encoder_5/conv1d_40/kernel:0', 'log_classifier_2/log_seq_encoder_5/conv1d_40/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier_2/log_seq_encoder_5/conv1d_39/kernel:0', 'log_classifier_2/log_seq_encoder_5/conv1d_39/bias:0', 'log_classifier_2/log_seq_encoder_5/conv1d_40/kernel:0', 'log_classifier_2/log_seq_encoder_5/conv1d_40/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier_2/log_seq_encoder_5/conv1d_39/kernel:0', 'log_classifier_2/log_seq_encoder_5/conv1d_39/bias:0', 'log_classifier_2/log_seq_encoder_5/conv1d_40/kernel:0', 'log_classifier_2/log_seq_encoder_5/conv1d_40/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier_2/log_seq_encoder_5/conv1d_39/kernel:0', 'log_classifier_2/log_seq_encoder_5/conv1d_39/bias:0', 'log_classifier_2/log_seq_encoder_5/conv1d_40/kernel:0', 'log_classifier_2/log_seq_encoder_5/conv1d_40/bias:0'] when minimizing the loss.\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.3766 - accuracy: 0.8866 - precision_4: 0.9643 - recall_4: 0.7672 - val_loss: 0.0154 - val_accuracy: 0.9985 - val_precision_4: 0.9985 - val_recall_4: 0.9940\n"
     ]
    }
   ],
   "source": [
    "# This is to check that the model's built in  complile and fit is working well\n",
    "log_classifier.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "hist = log_classifier.fit(train_data, validation_data=test_data, epochs=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43904e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       "array([[7.66337962e-06, 9.80014011e-05, 1.00093067e-03, 9.98893440e-01],\n",
       "       [9.89592433e-01, 5.51328994e-03, 3.35740834e-03, 1.53688435e-03],\n",
       "       [6.62352366e-04, 3.03132948e-03, 5.61865091e-01, 4.34441179e-01],\n",
       "       [4.07132698e-04, 2.33796425e-03, 9.93918657e-01, 3.33624077e-03],\n",
       "       [7.37686287e-06, 1.34223315e-04, 1.77774008e-03, 9.98080611e-01],\n",
       "       [9.91067469e-01, 8.64739716e-03, 7.38604649e-05, 2.11355509e-04],\n",
       "       [9.91131008e-01, 8.56753252e-03, 7.96614768e-05, 2.21782393e-04],\n",
       "       [9.91044044e-01, 8.64533335e-03, 7.55685614e-05, 2.35019528e-04],\n",
       "       [3.33352759e-03, 9.96509612e-01, 1.23531336e-05, 1.44439924e-04],\n",
       "       [7.12871997e-06, 7.86651581e-05, 1.06223300e-03, 9.98852015e-01],\n",
       "       [1.31358288e-03, 9.98492002e-01, 1.73531407e-05, 1.76999994e-04],\n",
       "       [2.50415440e-04, 5.75117883e-04, 9.96209264e-01, 2.96528218e-03],\n",
       "       [5.69077267e-04, 1.86373445e-03, 1.38085589e-01, 8.59481573e-01],\n",
       "       [1.63197110e-05, 3.31048592e-04, 1.16618890e-02, 9.87990797e-01],\n",
       "       [1.30293309e-03, 2.66160048e-03, 9.92003739e-01, 4.03175876e-03],\n",
       "       [1.54914164e-06, 9.99769151e-01, 1.59225999e-06, 2.27701050e-04],\n",
       "       [2.89532915e-03, 9.96965706e-01, 1.19809583e-05, 1.26916217e-04],\n",
       "       [2.95188418e-03, 9.96911585e-01, 1.05551962e-05, 1.25998107e-04],\n",
       "       [1.15705880e-05, 1.10450230e-04, 1.91853940e-03, 9.97959495e-01],\n",
       "       [5.95364509e-06, 5.62214445e-05, 9.09530558e-04, 9.99028325e-01],\n",
       "       [4.79136914e-04, 3.38860042e-03, 8.90458107e-01, 1.05674170e-01],\n",
       "       [3.24144930e-04, 7.72227009e-04, 9.96390283e-01, 2.51338235e-03],\n",
       "       [2.80480774e-04, 2.11435626e-03, 1.20929606e-01, 8.76675606e-01],\n",
       "       [8.38220440e-05, 2.90644908e-04, 1.97123503e-03, 9.97654378e-01],\n",
       "       [1.55579455e-05, 9.40620375e-05, 3.69112729e-03, 9.96199191e-01],\n",
       "       [1.43603074e-05, 9.99147177e-01, 8.60802447e-06, 8.29818367e-04],\n",
       "       [2.98146834e-03, 9.96878505e-01, 1.06959169e-05, 1.29244916e-04],\n",
       "       [4.34124330e-03, 3.16779036e-03, 3.31356041e-02, 9.59355354e-01],\n",
       "       [3.83984414e-04, 1.82887272e-03, 9.91788089e-01, 5.99918514e-03],\n",
       "       [1.30293309e-03, 2.66160048e-03, 9.92003739e-01, 4.03175876e-03],\n",
       "       [9.91938174e-01, 4.46479861e-03, 2.20652064e-03, 1.39048090e-03],\n",
       "       [9.92719889e-01, 4.07177722e-03, 1.67977170e-03, 1.52863364e-03]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now after the training the predeicitoin will show higher probability to the \n",
    "# a class and lesser probability to other classes\n",
    "log_classifier(sample_x_train)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "89b86cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 16), dtype=float32, numpy=\n",
       "array([[ 0.8232021 ,  5.750864  ,  5.5350776 ,  0.        ,  6.0789514 ,\n",
       "         0.27661368,  2.9831824 ,  3.068651  ,  3.690295  ,  0.        ,\n",
       "         0.06916624,  1.2565458 ,  6.966045  ,  0.        ,  4.735535  ,\n",
       "         0.        ],\n",
       "       [ 2.8035774 ,  0.33830366,  1.029506  ,  0.        ,  1.9357386 ,\n",
       "         4.2382283 ,  4.4059677 ,  1.4008049 ,  3.6615927 ,  0.        ,\n",
       "         0.        ,  4.04283   ,  0.85960007,  1.1615007 ,  6.68119   ,\n",
       "         8.036921  ],\n",
       "       [ 1.8879466 ,  4.6071744 ,  4.3146276 ,  0.        ,  6.5413814 ,\n",
       "         0.        ,  1.8162975 ,  2.134408  ,  2.9991972 ,  0.        ,\n",
       "         0.7637098 ,  1.9248446 ,  7.564635  ,  0.        ,  1.702782  ,\n",
       "         1.2924783 ],\n",
       "       [ 3.1914344 ,  3.6201518 ,  3.8094075 ,  0.        ,  7.528643  ,\n",
       "         0.        ,  1.2003884 ,  1.3355631 ,  2.2037168 ,  0.        ,\n",
       "         0.62469894,  3.254866  ,  7.6564665 ,  0.        ,  0.9608521 ,\n",
       "         2.400834  ],\n",
       "       [ 0.84989214,  5.7810473 ,  5.3139105 ,  0.        ,  6.56024   ,\n",
       "         0.        ,  2.6627722 ,  3.532383  ,  3.6891394 ,  0.        ,\n",
       "         0.        ,  1.0882467 ,  7.0130057 ,  0.        ,  4.271324  ,\n",
       "         0.        ],\n",
       "       [ 2.3181853 ,  0.        ,  0.8800768 ,  0.        ,  0.12385876,\n",
       "         5.80763   ,  3.2114851 ,  0.7127763 ,  2.7352786 ,  0.        ,\n",
       "         0.        ,  4.854218  ,  0.        ,  2.9356024 ,  9.003044  ,\n",
       "         8.843331  ],\n",
       "       [ 2.3022885 ,  0.        ,  0.91850793,  0.        ,  0.14182167,\n",
       "         5.7893057 ,  3.187264  ,  0.6744069 ,  2.785117  ,  0.        ,\n",
       "         0.        ,  4.8525844 ,  0.        ,  2.9136047 ,  8.896051  ,\n",
       "         8.79978   ],\n",
       "       [ 2.3337088 ,  0.        ,  0.9152569 ,  0.        ,  0.14484145,\n",
       "         5.799017  ,  3.2860403 ,  0.7888557 ,  2.7800453 ,  0.        ,\n",
       "         0.        ,  4.8417373 ,  0.        ,  2.9392607 ,  8.986374  ,\n",
       "         8.77402   ],\n",
       "       [ 1.8238207 ,  0.        ,  4.1416197 ,  0.        ,  3.18726   ,\n",
       "         4.054608  ,  0.13141243,  3.2994213 ,  1.7731495 ,  0.        ,\n",
       "         0.        ,  6.426401  ,  0.        ,  1.6534735 , 11.253428  ,\n",
       "         4.7412815 ],\n",
       "       [ 1.0411865 ,  5.982932  ,  5.328061  ,  0.        ,  6.003156  ,\n",
       "         0.        ,  3.0243924 ,  3.3069248 ,  3.7534113 ,  0.        ,\n",
       "         0.        ,  1.1607647 ,  7.04553   ,  0.        ,  4.5933266 ,\n",
       "         0.        ],\n",
       "       [ 2.2216735 ,  0.17217171,  4.457856  ,  0.        ,  3.1909049 ,\n",
       "         2.8680887 ,  0.61240935,  3.4987323 ,  1.1859603 ,  0.        ,\n",
       "         0.        ,  6.0992312 ,  0.        ,  1.0791453 , 10.868178  ,\n",
       "         3.5374432 ],\n",
       "       [ 3.2372036 ,  3.6459277 ,  2.842866  ,  0.        ,  7.9341416 ,\n",
       "         0.        ,  2.124025  ,  1.334595  ,  2.2627516 ,  0.        ,\n",
       "         1.1893123 ,  1.9899983 ,  7.7097473 ,  0.        ,  0.38409278,\n",
       "         2.3489146 ],\n",
       "       [ 1.1420339 ,  4.2041836 ,  3.8406682 ,  0.        ,  6.192566  ,\n",
       "         0.        ,  2.5103774 ,  2.5061135 ,  2.4664242 ,  0.        ,\n",
       "         0.06450859,  1.2830067 ,  6.736312  ,  0.        ,  2.7668598 ,\n",
       "         1.1821746 ],\n",
       "       [ 0.9461613 ,  5.837932  ,  5.5657754 ,  0.        ,  6.624728  ,\n",
       "         0.        ,  2.6615655 ,  2.716652  ,  2.7889736 ,  0.        ,\n",
       "         0.83969796,  0.9794202 ,  7.6767216 ,  0.        ,  3.2702954 ,\n",
       "         0.        ],\n",
       "       [ 3.3083932 ,  3.0082889 ,  2.8326325 ,  0.        ,  7.2386    ,\n",
       "         0.19673206,  2.2111034 ,  0.9569192 ,  1.7489662 ,  0.        ,\n",
       "         0.        ,  2.8318107 ,  6.509284  ,  0.        ,  1.5368406 ,\n",
       "         2.6362586 ],\n",
       "       [ 3.0901086 ,  4.047602  ,  5.24735   ,  0.        ,  5.746148  ,\n",
       "         1.6478027 ,  0.        ,  4.7502832 ,  0.        ,  0.        ,\n",
       "         0.        ,  5.3215394 ,  1.1886238 ,  0.10784763, 12.57835   ,\n",
       "         0.        ],\n",
       "       [ 1.8807373 ,  0.        ,  4.2438293 ,  0.        ,  3.2452245 ,\n",
       "         4.0315676 ,  0.09753641,  3.22167   ,  1.765698  ,  0.        ,\n",
       "         0.        ,  6.4746385 ,  0.        ,  1.6134429 , 11.253725  ,\n",
       "         4.689318  ],\n",
       "       [ 1.7506552 ,  0.        ,  4.162871  ,  0.        ,  3.1593618 ,\n",
       "         4.0787263 ,  0.05867005,  3.2427568 ,  1.678417  ,  0.        ,\n",
       "         0.        ,  6.520209  ,  0.        ,  1.7053138 , 11.286049  ,\n",
       "         4.661634  ],\n",
       "       [ 1.1238163 ,  6.128504  ,  5.0964446 ,  0.        ,  5.9640718 ,\n",
       "         0.        ,  3.0793889 ,  2.8989687 ,  3.5258641 ,  0.        ,\n",
       "         0.        ,  1.2051104 ,  6.8407493 ,  0.        ,  4.229903  ,\n",
       "         0.        ],\n",
       "       [ 1.0043743 ,  6.1641006 ,  5.34409   ,  0.        ,  6.097919  ,\n",
       "         0.        ,  3.0810366 ,  3.2455869 ,  3.943975  ,  0.        ,\n",
       "         0.        ,  1.1694521 ,  7.1182213 ,  0.        ,  4.605674  ,\n",
       "         0.1055508 ],\n",
       "       [ 1.7457854 ,  4.073841  ,  4.766381  ,  0.        ,  7.2483644 ,\n",
       "         0.        ,  1.7366942 ,  1.663081  ,  2.518505  ,  0.        ,\n",
       "         1.44303   ,  2.279636  ,  7.979861  ,  0.        ,  1.3670152 ,\n",
       "         1.7177024 ],\n",
       "       [ 3.125916  ,  3.5547683 ,  3.0068188 ,  0.        ,  8.111153  ,\n",
       "         0.        ,  2.2887907 ,  1.4384769 ,  2.2277582 ,  0.        ,\n",
       "         1.2326089 ,  2.211036  ,  7.4475703 ,  0.        ,  0.6094554 ,\n",
       "         2.80488   ],\n",
       "       [ 1.571156  ,  4.8238525 ,  4.8494635 ,  0.        ,  6.560239  ,\n",
       "         0.        ,  2.2088623 ,  2.3321536 ,  3.0071406 ,  0.        ,\n",
       "         0.3413146 ,  1.759451  ,  7.3291335 ,  0.        ,  3.0927243 ,\n",
       "         1.1103522 ],\n",
       "       [ 0.        ,  4.532896  ,  4.759558  ,  0.        ,  5.0636077 ,\n",
       "         0.99356395,  2.5925899 ,  2.389845  ,  3.2085297 ,  0.        ,\n",
       "         0.        ,  1.4700278 ,  6.2254696 ,  0.        ,  4.7997584 ,\n",
       "         1.071018  ],\n",
       "       [ 0.9737039 ,  5.659064  ,  4.632792  ,  0.        ,  6.3565626 ,\n",
       "         0.        ,  2.9625468 ,  3.1820242 ,  3.7657104 ,  0.        ,\n",
       "         0.        ,  0.90491647,  6.9590216 ,  0.        ,  3.6188583 ,\n",
       "         0.14768215],\n",
       "       [ 2.4005935 ,  3.3226912 ,  4.40781   ,  0.        ,  5.1479616 ,\n",
       "         1.8383595 ,  0.        ,  4.095861  ,  0.3301418 ,  0.        ,\n",
       "         0.        ,  4.7074866 ,  0.9821962 ,  0.45635042, 11.064929  ,\n",
       "         0.36847493],\n",
       "       [ 1.8131797 ,  0.        ,  4.1781898 ,  0.        ,  3.1368744 ,\n",
       "         4.0834913 ,  0.06080405,  3.3347244 ,  1.7037455 ,  0.        ,\n",
       "         0.        ,  6.4412045 ,  0.        ,  1.6439677 , 11.309777  ,\n",
       "         4.7318354 ],\n",
       "       [ 1.3784249 ,  3.1389792 ,  5.5872345 ,  0.        ,  4.356822  ,\n",
       "         0.5542206 ,  2.4165974 ,  1.8834125 ,  4.097327  ,  0.        ,\n",
       "         0.        ,  2.781577  ,  6.054203  ,  0.        ,  5.04084   ,\n",
       "         3.368929  ],\n",
       "       [ 2.774115  ,  3.622461  ,  3.8036568 ,  0.        ,  7.5915747 ,\n",
       "         0.        ,  1.3220867 ,  1.289235  ,  2.3082995 ,  0.        ,\n",
       "         0.74757713,  3.033159  ,  7.8212996 ,  0.        ,  0.90751123,\n",
       "         2.239026  ],\n",
       "       [ 3.3083932 ,  3.0082889 ,  2.8326325 ,  0.        ,  7.2386    ,\n",
       "         0.19673206,  2.2111034 ,  0.9569192 ,  1.7489662 ,  0.        ,\n",
       "         0.        ,  2.8318107 ,  6.509284  ,  0.        ,  1.5368406 ,\n",
       "         2.6362586 ],\n",
       "       [ 2.6086683 ,  0.20460495,  1.0736917 ,  0.        ,  2.0329509 ,\n",
       "         4.6250496 ,  4.591382  ,  1.3844776 ,  3.8120868 ,  0.        ,\n",
       "         0.        ,  4.3660827 ,  0.9648639 ,  1.3389155 ,  7.097145  ,\n",
       "         8.163547  ],\n",
       "       [ 2.3628144 ,  0.09860645,  1.0634209 ,  0.        ,  1.9891229 ,\n",
       "         4.718919  ,  4.571706  ,  1.468842  ,  3.8591375 ,  0.        ,\n",
       "         0.        ,  4.272004  ,  0.8490083 ,  1.416559  ,  7.174961  ,\n",
       "         8.258284  ]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = log_classifier(sample_x_train, extract_feature=True ) \n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28535322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b286990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[14 13 13 ... 11 11 25]\n",
      "  [13 13 22 ... 11 11 25]\n",
      "  [14 13 13 ... 11 11 25]\n",
      "  ...\n",
      "  [10  8  4 ...  6  6  7]\n",
      "  [13 13 13 ... 22 21 21]\n",
      "  [13 13 13 ... 22 21 21]]\n",
      "\n",
      " [[ 2 19 11 ...  8 10  2]\n",
      "  [ 2 19 11 ...  8 10  2]\n",
      "  [ 2 19 11 ...  8 10  2]\n",
      "  ...\n",
      "  [ 2 19 11 ...  8 10  2]\n",
      "  [ 2 19 11 ...  8 10  2]\n",
      "  [ 2 19 11 ...  8 10  2]]\n",
      "\n",
      " [[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]\n",
      "\n",
      " [[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]\n",
      "\n",
      " [[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]], shape=(32, 32, 64), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]], shape=(32, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_data:\n",
    "    x_train, y_train = batch\n",
    "    print(x_train)\n",
    "    print(y_train)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4bb17f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centriods initialized: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "total_labels initialized: [0. 0. 0. 0.]\n",
      "centroids: [[2.42723633e+00 1.61075535e-01 1.04813332e+00 0.00000000e+00\n",
      "  9.88495178e-01 5.11170959e+00 3.71239746e+00 1.05664352e+00\n",
      "  3.15759613e+00 0.00000000e+00 0.00000000e+00 4.53865234e+00\n",
      "  4.20471764e-01 2.19021057e+00 8.06535583e+00 8.36452026e+00]\n",
      " [2.22617950e+00 1.72305374e+00 4.27698151e+00 0.00000000e+00\n",
      "  4.17190155e+00 2.86426941e+00 1.52251129e-01 3.54656738e+00\n",
      "  9.93699341e-01 0.00000000e+00 0.00000000e+00 5.45192078e+00\n",
      "  5.91299553e-01 1.07752678e+00 1.09522058e+01 2.66130615e+00]\n",
      " [2.81991516e+00 3.66816589e+00 3.50354187e+00 0.00000000e+00\n",
      "  7.68100098e+00 5.91734838e-02 2.02764847e+00 1.43781494e+00\n",
      "  2.28084656e+00 0.00000000e+00 9.29355774e-01 2.48236298e+00\n",
      "  7.43869141e+00 1.99984103e-03 1.27673561e+00 2.48319199e+00]\n",
      " [9.82767868e-01 5.30186218e+00 5.08778900e+00 0.00000000e+00\n",
      "  6.05381470e+00 1.12217627e-01 2.69602234e+00 2.98189209e+00\n",
      "  3.56977356e+00 0.00000000e+00 1.17959681e-01 1.40428345e+00\n",
      "  6.79935791e+00 1.29742706e-02 4.24655548e+00 3.70331802e-01]]\n",
      "total_labels: [[800.]\n",
      " [800.]\n",
      " [800.]\n",
      " [800.]]\n"
     ]
    }
   ],
   "source": [
    "centroids = np.zeros((train_data.element_spec[1].shape[1],   16))\n",
    "print('centriods initialized:', centroids)\n",
    "total_labels = np.zeros(train_data.element_spec[1].shape[1]) # it was 4\n",
    "# total_labels[2] += 1\n",
    "# total_labels[2] += 1\n",
    "print('total_labels initialized:', total_labels)\n",
    "for batch in train_data:\n",
    "    logseq_batch, label_batch = batch\n",
    "    features = log_classifier(logseq_batch, extract_feature=True )\n",
    "    for i in range(len(label_batch)):\n",
    "        label = label_batch[i]\n",
    "        numeric_label = np.argmax(label)\n",
    "        total_labels[numeric_label] += 1\n",
    "        centroids[numeric_label] += features[i]\n",
    "total_label_reshaped = np.reshape(total_labels, (train_data.element_spec[1].shape[1], 1))\n",
    "centroids /= total_label_reshaped\n",
    "print('centroids:',centroids)\n",
    "print('total_labels:',total_label_reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7c70c318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n2 [[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "n3 [2 2 2]\n",
      "n4 [[2]\n",
      " [2]\n",
      " [2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.5, 1. , 1.5],\n",
       "       [2. , 2.5, 3. , 3.5],\n",
       "       [4. , 4.5, 5. , 5.5]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to understand the np divide operation\n",
    "n1 = np.arange(12)\n",
    "n2 = n1.reshape((3, 4))\n",
    "print('n2', n2)\n",
    "n3 = np.array([2, 2, 2])\n",
    "print('n3', n3)\n",
    "n4 = np.reshape(n3, (3, 1))\n",
    "print('n4', n4)\n",
    "n2/n4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6cdd8a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_x_train[0] tf.Tensor(\n",
      "[[ 4 30 25 ...  9  0  0]\n",
      " [30 25 17 ...  8  4 14]\n",
      " [12  3  6 ... 12  6 18]\n",
      " ...\n",
      " [30 25 17 ...  8  4 14]\n",
      " [12  3  6 ... 12  6 18]\n",
      " [ 4 30 25 ...  9  0  0]], shape=(32, 64), dtype=int32)\n",
      "sample_y_train[0] tf.Tensor([0. 0. 0. 1.], shape=(4,), dtype=float32)\n",
      "feature for the same: tf.Tensor(\n",
      "[2.8337116 4.522587  4.577522  0.        7.5018716 0.        2.0851574\n",
      " 1.8526348 2.728645  0.        0.7425541 2.766746  7.8422027 0.\n",
      " 2.1378212 1.855924 ], shape=(16,), dtype=float32)\n",
      "centroid for the class 3 : [0.98276848 5.30186157 5.08779053 0.         6.05381165 0.11221761\n",
      " 2.69602173 2.98188934 3.56977234 0.         0.11795975 1.40428314\n",
      " 6.79935242 0.01297427 4.24655457 0.37033184]\n"
     ]
    }
   ],
   "source": [
    "#take zi and a ck \n",
    "# from sample_x_train the first sample belongs to class 3\n",
    "print('sample_x_train[0]', sample_x_train[0])\n",
    "sample_y_train = sample_train_data[1]\n",
    "print('sample_y_train[0]', sample_y_train[0])\n",
    "print('feature for the same:', features[0])\n",
    "print('centroid for the class 3 :', centroids[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "946b8abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eucladian distance: 18.746838\n"
     ]
    }
   ],
   "source": [
    "# eucladian distance\n",
    "z_0_3= features[0] # [16], earlier [2048]\n",
    "C_3 = centroids[3] # [16], earlier [2048]\n",
    "ED = np.sum(np.square(z_0_3 - C_3 ))\n",
    "print('eucladian distance:', ED)\n",
    "# InvalidArgumentError: Incompatible shapes: [32,64] vs. [2048] [Op:Sub]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7953c3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape (32, 16)\n",
      "centroids.shape (4, 16)\n",
      "np.expand_dims(features, axis=1) : (32, 1, 16)\n",
      "np.expand_dims(centroids, axis=0): (1, 4, 16)\n",
      "sub_z_C (32, 4, 16)\n",
      "squred_sum (32, 4)\n"
     ]
    }
   ],
   "source": [
    "# wwe can not substract different shaped arrays , see the error\n",
    "print('features.shape', features.shape)\n",
    "print('centroids.shape', centroids.shape)\n",
    "# features - centroids # InvalidArgumentError: Incompatible shapes: [32,16] vs. [4,16] [Op:Sub]\n",
    "z = np.expand_dims(features, axis=1)\n",
    "C =  np.expand_dims(centroids, axis=0)\n",
    "print('np.expand_dims(features, axis=1) :', z.shape)\n",
    "print('np.expand_dims(centroids, axis=0):', C.shape)\n",
    "# Now we can substract\n",
    "sub_z_C = z - C\n",
    "print('sub_z_C', sub_z_C.shape)\n",
    "squred_sum = np.sum(np.square(z- C), axis=2)\n",
    "print('squred_sum', squred_sum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f941175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED_logits (32, 4)\n",
      "ED_logits_sample [-201.07862778  -24.55007728 -211.70321366 -148.03531404]\n"
     ]
    }
   ],
   "source": [
    "# make the dimensions same for substraction \n",
    "def euclidean_metric(a, b):\n",
    "#     n = a.shape[0]\n",
    "#     m = b.shape[0]\n",
    "    a = np.expand_dims(a, 1)\n",
    "    b = np.expand_dims(b, 0)\n",
    "#     logits = -((a - b)**2).sum(dim=2)\n",
    "    logits = -np.sum(np.square(a - b), axis=2)\n",
    "    return logits  \n",
    "ED_logits = euclidean_metric(features, centroids)\n",
    "print('ED_logits', ED_logits.shape)\n",
    "print('ED_logits_sample', ED_logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "be64ed04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smax.shape: (32, 4)\n",
      "smax_sample: tf.Tensor([2.16085000e-77 1.00000000e+00 5.25322016e-82 2.34986590e-54], shape=(4,), dtype=float64)\n",
      "reduced_max: tf.Tensor(\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         0.99998873 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.99986173 1.         1.         1.         1.\n",
      " 1.         1.        ], shape=(32,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# smax = tf.nn.softmax(ED_logits, axis=1)\n",
    "smax = tf.nn.softmax(ED_logits, )\n",
    "print('smax.shape:', smax.shape)\n",
    "print('smax_sample:', smax[0])\n",
    "reduced_max = tf.reduce_max(smax, axis=1)\n",
    "print('reduced_max:', reduced_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd81b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb4a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0806a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8cff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundaryLoss(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_labels=train_data.element_spec[1].shape[1], \n",
    "                feat_dim = 16):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.feat_dim = feat_dim\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.delta = tf.Variable(\n",
    "            initial_value=w_init((self.num_labels), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        \n",
    "    def call(self, features, centroids, labels):\n",
    "        logits =  euclidean_metric(features, centroids)  \n",
    "        ######### Why softmax before softplus#########\n",
    "        smax = tf.nn.softmax(logits, )\n",
    "        reduced_max = tf.reduce_max(smax, axis=1)\n",
    "        ############################\n",
    "        delta = tf.nn.softplus(self.delta)\n",
    "        label_indexs = np.argmax(labels)\n",
    "        c = centroids[label_indexs]\n",
    "        d = delta[label_indexs]\n",
    "        x = features\n",
    "        \n",
    "        euc_dis = tf.norm(x - c, ord='euclidean', axis=1,)\n",
    "        ##If axis is None (the default), the input is considered a vector and a \n",
    "        ## single vector norm is computed over the entire set of values in the tensor, \n",
    "        ## i.e. norm(tensor, ord=ord) is equivalent to norm(reshape(tensor, [-1]), ord=ord). If axis is a Python integer, the input is considered a batch of vectors, and axis determines the axis in tensor over which to compute vector norms.\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b78d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384e02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e564ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand this , a= features(batch_size, 2048) , b = centroids (4, 2048)\n",
    "def euclidean_metric_torch(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    a = a.unsqueeze(1).expand(n, m, -1)\n",
    "    b = b.unsqueeze(0).expand(n, m, -1)\n",
    "    logits = -((a - b)**2).sum(dim=2)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7067df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [[0 1 2]\n",
      " [3 4 5]]\n",
      "a.shape (2, 3)\n",
      "b [ 8  9 10 11 12 13 14 15]\n",
      "b [[ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]]\n",
      "b.shape: (4, 2)\n",
      "tfa tf.Tensor(\n",
      "[[0 1 2]\n",
      " [3 4 5]], shape=(2, 3), dtype=int32)\n",
      "tfb tf.Tensor(\n",
      "[[ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]], shape=(4, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "a = np.arange(6)\n",
    "a = a.reshape((2, -1))\n",
    "print('a:', a)\n",
    "print('a.shape', a.shape)\n",
    "b = np.arange(8, 16)\n",
    "print('b',b)\n",
    "b = np.reshape(b, (4, -1))\n",
    "print('b',b)\n",
    "print('b.shape:',b.shape)\n",
    "tfa = tf.constant(a)\n",
    "tfb = tf.constant(b)\n",
    "print('tfa',tfa)\n",
    "print('tfb',tfb)\n",
    "# n = tfa.shape[0]\n",
    "# m = b.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e1197fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.expand_dims(tfa, 0) : tf.Tensor(\n",
      "[[[0 1 2]\n",
      "  [3 4 5]]], shape=(1, 2, 3), dtype=int32)\n",
      "\n",
      "tf.expand_dims(tfa, 1) : tf.Tensor(\n",
      "[[[0 1 2]]\n",
      "\n",
      " [[3 4 5]]], shape=(2, 1, 3), dtype=int32)\n",
      "\n",
      "tf.expand_dims(tfa, 1) : tf.Tensor(\n",
      "[[[0]\n",
      "  [1]\n",
      "  [2]]\n",
      "\n",
      " [[3]\n",
      "  [4]\n",
      "  [5]]], shape=(2, 3, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print('tf.expand_dims(tfa, 0) :',tf.expand_dims(tfa, 0))\n",
    "print()\n",
    "print('tf.expand_dims(tfa, 1) :',tf.expand_dims(tfa, 1))\n",
    "print()\n",
    "print('tf.expand_dims(tfa, 1) :',tf.expand_dims(tfa, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "91885dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.shape(tfa): [2 1 3]\n",
      "tf.shape(tfb): [1 4 2]\n"
     ]
    }
   ],
   "source": [
    "tfa = tf.expand_dims(tfa, 1)\n",
    "print(f'tf.shape(tfa): {tf.shape(tfa)}')\n",
    "tfb = tf.expand_dims(tfb, 0)\n",
    "print(f'tf.shape(tfb): {tf.shape(tfb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88789603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfa_broadcast tf.Tensor(\n",
      "[[[0 1 2]\n",
      "  [0 1 2]\n",
      "  [0 1 2]\n",
      "  [0 1 2]]\n",
      "\n",
      " [[3 4 5]\n",
      "  [3 4 5]\n",
      "  [3 4 5]\n",
      "  [3 4 5]]], shape=(2, 4, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "n = a.shape[0]\n",
    "m = b.shape[0]\n",
    "tfa_broadcast = tf.broadcast_to(tfa, [2, 4, 3])\n",
    "tf.shape(tfa_broadcast)\n",
    "print('tfa_broadcast',tfa_broadcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8130a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "\n",
    "# The equivalent function for pytorch expand is tensorflow tf.broadcast_to\n",
    "\n",
    "# Docs: https://www.tensorflow.org/api_docs/python/tf/broadcast_to\n",
    "\n",
    "# Share\n",
    "# Follow\n",
    "# edited Oct 23, 2021 at 18:22\n",
    "\n",
    "# M.Innat\n",
    "# 12.2k66 gold badges3434 silver badges6767 bronze badges\n",
    "# answered Jan 4, 2019 at 9:12\n",
    "\n",
    "# funkyyyyyy\n",
    "# 6111 silver badge22 bronze badges\n",
    "# Add a comment\n",
    "\n",
    "# 0\n",
    "\n",
    "# Tensorflow automatically broadcasts, so in general you don't need to do any of this. Suppose you have a y' of shape 6x2x3 and your x is of shape 2x3, then you can already do y'*x or y'+x will already behave as if you had expanded it. But if for some other reason you really need to do it, then the command in tensorflow is tile:\n",
    "\n",
    "# y = tf.tile(tf.reshape(x, (1,2,3)), multiples=(6,1,1))\n",
    "# Docs: https://www.tensorflow.org/api_docs/python/tf/tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33171303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_metric(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    a = tf.expand_dims(a, 1)\n",
    "    b = tf.expand_dims(b, 0)\n",
    "    logits = -((a - b)**2).sum(dim=2)\n",
    "    return logits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee5fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c647ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d43a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1ca72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4af6a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6862fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenSet:\n",
    "    def __init__(self, data, pretrained_model):\n",
    "        \n",
    "        self.model = pretrained_model\n",
    "        self.best_eval_score = 0\n",
    "        self.delta = None\n",
    "        self.delta_points = []\n",
    "        self.centroids = None\n",
    "        self.test_results = None\n",
    "        self.predictions = None\n",
    "        self.true_labels = None\n",
    "        \n",
    "    def centroids_cal(self):\n",
    "        centriods = np.zeros(train_data.element_spec[1].shape[1], embedding_size)\n",
    "        total_labels = np.empty(0, dtype=longdouble)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca34bd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d34c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing the training step to get centroid for each class\n",
    "class OpenSet:\n",
    "    def __init__(self, data, pretrained_model=log_classifier):\n",
    "#         super().__init__():\n",
    "        self.model = pretrained_model        \n",
    "        self.centroids = None\n",
    "        self.num_labels = train_data.element_spec[1].shape[1]\n",
    "        \n",
    "    def centroids_cal(self):\n",
    "        centriods = np.zeros(self.num_labels, embedding_size)\n",
    "        total_labels = np.empty(0, dtype=longdouble)\n",
    "        for batch in data:\n",
    "            logseq_batch, label_batch = batch\n",
    "            features = self.model(logseq_batch, extract_feature=True ) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e841e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c5fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40affa9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169fa03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In context of deep learning the logits layer means the layer that feeds in to softmax (or other such normalization). The output of the softmax are the probabilities for the classification task and its input is logits layer. The logits layer typically produces values from -infinity to +infinity and the softmax layer transforms it to values from 0 to 1.\n",
    "\n",
    "# Historical Context\n",
    "\n",
    "# Where does this term comes from? In 1930s and 40s, several people were trying to adapt linear regression to the problem of predicting probabilities. However linear regression produces output from -infinity to +infinity while for probabilities our desired output is 0 to 1. One way to do this is by somehow mapping the probabilities 0 to 1 to -infinity to +infinity and then use linear regression as usual. One such mapping is cumulative normal distribution that was used by Chester Ittner Bliss in 1934 and he called this \"probit\" model, short for \"probability unit\". However this function is computationally expensive while lacking some of the desirable properties for multi-class classification. In 1944 Joseph Berkson used the function log(p/(1-p)) to do this mapping and called it logit, short for \"logistic unit\". The term logistic regression derived from this as well.\n",
    "\n",
    "# The Confusion\n",
    "\n",
    "# Unfortunately the term logits is abused in deep learning. From pure mathematical perspective logit is a function that performs above mapping. In deep learning people started calling the layer \"logits layer\" that feeds in to logit function. Then people started calling the output values of this layer \"logit\" creating the confusion with logit the function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
