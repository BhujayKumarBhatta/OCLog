{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b59a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bglog import BGLog\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45723977",
   "metadata": {},
   "outputs": [],
   "source": [
    "bglog = BGLog(save_padded_num_sequences=False, load_from_pkl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276adff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_num_seq_df loaded from data\\bgl_padded_num_seq_df.pkl\n",
      "trained tokenizer, tk, loaded from data\\bgltk.pkl\n",
      "train_0:, 800\n",
      "test_0:, 200\n",
      "train_1:, 800\n",
      "test_1:, 200\n",
      "train_2:, 800\n",
      "test_2:, 200\n",
      "train_3:, 800\n",
      "test_3:, 102\n",
      "4 class does not have 800 records, it has only 628 records\n",
      "test_4:, 0\n",
      "5 class does not have 800 records, it has only 165 records\n",
      "5 class does not have 200 records, it has only 165 records\n",
      "6 class does not have 800 records, it has only 75 records\n",
      "6 class does not have 200 records, it has only 75 records\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "<BatchDataset shapes: ((32, 32, 64), (32, 4)), types: (tf.int32, tf.float32)>\n",
      "<BatchDataset shapes: ((32, 32, 64), (32, 4)), types: (tf.int32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "train_test = bglog.get_tensor_train_test(ablation=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f96f7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d527dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_layer():\n",
    "    tk = bglog.tk\n",
    "    vocab_size = len(tk.word_index)\n",
    "    print(f'vocab_size: {vocab_size}')\n",
    "    char_onehot = vocab_size\n",
    "    embedding_weights = []\n",
    "    embedding_weights.append(np.zeros(vocab_size))\n",
    "    for char, i in tk.word_index.items(): # from 1 to 51\n",
    "        onehot = np.zeros(vocab_size)\n",
    "        onehot[i-1] = 1\n",
    "        embedding_weights.append(onehot)\n",
    "    embedding_weights = np.array(embedding_weights)\n",
    "\n",
    "#     input_size =[ train_data.element_spec[0].shape[1], train_data.element_spec[0].shape[2]]\n",
    "#     embedding_size = vocab_size\n",
    "\n",
    "#     embedding_layer = tf.keras.layers.Embedding(vocab_size+1,\n",
    "#                                                 embedding_size,\n",
    "#                                                 input_length=input_size,\n",
    "#                                                 weights = [embedding_weights])\n",
    "    return embedding_weights, vocab_size, char_onehot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd47bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(conv1d_set1 = 3, conv1d_set2 = 3, dense_neurons=2048, filters=64,\n",
    "            kernel_size=3,maxpool_1=True,epochs=25):\n",
    "    embedding_weights, vocab_size, char_onehot = get_embedding_layer()\n",
    "    B = train_data.element_spec[0].shape[0]\n",
    "    inputs = tf.keras.layers.Input(batch_shape=(B, train_data.element_spec[0].shape[1], train_data.element_spec[0].shape[2]), dtype='float64' )\n",
    "    x = tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
    "                                    output_dim=vocab_size,\n",
    "                                    input_length=train_data.element_spec[0].shape[2],\n",
    "                                    weights = [embedding_weights],\n",
    "                                    )(inputs)\n",
    "    for _ in range(conv1d_set1):\n",
    "        x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "    if maxpool_1:\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(1, train_data.element_spec[0].shape[2]))(x)\n",
    "        x = tf.reshape(x, (B, train_data.element_spec[0].shape[1], filters))        \n",
    "        for _ in range(conv1d_set2):\n",
    "            x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "        x = tf.keras.layers.MaxPooling1D(pool_size=(train_data.element_spec[0].shape[1]) )(x)\n",
    "        x = tf.reshape(x, (B, filters))\n",
    "    if not maxpool_1:\n",
    "        x = tf.keras.layers.Flatten()(x)       \n",
    "    x = tf.keras.layers.Dense(dense_neurons)(x)\n",
    "    outputs = tf.keras.layers.Dense(train_data.element_spec[1].shape[1], activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    print(model.summary())\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    hist = model.fit(train_data, validation_data=test_data, epochs=epochs) \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d574f04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(32, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (32, 32, 64, 50)          2550      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (32, 32, 64, 64)          9664      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (32, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (32, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (32, 32, 1, 64)           0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(32, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (32, 1, 64)               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (Tenso [(32, 64)]                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 2048)                133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (32, 4)                   8196      \n",
      "=================================================================\n",
      "Total params: 215,290\n",
      "Trainable params: 215,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.2800 - accuracy: 0.8759 - precision: 0.9071 - recall: 0.8456 - val_loss: 0.0116 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.0545 - accuracy: 0.9828 - precision: 0.9831 - recall: 0.9828 - val_loss: 0.0258 - val_accuracy: 0.9911 - val_precision: 0.9925 - val_recall: 0.9911\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0189 - accuracy: 0.9925 - precision: 0.9928 - recall: 0.9925 - val_loss: 0.0052 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.0339 - accuracy: 0.9869 - precision: 0.9869 - recall: 0.9869 - val_loss: 0.0132 - val_accuracy: 0.9940 - val_precision: 0.9955 - val_recall: 0.9940\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.0060 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - val_loss: 9.3046e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.0020 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997 - val_loss: 0.0108 - val_accuracy: 0.9955 - val_precision: 0.9955 - val_recall: 0.9955\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 1.5457e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 7.6686e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9955 - val_precision: 0.9955 - val_recall: 0.9955\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 5.5357e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9955\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 4.3372e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9970 - val_precision: 0.9985 - val_recall: 0.9955\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 3.4831e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9970 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 2.8773e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9970 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 2.4530e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9970 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 9s 89ms/step - loss: 2.0939e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9970 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 1.8351e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 1.6062e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 1.4246e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 1.2570e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 1.1401e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 1.0096e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 9.1029e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 8.2035e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9985\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 11s 106ms/step - loss: 7.4826e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9985\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 6.8138e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 6.2583e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.engine.functional.Functional at 0x1c7a8c65bb0>,\n",
       " <tensorflow.python.keras.callbacks.History at 0x1c7a90c13d0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7394bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85040437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a78ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043d19a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
