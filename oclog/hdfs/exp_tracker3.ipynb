{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b65943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each time we will run an experiment, we will restart the kernel. This is based on experimental learning from my previous project \n",
    "# that without this the result becomes unecpectedly stochastics in nature despite setting the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07dcfb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(ablation=1000, B=32, epochs=3, filters=64, kernel_size=3, dense_neurons=2048, \n",
    "              conv1d_set1=1, conv1d_set2=1, maxpool_1=False):\n",
    "    from hdflogv1 import HDFSLogv1\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    tf.random.set_seed(123)\n",
    "    import pickle\n",
    "    with open('../data/hdfs_log_obj.pkl', 'rb') as f:\n",
    "        hdfslogs = pickle.load(f)\n",
    "    ablation_data = hdfslogs.get_train_test_data(ablation=ablation)\n",
    "    x_train, y_train, x_test, y_test = hdfslogs.get_padded_train_test_data(ablation=ablation)\n",
    "    train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_data = train_data.shuffle(buffer_size=y_train.shape[0]).batch(B, drop_remainder=True)\n",
    "    print(train_data)\n",
    "    \n",
    "    tk = hdfslogs.tk    \n",
    "    vocab_size = len(tk.word_index)\n",
    "    print(f'vocab_size: {vocab_size}')\n",
    "    char_onehot = vocab_size\n",
    "    \n",
    "    embedding_weights = []\n",
    "    embedding_weights.append(np.zeros(vocab_size))\n",
    "    for char, i in tk.word_index.items(): # from 1 to 51\n",
    "        onehot = np.zeros(vocab_size)\n",
    "        onehot[i-1] = 1\n",
    "        embedding_weights.append(onehot)\n",
    "    embedding_weights = np.array(embedding_weights)\n",
    "    \n",
    "    input_size = [x_train.shape[1], x_train.shape[2]]\n",
    "    embedding_size = vocab_size\n",
    "\n",
    "    embedding_layer = tf.keras.layers.Embedding(vocab_size+1,\n",
    "                                                embedding_size,\n",
    "                                                input_length=input_size,\n",
    "                                                weights = [embedding_weights])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    inputs = tf.keras.layers.Input(batch_shape=(B, x_train.shape[1], x_train.shape[2]), dtype='float64' )\n",
    "    x = tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
    "                                    output_dim=embedding_size,\n",
    "                                    input_length=x_train.shape[2],\n",
    "                                    weights = [embedding_weights],\n",
    "                                    )(inputs)\n",
    "    for _ in range(conv1d_set1):\n",
    "        x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "    if maxpool_1:\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(1, x_train.shape[2]))(x)\n",
    "        x = tf.reshape(x, (B, x_train.shape[1], filters))        \n",
    "        for _ in range(conv1d_set2):\n",
    "            x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "        x = tf.keras.layers.MaxPooling1D(pool_size=(x_train.shape[1]) )(x)    \n",
    "    if not maxpool_1:\n",
    "        x = tf.keras.layers.Flatten()(x)       \n",
    "    x = tf.keras.layers.Dense(dense_neurons)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    print(model.summary())\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(train_data, epochs=epochs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3889496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so eve with 4000 ablation which means 4000 positive and 400 negative sequences we have achived 99.36%\n",
    "# Epoch 16/16\n",
    "# 32/32 [==============================] - 16s 514ms/step - loss: 0.5070 - accuracy: 0.9936\n",
    "# now it is time to include validation set as well, for which we will create a new notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8096b9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 4000\n",
      "4000 12838\n",
      "train_test_data done: 0.015006542205810547\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.474947214126587\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((250, 32, 64), (250,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(250, 32, 64)]           0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (250, 32, 64, 42)         1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (250, 32, 64, 64)         8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (250, 32, 64, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (250, 32, 64, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (250, 32, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(250, 32, 64)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (250, 32, 64)             12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (250, 32, 64)             12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (250, 32, 64)             12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (250, 1, 64)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (250, 1, 2048)            133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (250, 1, 1)               2049      \n",
      "=================================================================\n",
      "Total params: 206,863\n",
      "Trainable params: 206,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/16\n",
      "32/32 [==============================] - 16s 514ms/step - loss: 0.6163 - accuracy: 0.7171\n",
      "Epoch 2/16\n",
      "32/32 [==============================] - 16s 512ms/step - loss: 0.6018 - accuracy: 0.7419\n",
      "Epoch 3/16\n",
      "32/32 [==============================] - 16s 515ms/step - loss: 0.5850 - accuracy: 0.7919\n",
      "Epoch 4/16\n",
      "32/32 [==============================] - 17s 521ms/step - loss: 0.5678 - accuracy: 0.8515\n",
      "Epoch 5/16\n",
      "32/32 [==============================] - 16s 514ms/step - loss: 0.5754 - accuracy: 0.8196\n",
      "Epoch 6/16\n",
      "32/32 [==============================] - 17s 530ms/step - loss: 0.5837 - accuracy: 0.7908\n",
      "Epoch 7/16\n",
      "32/32 [==============================] - 17s 529ms/step - loss: 0.5700 - accuracy: 0.8320\n",
      "Epoch 8/16\n",
      "32/32 [==============================] - 18s 569ms/step - loss: 0.5208 - accuracy: 0.9619\n",
      "Epoch 9/16\n",
      "32/32 [==============================] - 17s 516ms/step - loss: 0.5087 - accuracy: 0.9905\n",
      "Epoch 10/16\n",
      "32/32 [==============================] - 17s 521ms/step - loss: 0.5074 - accuracy: 0.9931\n",
      "Epoch 11/16\n",
      "32/32 [==============================] - 17s 520ms/step - loss: 0.5073 - accuracy: 0.9933\n",
      "Epoch 12/16\n",
      "32/32 [==============================] - 16s 514ms/step - loss: 0.5071 - accuracy: 0.9935\n",
      "Epoch 13/16\n",
      "32/32 [==============================] - 16s 515ms/step - loss: 0.5071 - accuracy: 0.9936\n",
      "Epoch 14/16\n",
      "32/32 [==============================] - 17s 519ms/step - loss: 0.5070 - accuracy: 0.9936\n",
      "Epoch 15/16\n",
      "32/32 [==============================] - 17s 517ms/step - loss: 0.5070 - accuracy: 0.9936\n",
      "Epoch 16/16\n",
      "32/32 [==============================] - 16s 514ms/step - loss: 0.5070 - accuracy: 0.9936\n"
     ]
    }
   ],
   "source": [
    "# That was certainly encouraging result \n",
    "# We got 99.9 %  accuracy  - Epoch 16/16\n",
    "# epoch 11/16\n",
    "# 16/16 [==============================] - 8s 513ms/step - loss: 0.5073 - accuracy: 0.9920\n",
    "# Epoch 12/16\n",
    "# 16/16 [==============================] - 8s 521ms/step - loss: 0.5044 - accuracy: 0.9980\n",
    "# Epoch 13/16\n",
    "# 16/16 [==============================] - 8s 512ms/step - loss: 0.5040 - accuracy: 0.9985\n",
    "# Epoch 14/16\n",
    "# 16/16 [==============================] - 8s 513ms/step - loss: 0.5038 - accuracy: 0.9990\n",
    "# Epoch 15/16\n",
    "# 16/16 [==============================] - 8s 510ms/step - loss: 0.5038 - accuracy: 0.9990\n",
    "# 16/16 [==============================] - 8s 508ms/step - loss: 0.5038 - accuracy: 0.9990\n",
    "# #################remeber the setting ####################\n",
    "# test_model(ablation=2000, B=250, kernel_size=3, epochs=16, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )\n",
    "# now we will give more data\n",
    "test_model(ablation=4000, B=250, kernel_size=3, epochs=16, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "044bcc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 2000\n",
      "2000 14838\n",
      "train_test_data done: 0.015001535415649414\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.868514776229858\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((250, 32, 64), (250,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(250, 32, 64)]           0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (250, 32, 64, 42)         1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (250, 32, 64, 64)         8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (250, 32, 64, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (250, 32, 64, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (250, 32, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(250, 32, 64)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (250, 32, 64)             12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (250, 32, 64)             12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (250, 32, 64)             12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (250, 1, 64)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (250, 1, 2048)            133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (250, 1, 1)               2049      \n",
      "=================================================================\n",
      "Total params: 206,863\n",
      "Trainable params: 206,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/16\n",
      "16/16 [==============================] - 9s 544ms/step - loss: 0.6494 - accuracy: 0.6285\n",
      "Epoch 2/16\n",
      "16/16 [==============================] - 8s 523ms/step - loss: 0.5830 - accuracy: 0.8005\n",
      "Epoch 3/16\n",
      "16/16 [==============================] - 8s 523ms/step - loss: 0.5849 - accuracy: 0.7930\n",
      "Epoch 4/16\n",
      "16/16 [==============================] - 8s 514ms/step - loss: 0.5826 - accuracy: 0.7950\n",
      "Epoch 5/16\n",
      "16/16 [==============================] - 8s 524ms/step - loss: 0.5783 - accuracy: 0.8098\n",
      "Epoch 6/16\n",
      "16/16 [==============================] - 8s 511ms/step - loss: 0.5684 - accuracy: 0.8410\n",
      "Epoch 7/16\n",
      "16/16 [==============================] - 8s 513ms/step - loss: 0.5807 - accuracy: 0.8020\n",
      "Epoch 8/16\n",
      "16/16 [==============================] - 8s 516ms/step - loss: 0.5754 - accuracy: 0.8133\n",
      "Epoch 9/16\n",
      "16/16 [==============================] - 8s 514ms/step - loss: 0.5516 - accuracy: 0.8852\n",
      "Epoch 10/16\n",
      "16/16 [==============================] - 8s 519ms/step - loss: 0.5207 - accuracy: 0.9567\n",
      "Epoch 11/16\n",
      "16/16 [==============================] - 8s 513ms/step - loss: 0.5073 - accuracy: 0.9920\n",
      "Epoch 12/16\n",
      "16/16 [==============================] - 8s 521ms/step - loss: 0.5044 - accuracy: 0.9980\n",
      "Epoch 13/16\n",
      "16/16 [==============================] - 8s 512ms/step - loss: 0.5040 - accuracy: 0.9985\n",
      "Epoch 14/16\n",
      "16/16 [==============================] - 8s 513ms/step - loss: 0.5038 - accuracy: 0.9990\n",
      "Epoch 15/16\n",
      "16/16 [==============================] - 8s 510ms/step - loss: 0.5038 - accuracy: 0.9990\n",
      "Epoch 16/16\n",
      "16/16 [==============================] - 8s 508ms/step - loss: 0.5038 - accuracy: 0.9990\n"
     ]
    }
   ],
   "source": [
    "# it helped , accuracy touched 80% . the best score was 82% . LEt us increase the data further\n",
    "test_model(ablation=2000, B=250, kernel_size=3, epochs=16, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce411efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 1000\n",
      "1000 15838\n",
      "train_test_data done: 0.015004158020019531\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 7.093010902404785\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((250, 32, 64), (250,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(250, 32, 64)]           0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (250, 32, 64, 42)         1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (250, 32, 64, 64)         8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (250, 32, 64, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (250, 32, 64, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (250, 32, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(250, 32, 64)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (250, 32, 64)             12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (250, 32, 64)             12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (250, 32, 64)             12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (250, 1, 64)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (250, 1, 2048)            133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (250, 1, 1)               2049      \n",
      "=================================================================\n",
      "Total params: 206,863\n",
      "Trainable params: 206,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/16\n",
      "8/8 [==============================] - 4s 522ms/step - loss: 0.6814 - accuracy: 0.5155\n",
      "Epoch 2/16\n",
      "8/8 [==============================] - 4s 471ms/step - loss: 0.6144 - accuracy: 0.7380\n",
      "Epoch 3/16\n",
      "8/8 [==============================] - 4s 476ms/step - loss: 0.5867 - accuracy: 0.7935\n",
      "Epoch 4/16\n",
      "8/8 [==============================] - 4s 482ms/step - loss: 0.5978 - accuracy: 0.7535\n",
      "Epoch 5/16\n",
      "8/8 [==============================] - 4s 481ms/step - loss: 0.5894 - accuracy: 0.7740\n",
      "Epoch 6/16\n",
      "8/8 [==============================] - 4s 477ms/step - loss: 0.5818 - accuracy: 0.7990\n",
      "Epoch 7/16\n",
      "8/8 [==============================] - 4s 484ms/step - loss: 0.5836 - accuracy: 0.8095\n",
      "Epoch 8/16\n",
      "8/8 [==============================] - 4s 478ms/step - loss: 0.5880 - accuracy: 0.7855\n",
      "Epoch 9/16\n",
      "8/8 [==============================] - 4s 477ms/step - loss: 0.5819 - accuracy: 0.7955\n",
      "Epoch 10/16\n",
      "8/8 [==============================] - 4s 477ms/step - loss: 0.5811 - accuracy: 0.7980\n",
      "Epoch 11/16\n",
      "8/8 [==============================] - 4s 478ms/step - loss: 0.5811 - accuracy: 0.7995\n",
      "Epoch 12/16\n",
      "8/8 [==============================] - 4s 490ms/step - loss: 0.5818 - accuracy: 0.7960\n",
      "Epoch 13/16\n",
      "8/8 [==============================] - 4s 481ms/step - loss: 0.5814 - accuracy: 0.7975\n",
      "Epoch 14/16\n",
      "8/8 [==============================] - 4s 466ms/step - loss: 0.5806 - accuracy: 0.7990\n",
      "Epoch 15/16\n",
      "8/8 [==============================] - 4s 472ms/step - loss: 0.5803 - accuracy: 0.7995\n",
      "Epoch 16/16\n",
      "8/8 [==============================] - 4s 479ms/step - loss: 0.5803 - accuracy: 0.8010\n"
     ]
    }
   ],
   "source": [
    "# slight improvement, earlier we observed data to batch ratio is actually 4:1 ,\n",
    "# let us see if the batch size 250 helps \n",
    "test_model(ablation=1000, B=250, kernel_size=3, epochs=16, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6d6536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 1000\n",
      "1000 15838\n",
      "train_test_data done: 0.015027999877929688\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.854597568511963\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((40, 32, 64), (40,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(40, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (40, 32, 64, 42)          1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (40, 32, 64, 64)          8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (40, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (40, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (40, 32, 1, 64)           0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(40, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (40, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (40, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (40, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (40, 1, 64)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (40, 1, 2048)             133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (40, 1, 1)                2049      \n",
      "=================================================================\n",
      "Total params: 206,863\n",
      "Trainable params: 206,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/16\n",
      "50/50 [==============================] - 7s 132ms/step - loss: 0.6149 - accuracy: 0.7165\n",
      "Epoch 2/16\n",
      "50/50 [==============================] - 6s 128ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 3/16\n",
      "50/50 [==============================] - 6s 126ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 4/16\n",
      "50/50 [==============================] - 6s 130ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 5/16\n",
      "50/50 [==============================] - 7s 136ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 6/16\n",
      "50/50 [==============================] - 7s 135ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 7/16\n",
      "50/50 [==============================] - 6s 127ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 8/16\n",
      "50/50 [==============================] - 6s 124ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 9/16\n",
      "50/50 [==============================] - 7s 147ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 10/16\n",
      "50/50 [==============================] - 7s 132ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 11/16\n",
      "50/50 [==============================] - 6s 125ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 12/16\n",
      "50/50 [==============================] - 7s 135ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 13/16\n",
      "50/50 [==============================] - 7s 133ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 14/16\n",
      "50/50 [==============================] - 6s 123ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 15/16\n",
      "50/50 [==============================] - 7s 139ms/step - loss: 0.5967 - accuracy: 0.7540\n",
      "Epoch 16/16\n",
      "50/50 [==============================] - 6s 130ms/step - loss: 0.5967 - accuracy: 0.7540\n"
     ]
    }
   ],
   "source": [
    "# no improvment even at batch size 40 , let us increase the data further\n",
    "test_model(ablation=1000, B=40, kernel_size=3, epochs=16, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa13da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 160\n",
      "160 16678\n",
      "train_test_data done: 0.016001462936401367\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.859640836715698\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((40, 32, 64), (40,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(40, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (40, 32, 64, 42)          1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (40, 32, 64, 64)          8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (40, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (40, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (40, 32, 1, 64)           0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(40, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (40, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (40, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (40, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (40, 1, 64)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (40, 1, 2048)             133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (40, 1, 1)                2049      \n",
      "=================================================================\n",
      "Total params: 206,863\n",
      "Trainable params: 206,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/16\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.6784 - accuracy: 0.5219\n",
      "Epoch 2/16\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.6271 - accuracy: 0.7281\n",
      "Epoch 3/16\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.6083 - accuracy: 0.7406\n",
      "Epoch 4/16\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.6101 - accuracy: 0.7281\n",
      "Epoch 5/16\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.6067 - accuracy: 0.7281\n",
      "Epoch 6/16\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 7/16\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 8/16\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 9/16\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 10/16\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 11/16\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 12/16\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 13/16\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 14/16\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 15/16\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 16/16\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.6065 - accuracy: 0.7281\n"
     ]
    }
   ],
   "source": [
    "# dropped to 72.8% , let us increase the batch size\n",
    "test_model(ablation=160, B=40, kernel_size=3, epochs=16, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c49d5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 160\n",
      "160 16678\n",
      "train_test_data done: 0.015029430389404297\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.874576091766357\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((20, 32, 64), (20,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(20, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (20, 32, 64, 42)          1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (20, 32, 64, 64)          8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (20, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (20, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (20, 32, 1, 64)           0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(20, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (20, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (20, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (20, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (20, 1, 64)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (20, 1, 2048)             133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (20, 1, 1)                2049      \n",
      "=================================================================\n",
      "Total params: 206,863\n",
      "Trainable params: 206,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/16\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.6582 - accuracy: 0.6125\n",
      "Epoch 2/16\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 0.6110 - accuracy: 0.7281\n",
      "Epoch 3/16\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 0.6066 - accuracy: 0.7281\n",
      "Epoch 4/16\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 0.6064 - accuracy: 0.7281\n",
      "Epoch 5/16\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 6/16\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 7/16\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 8/16\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.6182 - accuracy: 0.7094\n",
      "Epoch 9/16\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.6069 - accuracy: 0.7281\n",
      "Epoch 10/16\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 11/16\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 12/16\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 13/16\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 14/16\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 15/16\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.6065 - accuracy: 0.7281\n",
      "Epoch 16/16\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 0.6065 - accuracy: 0.7281\n"
     ]
    }
   ],
   "source": [
    "# loss: 0.5804 - accuracy: 0.8250\n",
    "# loss: 0.5862 - accuracy: 0.7937\n",
    "# So increasing data point and increasing batch_size both is helping \n",
    "#we got 79% at the 16th epochs where as at the 10th epochs it touched 82%\n",
    "# Let us increase data point further\n",
    "test_model(ablation=160, B=20, kernel_size=3, epochs=16, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38eaa4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 80\n",
      "80 16758\n",
      "train_test_data done: 0.015012025833129883\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.98826789855957\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((20, 32, 64), (20,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(20, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (20, 32, 64, 42)          1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (20, 32, 64, 64)          8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (20, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (20, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (20, 32, 1, 64)           0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(20, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (20, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (20, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (20, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (20, 1, 64)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (20, 1, 2048)             133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (20, 1, 1)                2049      \n",
      "=================================================================\n",
      "Total params: 206,863\n",
      "Trainable params: 206,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/16\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.6936 - accuracy: 0.5063\n",
      "Epoch 2/16\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.6567 - accuracy: 0.6062\n",
      "Epoch 3/16\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.6159 - accuracy: 0.7188\n",
      "Epoch 4/16\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.5981 - accuracy: 0.7563\n",
      "Epoch 5/16\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.6039 - accuracy: 0.7437\n",
      "Epoch 6/16\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.6077 - accuracy: 0.7312\n",
      "Epoch 7/16\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.6031 - accuracy: 0.7375\n",
      "Epoch 8/16\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.6026 - accuracy: 0.7375\n",
      "Epoch 9/16\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.5920 - accuracy: 0.7750\n",
      "Epoch 10/16\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.5804 - accuracy: 0.8250\n",
      "Epoch 11/16\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.5946 - accuracy: 0.7625\n",
      "Epoch 12/16\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.5950 - accuracy: 0.7625\n",
      "Epoch 13/16\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6057 - accuracy: 0.7312\n",
      "Epoch 14/16\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.5996 - accuracy: 0.7437\n",
      "Epoch 15/16\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.5929 - accuracy: 0.7688\n",
      "Epoch 16/16\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.5862 - accuracy: 0.7937\n"
     ]
    }
   ],
   "source": [
    "# no more epochs did not help , let us increase the bach size\n",
    "test_model(ablation=80, B=20, kernel_size=3, epochs=16, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7852ea9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 80\n",
      "80 16758\n",
      "train_test_data done: 0.015974998474121094\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.878019571304321\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((10, 32, 64), (10,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(10, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (10, 32, 64, 42)          1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (10, 32, 64, 64)          8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (10, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (10, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (10, 32, 1, 64)           0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(10, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (10, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (10, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (10, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (10, 1, 64)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (10, 1, 2048)             133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (10, 1, 1)                2049      \n",
      "=================================================================\n",
      "Total params: 206,863\n",
      "Trainable params: 206,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/16\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.6936 - accuracy: 0.4812\n",
      "Epoch 2/16\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.6319 - accuracy: 0.6938\n",
      "Epoch 3/16\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.6191 - accuracy: 0.7063\n",
      "Epoch 4/16\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.6148 - accuracy: 0.7063\n",
      "Epoch 5/16\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.6129 - accuracy: 0.7125\n",
      "Epoch 6/16\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.6731 - accuracy: 0.6687\n",
      "Epoch 7/16\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.8133 - accuracy: 0.5000\n",
      "Epoch 8/16\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.8133 - accuracy: 0.5000\n",
      "Epoch 9/16\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.8133 - accuracy: 0.5000\n",
      "Epoch 10/16\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.8133 - accuracy: 0.5000\n",
      "Epoch 11/16\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.8133 - accuracy: 0.5000\n",
      "Epoch 12/16\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.8133 - accuracy: 0.5000\n",
      "Epoch 13/16\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.8133 - accuracy: 0.5000\n",
      "Epoch 14/16\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.8133 - accuracy: 0.5000\n",
      "Epoch 15/16\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.8133 - accuracy: 0.5000\n",
      "Epoch 16/16\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.8133 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# with ablation 80 , accuracy dropped to 50% , althoough it touched 71.25\n",
    "# 0.6129 - accuracy: 0.7125\n",
    "# 0.8133 - accuracy: 0.5000\n",
    "# may be more epochs wil help ?\n",
    "test_model(ablation=80, B=10, kernel_size=3, epochs=16, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2ad9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 80\n",
      "80 16758\n",
      "train_test_data done: 0.015000343322753906\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.838227033615112\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((10, 32, 64), (10,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(10, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (10, 32, 64, 42)          1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (10, 32, 64, 64)          8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (10, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (10, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (10, 32, 1, 64)           0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(10, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (10, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (10, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (10, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (10, 1, 64)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (10, 1, 2048)             133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (10, 1, 1)                2049      \n",
      "=================================================================\n",
      "Total params: 206,863\n",
      "Trainable params: 206,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/8\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.6936 - accuracy: 0.4812\n",
      "Epoch 2/8\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.6319 - accuracy: 0.6938\n",
      "Epoch 3/8\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.6191 - accuracy: 0.7063\n",
      "Epoch 4/8\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.6148 - accuracy: 0.7063\n",
      "Epoch 5/8\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.6129 - accuracy: 0.7125\n",
      "Epoch 6/8\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.6731 - accuracy: 0.6687\n",
      "Epoch 7/8\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.8133 - accuracy: 0.5000\n",
      "Epoch 8/8\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.8133 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# improved by 3 % - loss: 0.5840 - accuracy: 0.7875 - test_model(ablation=40, B=10, kernel_size=3, epochs=8, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )\n",
    "# when data is doubled 20 to 40  but batch remined same as 5 accuracy drooped by 3% \n",
    "# However when batch size  doubled from 5 to 10 accuracy improved by 3%  from the best score\n",
    "# Let us double the data again\n",
    "test_model(ablation=80, B=10, kernel_size=3, epochs=8, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc82807f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 40\n",
      "40 16798\n",
      "train_test_data done: 0.01399683952331543\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.6837499141693115\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((10, 32, 64), (10,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(10, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (10, 32, 64, 42)          1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (10, 32, 64, 64)          8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (10, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (10, 32, 64, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (10, 32, 1, 64)           0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(10, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (10, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (10, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (10, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (10, 1, 64)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (10, 1, 2048)             133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (10, 1, 1)                2049      \n",
      "=================================================================\n",
      "Total params: 206,863\n",
      "Trainable params: 206,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/8\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.7406 - accuracy: 0.4125\n",
      "Epoch 2/8\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.6819 - accuracy: 0.5000\n",
      "Epoch 3/8\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 0.6503 - accuracy: 0.6375\n",
      "Epoch 4/8\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.5979 - accuracy: 0.7500\n",
      "Epoch 5/8\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.6548 - accuracy: 0.6750\n",
      "Epoch 6/8\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.5998 - accuracy: 0.7625\n",
      "Epoch 7/8\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.5899 - accuracy: 0.7750\n",
      "Epoch 8/8\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.5840 - accuracy: 0.7875\n"
     ]
    }
   ],
   "source": [
    "# not improving ,3% accuracy dropped. Increase the batch size \n",
    "test_model(ablation=40, B=10, kernel_size=3, epochs=8, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "548c436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 40\n",
      "40 16798\n",
      "train_test_data done: 0.015001535415649414\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.859712600708008\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (5, 32, 64, 64)           12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (5, 32, 64, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (5, 32, 1, 64)            0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (5, 32, 64)               12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (5, 32, 64)               12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (5, 32, 64)               12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (5, 1, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 1, 2048)              133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 206,863\n",
      "Trainable params: 206,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/8\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7531 - accuracy: 0.4250\n",
      "Epoch 2/8\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6606 - accuracy: 0.6000\n",
      "Epoch 3/8\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6122 - accuracy: 0.7250\n",
      "Epoch 4/8\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6080 - accuracy: 0.7250\n",
      "Epoch 5/8\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6077 - accuracy: 0.7250\n",
      "Epoch 6/8\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.6077 - accuracy: 0.7250\n",
      "Epoch 7/8\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.6077 - accuracy: 0.7250\n",
      "Epoch 8/8\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6077 - accuracy: 0.7250\n"
     ]
    }
   ],
   "source": [
    "# not improving , now let us double the data\n",
    "test_model(ablation=40, B=5, kernel_size=3, epochs=8, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a1cb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.016002416610717773\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.773735284805298\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (5, 32, 64, 64)           12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (5, 32, 64, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (5, 32, 1, 64)            0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (5, 32, 64)               12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (5, 32, 64)               12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (5, 32, 64)               12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (5, 1, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 1, 2048)              133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 206,863\n",
      "Trainable params: 206,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/12\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6926 - accuracy: 0.5500\n",
      "Epoch 2/12\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.6849 - accuracy: 0.5000\n",
      "Epoch 3/12\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.6642 - accuracy: 0.5750\n",
      "Epoch 4/12\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6622 - accuracy: 0.5750\n",
      "Epoch 5/12\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6397 - accuracy: 0.6500\n",
      "Epoch 6/12\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6128 - accuracy: 0.7250\n",
      "Epoch 7/12\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5996 - accuracy: 0.7500\n",
      "Epoch 8/12\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5987 - accuracy: 0.7500\n",
      "Epoch 9/12\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5986 - accuracy: 0.7500\n",
      "Epoch 10/12\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5983 - accuracy: 0.7500\n",
      "Epoch 11/12\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5983 - accuracy: 0.7500\n",
      "Epoch 12/12\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5983 - accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# increasing the epochs is not helping, let us increase the conv layer 1 more for each set1 and set 2\n",
    "test_model(ablation=20, B=5, kernel_size=3, epochs=12, dense_neurons=2048, conv1d_set1=3,conv1d_set2=3, maxpool_1=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb90c983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.014966249465942383\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.63904070854187\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (5, 32, 64, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (5, 32, 1, 64)            0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (5, 32, 64)               12352     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (5, 32, 64)               12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (5, 1, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 1, 2048)              133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 182,159\n",
      "Trainable params: 182,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/12\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6918 - accuracy: 0.5000\n",
      "Epoch 2/12\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5000\n",
      "Epoch 3/12\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6360 - accuracy: 0.6500\n",
      "Epoch 4/12\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.6073 - accuracy: 0.7500\n",
      "Epoch 5/12\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5985 - accuracy: 0.7500\n",
      "Epoch 6/12\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5922 - accuracy: 0.7500\n",
      "Epoch 7/12\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6372 - accuracy: 0.6750\n",
      "Epoch 8/12\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5996 - accuracy: 0.7500\n",
      "Epoch 9/12\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5983 - accuracy: 0.7500\n",
      "Epoch 10/12\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5982 - accuracy: 0.7500\n",
      "Epoch 11/12\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5978 - accuracy: 0.7500\n",
      "Epoch 12/12\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6486 - accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "# so hierarchical conv improved the best result by 5% - 11ms/step - loss: 0.5922 - accuracy: 0.7500\n",
    "# This is the setting - test_model(ablation=20, B=5, kernel_size=3, epochs=6, dense_neurons=2048, conv1d_set1=2,conv1d_set2=2, maxpool_1=True )\n",
    "# let us now increase epochs \n",
    "test_model(ablation=20, B=5, kernel_size=3, epochs=12, dense_neurons=2048, conv1d_set1=2,conv1d_set2=2, maxpool_1=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da09ad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.014998912811279297\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.645535230636597\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (5, 32, 64, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (5, 32, 1, 64)            0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (5, 32, 64)               12352     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (5, 32, 64)               12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (5, 1, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 1, 2048)              133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 182,159\n",
      "Trainable params: 182,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6918 - accuracy: 0.5000\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6817 - accuracy: 0.5000\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6360 - accuracy: 0.6500\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6073 - accuracy: 0.7500\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5985 - accuracy: 0.7500\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5922 - accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# increasing the conv1d_set did not help . lets include a maxpooling\n",
    "test_model(ablation=20, B=5, kernel_size=3, epochs=6, dense_neurons=2048, conv1d_set1=2,conv1d_set2=2, maxpool_1=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03c718d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.013999700546264648\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.768073558807373\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           8128      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (5, 32, 64, 64)           12352     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (5, 131072)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 2048)                 268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1)                    2049      \n",
      "=================================================================\n",
      "Total params: 268,461,839\n",
      "Trainable params: 268,461,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 6s 759ms/step - loss: 0.6651 - accuracy: 0.5750\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 6s 751ms/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 6s 767ms/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 6s 744ms/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 6s 759ms/step - loss: 0.6362 - accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "# yes ,, the setting produced same result twice - test_model(ablation=20, B=5, kernel_size=3, epochs=6, dense_neurons= 2048 )\n",
    "# lets increase one more layer of conv1d\n",
    "test_model(ablation=20, B=5, kernel_size=3, epochs=6, dense_neurons=2048, conv1d_set1=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dd15d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.016002178192138672\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 7.299583911895752\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (5, 32, 64, 64)           8128      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (5, 131072)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (5, 2048)                 268437504 \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (5, 1)                    2049      \n",
      "=================================================================\n",
      "Total params: 268,449,487\n",
      "Trainable params: 268,449,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 7s 937ms/step - loss: 0.6635 - accuracy: 0.6250\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 8s 938ms/step - loss: 0.6266 - accuracy: 0.6750\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 8s 947ms/step - loss: 0.6326 - accuracy: 0.6750\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 8s 947ms/step - loss: 0.6172 - accuracy: 0.7000\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 8s 943ms/step - loss: 0.6172 - accuracy: 0.7000\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 8s 992ms/step - loss: 0.6172 - accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "# decreasing not helping , keeping it same as the best just to check consistency\n",
    "test_model(ablation=20, B=5, kernel_size=3, epochs=6, dense_neurons= 2048 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b10bc1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.016967058181762695\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.756180047988892\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           8128      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (5, 131072)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 1024)                 134218752 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1)                    1025      \n",
      "=================================================================\n",
      "Total params: 134,229,711\n",
      "Trainable params: 134,229,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 3s 365ms/step - loss: 0.6661 - accuracy: 0.5500\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 3s 371ms/step - loss: 0.6267 - accuracy: 0.6750\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 0.6304 - accuracy: 0.6750\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 3s 343ms/step - loss: 0.6267 - accuracy: 0.6750\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 3s 352ms/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 3s 353ms/step - loss: 0.6362 - accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "# increasing the dense_neuron did not help, now reduce \n",
    "test_model(ablation=20, B=5, kernel_size=3, epochs=6, dense_neurons= 1024 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d91c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.01500082015991211\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.808279752731323\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           8128      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (5, 131072)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 4098)                 537137154 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1)                    4099      \n",
      "=================================================================\n",
      "Total params: 537,151,187\n",
      "Trainable params: 537,151,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6606 - accuracy: 0.6000\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6362 - accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "# increainsg the filers , kernel size not helping. lets try with dense neuron wuth the best result so far test_model(ablation=20, B=5, kernel_size=3, epochs=6)\n",
    "test_model(ablation=20, B=5, kernel_size=3, epochs=6, dense_neurons= 4098 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f7f831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.015002012252807617\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.6594531536102295\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 82)           10414     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (5, 167936)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 2048)                 343934976 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1)                    2049      \n",
      "=================================================================\n",
      "Total params: 343,949,245\n",
      "Trainable params: 343,949,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.6643 - accuracy: 0.5500\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.6267 - accuracy: 0.6750\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.6267 - accuracy: 0.6750\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.6267 - accuracy: 0.6750\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.6267 - accuracy: 0.6750\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.6267 - accuracy: 0.6750\n"
     ]
    }
   ],
   "source": [
    "# so far best score loss: 0.6172 - accuracy: 0.7000 is with test_model(ablation=20, B=5, kernel_size=3, epochs=6)\n",
    "test_model(ablation=20, B=5, kernel_size=3, epochs=6, filters=82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a7a286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.015002727508544922\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.7468507289886475\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 128)          16256     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (5, 262144)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 2048)                 536872960 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1)                    2049      \n",
      "=================================================================\n",
      "Total params: 536,893,071\n",
      "Trainable params: 536,893,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6624 - accuracy: 0.5750\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6362 - accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "test_model(ablation=20, B=5, kernel_size=3, epochs=6, filters=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b0e3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.013999462127685547\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.646817684173584\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           8128      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (5, 131072)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 2048)                 268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1)                    2049      \n",
      "=================================================================\n",
      "Total params: 268,449,487\n",
      "Trainable params: 268,449,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/12\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 0.6635 - accuracy: 0.6250\n",
      "Epoch 2/12\n",
      "8/8 [==============================] - 6s 747ms/step - loss: 0.6266 - accuracy: 0.6750\n",
      "Epoch 3/12\n",
      "8/8 [==============================] - 6s 747ms/step - loss: 0.6326 - accuracy: 0.6750\n",
      "Epoch 4/12\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.6172 - accuracy: 0.7000\n",
      "Epoch 5/12\n",
      "8/8 [==============================] - 6s 755ms/step - loss: 0.6172 - accuracy: 0.7000\n",
      "Epoch 6/12\n",
      "8/8 [==============================] - 6s 745ms/step - loss: 0.6172 - accuracy: 0.7000\n",
      "Epoch 7/12\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.6172 - accuracy: 0.7000\n",
      "Epoch 8/12\n",
      "8/8 [==============================] - 6s 739ms/step - loss: 0.6172 - accuracy: 0.7000\n",
      "Epoch 9/12\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.6172 - accuracy: 0.7000\n",
      "Epoch 10/12\n",
      "8/8 [==============================] - 6s 746ms/step - loss: 0.6172 - accuracy: 0.7000\n",
      "Epoch 11/12\n",
      "8/8 [==============================] - 6s 746ms/step - loss: 0.6172 - accuracy: 0.7000\n",
      "Epoch 12/12\n",
      "8/8 [==============================] - 6s 749ms/step - loss: 0.6172 - accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "test_model(ablation=20, B=5, kernel_size=3, epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "258f4cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.015002012252807617\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.641399621963501\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           8128      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (5, 131072)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 2048)                 268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1)                    2049      \n",
      "=================================================================\n",
      "Total params: 268,449,487\n",
      "Trainable params: 268,449,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 6s 742ms/step - loss: 0.6635 - accuracy: 0.6250\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.6266 - accuracy: 0.6750\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 6s 745ms/step - loss: 0.6326 - accuracy: 0.6750\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 6s 749ms/step - loss: 0.6172 - accuracy: 0.7000\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 6s 747ms/step - loss: 0.6172 - accuracy: 0.7000\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.6172 - accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "test_model(ablation=20, B=5, kernel_size=3, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea8800d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.015009403228759766\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.722247838973999\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           21568     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (5, 131072)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 2048)                 268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1)                    2049      \n",
      "=================================================================\n",
      "Total params: 268,462,927\n",
      "Trainable params: 268,462,927\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 6s 746ms/step - loss: 0.6647 - accuracy: 0.5250\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 6s 746ms/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 6s 753ms/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 6s 756ms/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 6s 739ms/step - loss: 0.6362 - accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "test_model(ablation=20, B=5, kernel_size=8, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c07f342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.0149993896484375\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.682743549346924\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           21568     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (5, 131072)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 2048)                 268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1)                    2049      \n",
      "=================================================================\n",
      "Total params: 268,462,927\n",
      "Trainable params: 268,462,927\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 6s 812ms/step - loss: 0.6647 - accuracy: 0.5250\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 7s 813ms/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.6362 - accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "test_model(ablation=20, B=5, kernel_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30efc605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.015000104904174805\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.96438455581665\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           10816     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (5, 131072)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 2048)                 268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1)                    2049      \n",
      "=================================================================\n",
      "Total params: 268,452,175\n",
      "Trainable params: 268,452,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 6s 765ms/step - loss: 0.6611 - accuracy: 0.6000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 7s 822ms/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 6s 766ms/step - loss: 0.6362 - accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "test_model(ablation=20, B=5, kernel_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d00f27bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.015002965927124023\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.9465086460113525\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           5440      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (5, 131072)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 2048)                 268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1)                    2049      \n",
      "=================================================================\n",
      "Total params: 268,446,799\n",
      "Trainable params: 268,446,799\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 6s 750ms/step - loss: 0.6615 - accuracy: 0.6000\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 6s 766ms/step - loss: 0.6362 - accuracy: 0.6500\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 0.6362 - accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "test_model(ablation=20, B=5, kernel_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ee1e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.014000654220581055\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 7.033799171447754\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((5, 32, 64), (5,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(5, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (5, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (5, 32, 64, 64)           8128      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (5, 131072)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (5, 2048)                 268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (5, 1)                    2049      \n",
      "=================================================================\n",
      "Total params: 268,449,487\n",
      "Trainable params: 268,449,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 7s 882ms/step - loss: 0.6635 - accuracy: 0.6250\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 7s 864ms/step - loss: 0.6266 - accuracy: 0.6750\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 0.6326 - accuracy: 0.6750\n"
     ]
    }
   ],
   "source": [
    "test_model(ablation=20, B=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8394d79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 6\n",
      "6 16832\n",
      "train_test_data done: 0.015001296997070312\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.7540202140808105\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((1, 32, 64), (1,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(1, 32, 64)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (1, 32, 64, 42)           1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (1, 32, 64, 64)           8128      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (1, 131072)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (1, 2048)                 268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, 1)                    2049      \n",
      "=================================================================\n",
      "Total params: 268,449,487\n",
      "Trainable params: 268,449,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "12/12 [==============================] - 9s 775ms/step - loss: 0.8290 - accuracy: 0.4167\n",
      "Epoch 2/3\n",
      "12/12 [==============================] - 9s 739ms/step - loss: 0.8133 - accuracy: 0.5000\n",
      "Epoch 3/3\n",
      "12/12 [==============================] - 9s 732ms/step - loss: 0.8133 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "test_model(ablation=6, B=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b0e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca6072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 100\n",
      "100 16738\n",
      "train_test_data done: 0.014999866485595703\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.796327829360962\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((10, 32, 64), (10,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(10, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (10, 32, 64, 42)          1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (10, 32, 64, 64)          8128      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (10, 131072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (10, 2048)                268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (10, 1)                   2049      \n",
      "=================================================================\n",
      "Total params: 268,449,487\n",
      "Trainable params: 268,449,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "20/20 [==============================] - 17s 870ms/step - loss: 0.6924 - accuracy: 0.5350\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 17s 830ms/step - loss: 0.6837 - accuracy: 0.5500\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 17s 832ms/step - loss: 0.6654 - accuracy: 0.5750\n"
     ]
    }
   ],
   "source": [
    "test_model(ablation=100, B=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d345f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c87d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 20\n",
      "20 16818\n",
      "train_test_data done: 0.015000343322753906\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 6.722995281219482\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((10, 32, 64), (10,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(10, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (10, 32, 64, 42)          1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (10, 32, 64, 64)          8128      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (10, 131072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (10, 2048)                268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (10, 1)                   2049      \n",
      "=================================================================\n",
      "Total params: 268,449,487\n",
      "Trainable params: 268,449,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.6987 - accuracy: 0.5750\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.6457 - accuracy: 0.6250\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.6457 - accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "test_model(ablation=20, B=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef2f8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252cbed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca3e32a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ablation data: 2000\n",
      "2000 14838\n",
      "train_test_data done: 0.028005361557006836\n",
      "RAM usage train_test_data:  72\n",
      "length of train  sequence original 4\n",
      "length of train  sequence original 25\n",
      "length of train  sequence original 33\n",
      "length of train  sequence original 21\n",
      "length of train  sequence original 2\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "length of train sequence padded 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "len of test seq after padding 32\n",
      "padded_train_test_data done: 7.109444856643677\n",
      "RAM usage padded_train_test_data:  72\n",
      "<BatchDataset shapes: ((32, 32, 64), (32,)), types: (tf.int32, tf.int64)>\n",
      "vocab_size: 42\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(32, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (32, 32, 64, 42)          1806      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (32, 32, 64, 64)          8128      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (32, 131072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 2048)                268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (32, 1)                   2049      \n",
      "=================================================================\n",
      "Total params: 268,449,487\n",
      "Trainable params: 268,449,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "125/125 [==============================] - 134s 1s/step - loss: 0.6940 - accuracy: 0.4983\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 127s 1s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 126s 1s/step - loss: 0.6931 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf2884b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
