{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8bd37c0-54f3-4edf-8517-10b7b8285fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "cur_dir = os.getcwd()\n",
    "basename = os.path.basename(cur_dir)\n",
    "for _ in range(5):\n",
    "    if basename != 'OCLog':\n",
    "        cur_dir = os.path.dirname(cur_dir)\n",
    "        basename = os.path.basename(cur_dir)\n",
    "        #print(cur_dir, basename)\n",
    "    else:\n",
    "        if cur_dir not in sys.path:\n",
    "            sys.path.append(cur_dir)\n",
    "            #print(sys.path)\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tqdm import trange, tqdm, tnrange\n",
    "from oclog.BGL.bglogUKC import BGLog, get_embedding_layer\n",
    "from oclog.openset.boundary_loss import euclidean_metric, BoundaryLoss\n",
    "from oclog.openset.pretraining import LogLineEncoder, LogSeqEncoder, LogClassifier\n",
    "# from oclog.openset.openset import OpenSet\n",
    "from oclog.openset.opensetv6 import OpenSet\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "import sklearn.metrics as m\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def update_tracker(file_name, data):\n",
    "    if os.path.exists(file_name):\n",
    "        wb = load_workbook(file_name)\n",
    "    else:\n",
    "        wb = Workbook()    \n",
    "    wb.save(file_name)\n",
    "    # wb.close(file_name)\n",
    "    orig_df = pd.read_excel(file_name,)\n",
    "    #print(orig_df.head())\n",
    "    new_df = pd.DataFrame(data, )\n",
    "    concat_df = pd.concat([orig_df, new_df], axis=0)\n",
    "    #print(concat_df.head())\n",
    "    concat_df.to_excel(file_name)\n",
    "    return concat_df\n",
    "\n",
    "def oset_train(ablation=5000,designated_ukc_cls=3,num_classes=2,embedding_size=128,lr_rate=3,optimizer='sgd',\n",
    "pretrain_epochs=3,octrain_epochs=200,wait_patience=3, debug=False, tracker='tracker.xlsx', comment='',\n",
    "             tracker_update=True):\n",
    "    tf.random.set_seed(1234)\n",
    "    np.random.seed(1234) \n",
    "    bglog = BGLog(save_padded_num_sequences=False, debug=debug,  load_from_pkl=True, )\n",
    "    train_test = bglog.get_tensor_train_val_test(ablation=ablation, designated_ukc_cls=designated_ukc_cls )\n",
    "    train_data, val_data, test_data = train_test\n",
    "    line_encoder = LogLineEncoder(bglog, chars_in_line=64)\n",
    "    logSeqencer =  LogSeqEncoder(line_in_seq=32, dense_neurons=embedding_size)\n",
    "    ptmodel = LogClassifier(line_encoder=line_encoder, seq_encoder=logSeqencer, num_classes=num_classes)\n",
    "    ptmodel.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    hist = ptmodel.fit(train_data, validation_data=val_data, epochs=pretrain_epochs)    \n",
    "    pre_tr_acc = hist.history.get('accuracy')[len(hist.history.get('accuracy'))-1]\n",
    "    # print(round(pre_tr_acc, 4))\n",
    "    pre_val_acc = hist.history.get('val_accuracy')[len(hist.history.get('val_accuracy'))-1]\n",
    "    # print(round(pre_val_acc, 4))\n",
    "    oset = OpenSet(num_classes, ptmodel, embedding_size=embedding_size)\n",
    "    _, _ = oset.train(train_data,data_val=val_data, epochs=octrain_epochs, \n",
    "                      lr_rate=lr_rate, wait_patience=wait_patience, optimizer=optimizer,\n",
    "                     pretrain_hist=hist)\n",
    "    _, _, f1_weighted, f_measure = oset.evaluate(test_data, ukc_label=designated_ukc_cls)\n",
    "    lst = list(tf.reshape(oset.radius, (1, num_classes)).numpy()[0])\n",
    "    lst = [str(i) for i in lst]\n",
    "    radius = ','.join(lst)    \n",
    "    loss = oset.losses[len(oset.losses)-1].numpy()    \n",
    "    tracker_data = {'ablation':[ablation],'designated_ukc_cls': [designated_ukc_cls],'num_classes': [num_classes],\n",
    "                   'embedding_size': [embedding_size], 'lr_rate': [lr_rate], 'optimizer': [optimizer],\n",
    "                    'pretrain_epochs': [pretrain_epochs],'octrain_epochs': [oset.epoch], 'wait_patience': [wait_patience], \n",
    "                   'f1_weighted': [f1_weighted], 'f1_macro': f_measure.get('F1-score'), \n",
    "                   'F1Known': f_measure.get('Known'), 'F1Open': f_measure.get('Open'), 'loss':[loss], 'Radius': radius,\n",
    "                   'pre_tr_acc': pre_tr_acc, 'pre_val_acc': pre_val_acc,'comment': comment}\n",
    "    \n",
    "    if tracker_update:\n",
    "        update_tracker(tracker, tracker_data)\n",
    "    return test_data, oset, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462293b-d85a-4f78-a720-01698a059383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_num_seq_df loaded from C:\\Users\\Bhujay_ROG\\MyDev\\OCLog\\oclog\\BGL\\data\\bgl_ukc.pkl\n",
      "trained tokenizer, tk, loaded from C:\\Users\\Bhujay_ROG\\MyDev\\OCLog\\oclog\\BGL\\data\\bgltkukc.pkl\n",
      "train_0:, 2400\n",
      "val_0:, 300\n",
      "test_0:, 300\n",
      "train_1:, 2400\n",
      "val_1:, 300\n",
      "test_1:, 300\n",
      "train_2:, 2400\n",
      "val_2:, 300\n",
      "test_2:, 300\n",
      "class 5 is added as ukc\n",
      "ukc_5:, 165\n",
      "vocab_size: 50\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 22s 94ms/step - loss: 0.0422 - accuracy: 0.9857 - precision: 0.9933 - recall: 0.9749 - val_loss: 0.0029 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 22s 99ms/step - loss: 0.0023 - accuracy: 0.9996 - precision: 0.9996 - recall: 0.9994 - val_loss: 0.0038 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 22s 96ms/step - loss: 5.2741e-04 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999 - val_loss: 0.0497 - val_accuracy: 0.9799 - val_precision: 0.9799 - val_recall: 0.9799\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 22s 96ms/step - loss: 0.0417 - accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - val_loss: 1.3330e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 22s 96ms/step - loss: 6.0524e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1376e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 22s 97ms/step - loss: 9.5011e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2070e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 22s 97ms/step - loss: 6.7787e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1127e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 22s 97ms/step - loss: 5.5497e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0421e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 21s 95ms/step - loss: 4.8065e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5566e-05 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 21s 95ms/step - loss: 4.2314e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7270e-05 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:31<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/200, train_loss: 7.153515815734863, F1_train: 0.6808977858129492 F1_val: 0.6890074211502782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:31<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/200, train_loss: 7.153472900390625, F1_train: 0.699450319871884 F1_val: 0.6931595622119816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:30<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/200, train_loss: 7.153521537780762, F1_train: 0.7066927224284855 F1_val: 0.692991214057508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:30<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/200, train_loss: 7.15346622467041, F1_train: 0.7298765734563775 F1_val: 0.692991214057508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:30<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/200, train_loss: 7.153414726257324, F1_train: 0.7359988020365378 F1_val: 0.6952156063389986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:30<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/200, train_loss: 7.15341854095459, F1_train: 0.7392765386639238 F1_val: 0.6952156063389986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:30<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/200, train_loss: 7.153411865234375, F1_train: 0.7431094411521186 F1_val: 0.692991214057508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:31<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/200, train_loss: 7.1534857749938965, F1_train: 0.7447045774057043 F1_val: 0.6952156063389986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▏                       | 158/225 [00:21<00:09,  7.14it/s]"
     ]
    }
   ],
   "source": [
    "comment=\"data 3000\"\n",
    "test_data, oset, hist = oset_train(ablation=3000,designated_ukc_cls=5,num_classes=3,embedding_size=12,\n",
    "                             lr_rate=2.6, optimizer='adam',\n",
    "pretrain_epochs=10, wait_patience=8, comment=comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526af111-a4ee-4744-9efd-7198dc46a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretraining should stop based on wait_patience"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
