{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24d54f7-c6b1-43de-b23e-05e3907ccef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "cur_dir = os.getcwd()\n",
    "basename = os.path.basename(cur_dir)\n",
    "for _ in range(5):\n",
    "    if basename != 'OCLog':\n",
    "        cur_dir = os.path.dirname(cur_dir)\n",
    "        basename = os.path.basename(cur_dir)\n",
    "        #print(cur_dir, basename)\n",
    "    else:\n",
    "        if cur_dir not in sys.path:\n",
    "            sys.path.append(cur_dir)\n",
    "            #print(sys.path)\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tqdm import trange, tqdm, tnrange\n",
    "from oclog.BGL.bglv1 import BGLog\n",
    "from oclog.openset.opensetv12 import OpenSet\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "import sklearn.metrics as m\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b96066-4d1b-46e9-a982-d3157a51d29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_num_seq_df loaded from C:\\Users\\Bhujay_ROG\\MyDev\\OCLog\\oclog\\BGL\\data\\bgl_ukc.pkl\n",
      "trained tokenizer, tk, loaded from C:\\Users\\Bhujay_ROG\\MyDev\\OCLog\\oclog\\BGL\\data\\bgl_tk.pkl\n",
      "train_0:, 1200, val_0:, 150, test_0:, 150, train_1:, 1200, val_1:, 150, test_1:, 150, train_2:, 1200, val_2:, 150, test_2:, 150, class 5 is added as ukc\n",
      "ukc_5:, 150\n",
      "length of train_data - (num_seq_per_cls * num_class)// batch size: 112\n",
      "get_bgdata  num_classses: 3 and self.num_classes: 3\n"
     ]
    }
   ],
   "source": [
    "oset = OpenSet()\n",
    "train_data, val_data,  test_data, bglog  = oset.get_bgdata(bg_class_obj=BGLog, save_padded_num_sequences=False, \n",
    "                                                           load_from_pkl=True, ablation=1500,\n",
    "                                                           debug=False,\n",
    "                                                          designated_ukc_cls=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "993dded3-1251-4cc3-bd89-a09efa86b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = oset.train(train_data=train_data, val_data=val_data,\n",
    "#                  test_data=test_data, bglog=bglog, \n",
    "#                  manual_color_map=True, centroid_black=True,                               \n",
    "#                  tsne_n_iter=2000, tsne_perplexity=8,\n",
    "#                  embedding_size=12, oc_lr=2.5, pt_epochs=2, oc_epochs=2,\n",
    "#                 save_ptmodel=False, save_ocmodel=False, oc_centroid_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5815c2ec-5441-45ee-b3b6-cdec785de5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oclog.openset.ptmodelv1 import LogLineEncoder, LogSeqEncoder, LogClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1bbfc42-327a-4f48-bee4-84bba8d3aacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n",
      "in train step\n",
      "label_batch withi train step:...... Tensor(\"IteratorGetNext:1\", shape=(32, 3), dtype=float32)\n",
      "self.batch_features Tensor(\"log_classifier/log_seq_encoder/dense/Relu:0\", shape=(32, 16), dtype=float32)\n",
      "y_pred Tensor(\"log_classifier/dense_1/Softmax:0\", shape=(32, 3), dtype=float32)\n",
      "using hvm_loss .........................\n",
      "batch_feature within hvm loss Tensor(\"log_classifier/log_seq_encoder/dense/Relu:0\", shape=(32, 16), dtype=float32)\n",
      "label_batch within hvm loss Tensor(\"IteratorGetNext:1\", shape=(32, 3), dtype=float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Bhujay_ROG\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Bhujay_ROG\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Bhujay_ROG\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Bhujay_ROG\\MyDev\\OCLog\\oclog\\openset\\ptmodelv1.py\", line 165, in train_step\n        loss = self.hvm_loss(self.batch_features, embedding_size,  y, y_pred)\n    File \"C:\\Users\\Bhujay_ROG\\MyDev\\OCLog\\oclog\\openset\\ptmodelv1.py\", line 206, in hvm_loss\n        print('label', label.numpy())\n\n    AttributeError: 'Tensor' object has no attribute 'numpy'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# ptmodel_arch.compile(optimizer=pt_optimizer, loss=pt_loss, metrics=pt_metrics)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m ptmodel_arch\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mpt_optimizer, metrics\u001b[38;5;241m=\u001b[39mpt_metrics)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mptmodel_arch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\venv1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\venv1\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Bhujay_ROG\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Bhujay_ROG\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Bhujay_ROG\\venv1\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Bhujay_ROG\\MyDev\\OCLog\\oclog\\openset\\ptmodelv1.py\", line 165, in train_step\n        loss = self.hvm_loss(self.batch_features, embedding_size,  y, y_pred)\n    File \"C:\\Users\\Bhujay_ROG\\MyDev\\OCLog\\oclog\\openset\\ptmodelv1.py\", line 206, in hvm_loss\n        print('label', label.numpy())\n\n    AttributeError: 'Tensor' object has no attribute 'numpy'\n"
     ]
    }
   ],
   "source": [
    "chars_in_line = train_data.element_spec[0].shape[2]\n",
    "line_in_seq = train_data.element_spec[0].shape[1]\n",
    "num_classes = train_data.element_spec[1].shape[1]\n",
    "char_embedding_size = len(bglog.tk.word_index) \n",
    "pt_optimizer = 'adam'\n",
    "pt_loss = 'categorical_crossentropy'\n",
    "pt_metrics = ['accuracy', tf.keras.metrics.Precision(),tf.keras.metrics.Recall()]\n",
    "tf_random_seed =  1234 \n",
    "embedding_size = 16\n",
    "# num_classes = kwargs.get('num_classes', train_data.element_spec[1].shape[1])\n",
    "tf.random.set_seed(tf_random_seed)\n",
    "line_encoder = LogLineEncoder(bglog, chars_in_line=chars_in_line, char_embedding_size=char_embedding_size,)\n",
    "log_seqencer =  LogSeqEncoder(line_in_seq=line_in_seq, dense_neurons=embedding_size)\n",
    "ptmodel_arch = LogClassifier(line_encoder=line_encoder, seq_encoder=log_seqencer, num_classes=num_classes)\n",
    "# ptmodel_arch.compile(optimizer=pt_optimizer, loss=pt_loss, metrics=pt_metrics)\n",
    "ptmodel_arch.compile(optimizer=pt_optimizer, metrics=pt_metrics)\n",
    "ptmodel_arch.fit(train_data)\n",
    "# ptmodel_arch.batch_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4a3cb-8ae2-495b-8e15-c3258ac38c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptmodel_arch.batch_features\n",
    "# batch = next(iter(train_data))\n",
    "# logseq_batch, label_batch = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b487a205-ad9e-4623-939c-3e956b904f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(logseq_batch.shape, label_batch.shape)\n",
    "# ptmodel_arch(logseq_batch)\n",
    "# batch_features = ptmodel_arch.batch_features\n",
    "# print('batch_features', batch_features.shape)\n",
    "# print('first feature', batch_features[0])\n",
    "# print('')\n",
    "# centroids = tf.zeros((num_classes, embedding_size))\n",
    "# total_labels = tf.zeros(num_classes)\n",
    "# for i in range(label_batch.shape[0]): # (32, 4) --> here length is 32\n",
    "#     label = label_batch[i] # label looks like [0 0 0 1]\n",
    "#     # numeric_label = np.argmax(label) # index position of the label = 3 , so it is actually class =3\n",
    "#     numeric_label = tf.math.argmax(label).numpy()\n",
    "#     ##total_labels = [0 0 0 0] each col representing a class \n",
    "#     ## count the number for each class\n",
    "#     total_labels_lst = tf.unstack(total_labels)\n",
    "#     total_labels_lst[numeric_label] += 1 \n",
    "#     total_labels = tf.stack(total_labels_lst)\n",
    "#     centroids_lst = tf.unstack(centroids)\n",
    "#     centroids_lst[numeric_label] += batch_features[i]\n",
    "#     centroids = tf.stack(centroids_lst)\n",
    "#     # self.labelled_features[numeric_label] = features[i]\n",
    "#     # each row index in the centroid array is a class\n",
    "#     # we add first identify the feature belonging to which class by the numeric_label\n",
    "#     # Then add all the features belonging to the class in the corresponding row of the centroid arr\n",
    "# ### shape of centroids is (4, 16) whereas shape of total_labels is (1, 4)\n",
    "# ### reshape the total_labels as 4,1 ==> [[0], [0], [0], [0]]==> 4 rows \n",
    "# ## so that we can divide the centroids array by the total_labels\n",
    "# total_label_reshaped = tf.reshape(total_labels, (num_classes, 1))\n",
    "# centroids /= total_label_reshaped\n",
    "# pt_batch_centroids = centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8facf7b-4a62-43bc-a71a-12359c2c3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_label.numpy()\n",
    "# # type(numeric_label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9699a025-b4ef-4f0e-afd2-97483fd1dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('centroid for 3 classes', pt_batch_centroids)\n",
    "# # print('centroid for 32 features', pt_batch_centroids[0])\n",
    "# label_indexs = tf.math.argmax(label_batch, axis=1)\n",
    "# # c = tf.gather(centroids, indices=label_indexs)\n",
    "# centroid_for_features_as_per_class = tf.gather(centroids, indices=label_indexs)\n",
    "# print('centroid_for_features_as_per_class', centroid_for_features_as_per_class.shape)\n",
    "# print('first feature in batch_feature', batch_features[0], )\n",
    "# euc_dis = tf.norm(batch_features - centroid_for_features_as_per_class, ord='euclidean', axis=1)\n",
    "# print('distance for the first feature', euc_dis[0], euc_dis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0361f38-900f-458b-8075-3ffdc62371b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reduce_mean(euc_dis, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
