{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24d54f7-c6b1-43de-b23e-05e3907ccef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "cur_dir = os.getcwd()\n",
    "basename = os.path.basename(cur_dir)\n",
    "for _ in range(5):\n",
    "    if basename != 'OCLog':\n",
    "        cur_dir = os.path.dirname(cur_dir)\n",
    "        basename = os.path.basename(cur_dir)\n",
    "        #print(cur_dir, basename)\n",
    "    else:\n",
    "        if cur_dir not in sys.path:\n",
    "            sys.path.append(cur_dir)\n",
    "            #print(sys.path)\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tqdm import trange, tqdm, tnrange\n",
    "from oclog.BGL.bglv1 import BGLog\n",
    "from oclog.openset.opensetv12 import OpenSet\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "import sklearn.metrics as m\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b96066-4d1b-46e9-a982-d3157a51d29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_num_seq_df loaded from C:\\Users\\Bhujay_ROG\\MyDev\\OCLog\\oclog\\BGL\\data\\bgl_ukc.pkl\n",
      "trained tokenizer, tk, loaded from C:\\Users\\Bhujay_ROG\\MyDev\\OCLog\\oclog\\BGL\\data\\bgl_tk.pkl\n",
      "train_0:, 1200, val_0:, 150, test_0:, 150, train_1:, 1200, val_1:, 150, test_1:, 150, train_2:, 1200, val_2:, 150, test_2:, 150, class 5 is added as ukc\n",
      "ukc_5:, 150\n",
      "length of train_data - (num_seq_per_cls * num_class)// batch size: 112\n",
      "get_bgdata  num_classses: 3 and self.num_classes: 3\n"
     ]
    }
   ],
   "source": [
    "oset = OpenSet()\n",
    "train_data, val_data,  test_data, bglog  = oset.get_bgdata(bg_class_obj=BGLog, save_padded_num_sequences=False, \n",
    "                                                           load_from_pkl=True, ablation=1500,\n",
    "                                                           debug=False,\n",
    "                                                          designated_ukc_cls=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "993dded3-1251-4cc3-bd89-a09efa86b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = oset.train(train_data=train_data, val_data=val_data,\n",
    "#                  test_data=test_data, bglog=bglog, \n",
    "#                  manual_color_map=True, centroid_black=True,                               \n",
    "#                  tsne_n_iter=2000, tsne_perplexity=8,\n",
    "#                  embedding_size=12, oc_lr=2.5, pt_epochs=2, oc_epochs=2,\n",
    "#                 save_ptmodel=False, save_ocmodel=False, oc_centroid_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5815c2ec-5441-45ee-b3b6-cdec785de5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oclog.openset.ptmodelv1 import LogLineEncoder, LogSeqEncoder, LogClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1bbfc42-327a-4f48-bee4-84bba8d3aacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n",
      "in train step\n",
      "label_batch withi train step:...... Tensor(\"IteratorGetNext:1\", shape=(32, 3), dtype=float32)\n",
      "in train step\n",
      "label_batch withi train step:...... Tensor(\"IteratorGetNext:1\", shape=(32, 3), dtype=float32)\n",
      "112/112 [==============================] - 12s 100ms/step - accuracy: 0.9342 - precision_1: 0.9903 - recall_1: 0.8786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ce1f7b070>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_in_line = train_data.element_spec[0].shape[2]\n",
    "line_in_seq = train_data.element_spec[0].shape[1]\n",
    "num_classes = train_data.element_spec[1].shape[1]\n",
    "char_embedding_size = len(bglog.tk.word_index) \n",
    "pt_optimizer = 'adam'\n",
    "pt_loss = 'categorical_crossentropy'\n",
    "pt_metrics = ['accuracy', tf.keras.metrics.Precision(),tf.keras.metrics.Recall()]\n",
    "tf_random_seed =  1234 \n",
    "embedding_size = 16\n",
    "# num_classes = kwargs.get('num_classes', train_data.element_spec[1].shape[1])\n",
    "tf.random.set_seed(tf_random_seed)\n",
    "line_encoder = LogLineEncoder(bglog, chars_in_line=chars_in_line, char_embedding_size=char_embedding_size,)\n",
    "log_seqencer =  LogSeqEncoder(line_in_seq=line_in_seq, dense_neurons=embedding_size)\n",
    "ptmodel_arch = LogClassifier(line_encoder=line_encoder, seq_encoder=log_seqencer, num_classes=num_classes)\n",
    "# ptmodel_arch.compile(optimizer=pt_optimizer, loss=pt_loss, metrics=pt_metrics)\n",
    "ptmodel_arch.compile(optimizer=pt_optimizer, metrics=pt_metrics)\n",
    "ptmodel_arch.fit(train_data)\n",
    "# ptmodel_arch.batch_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60a4a3cb-8ae2-495b-8e15-c3258ac38c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptmodel_arch.batch_features\n",
    "batch = next(iter(train_data))\n",
    "logseq_batch, label_batch = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b487a205-ad9e-4623-939c-3e956b904f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 64) (32, 3)\n",
      "batch_features (32, 16)\n",
      "first feature tf.Tensor(\n",
      "[ 0.         0.         0.        10.295653   4.5766234  0.\n",
      "  0.         0.2313345  0.         0.         0.         0.\n",
      " 13.923516   0.         0.         0.       ], shape=(16,), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(logseq_batch.shape, label_batch.shape)\n",
    "ptmodel_arch(logseq_batch)\n",
    "batch_features = ptmodel_arch.batch_features\n",
    "print('batch_features', batch_features.shape)\n",
    "print('first feature', batch_features[0])\n",
    "print('')\n",
    "centroids = tf.zeros((num_classes, embedding_size))\n",
    "total_labels = tf.zeros(num_classes)\n",
    "for i in range(label_batch.shape[0]): # (32, 4) --> here length is 32\n",
    "    label = label_batch[i] # label looks like [0 0 0 1]\n",
    "    # numeric_label = np.argmax(label) # index position of the label = 3 , so it is actually class =3\n",
    "    numeric_label = tf.math.argmax(label).numpy()\n",
    "    ##total_labels = [0 0 0 0] each col representing a class \n",
    "    ## count the number for each class\n",
    "    total_labels_lst = tf.unstack(total_labels)\n",
    "    total_labels_lst[numeric_label] += 1 \n",
    "    total_labels = tf.stack(total_labels_lst)\n",
    "    centroids_lst = tf.unstack(centroids)\n",
    "    centroids_lst[numeric_label] += batch_features[i]\n",
    "    centroids = tf.stack(centroids_lst)\n",
    "    # self.labelled_features[numeric_label] = features[i]\n",
    "    # each row index in the centroid array is a class\n",
    "    # we add first identify the feature belonging to which class by the numeric_label\n",
    "    # Then add all the features belonging to the class in the corresponding row of the centroid arr\n",
    "### shape of centroids is (4, 16) whereas shape of total_labels is (1, 4)\n",
    "### reshape the total_labels as 4,1 ==> [[0], [0], [0], [0]]==> 4 rows \n",
    "## so that we can divide the centroids array by the total_labels\n",
    "total_label_reshaped = tf.reshape(total_labels, (num_classes, 1))\n",
    "centroids /= total_label_reshaped\n",
    "pt_batch_centroids = centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8facf7b-4a62-43bc-a71a-12359c2c3d61",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnumeric_label\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "numeric_label.numpy()\n",
    "# type(numeric_label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9699a025-b4ef-4f0e-afd2-97483fd1dc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centroid for 3 classes tf.Tensor(\n",
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0461287e+01 4.5569844e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.9337600e-01 5.5942935e-04 3.8482281e-03\n",
      "  0.0000000e+00 0.0000000e+00 1.4086994e+01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]\n",
      " [1.9430670e+01 2.0913212e+01 4.3582392e+00 1.8160439e+00 2.1616616e+00\n",
      "  1.4756054e-01 0.0000000e+00 0.0000000e+00 3.1542070e+00 5.4978263e-01\n",
      "  1.6582438e-01 3.3761695e-01 4.6369295e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]\n",
      " [3.3319256e-01 4.7300778e-02 1.4957752e+01 4.8455632e-01 9.1551437e+00\n",
      "  0.0000000e+00 0.0000000e+00 5.6322670e-01 1.3443686e+01 1.4567280e+01\n",
      "  5.8653355e+00 0.0000000e+00 7.5367551e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]], shape=(3, 16), dtype=float32)\n",
      "centroid_for_features_as_per_class (32, 16)\n",
      "first feature in batch_feature tf.Tensor(\n",
      "[ 0.         0.         0.        10.295653   4.5766234  0.\n",
      "  0.         0.2313345  0.         0.         0.         0.\n",
      " 13.923516   0.         0.         0.       ], shape=(16,), dtype=float32)\n",
      "distance for the first feature tf.Tensor(0.23664537, shape=(), dtype=float32) (32,)\n"
     ]
    }
   ],
   "source": [
    "print('centroid for 3 classes', pt_batch_centroids)\n",
    "# print('centroid for 32 features', pt_batch_centroids[0])\n",
    "label_indexs = tf.math.argmax(label_batch, axis=1)\n",
    "# c = tf.gather(centroids, indices=label_indexs)\n",
    "centroid_for_features_as_per_class = tf.gather(centroids, indices=label_indexs)\n",
    "print('centroid_for_features_as_per_class', centroid_for_features_as_per_class.shape)\n",
    "print('first feature in batch_feature', batch_features[0], )\n",
    "euc_dis = tf.norm(batch_features - centroid_for_features_as_per_class, ord='euclidean', axis=1)\n",
    "print('distance for the first feature', euc_dis[0], euc_dis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0361f38-900f-458b-8075-3ffdc62371b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.984352>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(euc_dis, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
