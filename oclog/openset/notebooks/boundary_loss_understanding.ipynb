{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1ba441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bglog import BGLog, get_embedding_layer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33c736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bglog = BGLog(save_padded_num_sequences=False, load_from_pkl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4822fcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_num_seq_df loaded from data\\bgl_padded_num_seq_df.pkl\n",
      "trained tokenizer, tk, loaded from data\\bgltk.pkl\n",
      "train_0:, 800\n",
      "test_0:, 200\n",
      "train_1:, 800\n",
      "test_1:, 200\n",
      "train_2:, 800\n",
      "test_2:, 200\n",
      "train_3:, 800\n",
      "test_3:, 102\n",
      "4 class does not have 800 records, it has only 628 records\n",
      "test_4:, 0\n",
      "5 class does not have 800 records, it has only 165 records\n",
      "5 class does not have 200 records, it has only 165 records\n",
      "6 class does not have 800 records, it has only 75 records\n",
      "6 class does not have 200 records, it has only 75 records\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "<BatchDataset shapes: ((32, 32, 64), (32, 4)), types: (tf.int32, tf.float32)>\n",
      "<BatchDataset shapes: ((32, 32, 64), (32, 4)), types: (tf.int32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "train_test = bglog.get_tensor_train_test(ablation=1000)\n",
    "train_data, test_data = train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48191d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(conv1d_set1 = 3, conv1d_set2 = 3, dense_neurons=2048, filters=64,\n",
    "            kernel_size=3,maxpool_1=True,epochs=25, dense_activation='relu'):\n",
    "    embedding_weights, vocab_size, char_onehot = get_embedding_layer(bglog)\n",
    "    B = train_data.element_spec[0].shape[0]\n",
    "#     inputs = tf.keras.layers.Input(batch_shape=(B, train_data.element_spec[0].shape[1], train_data.element_spec[0].shape[2]), dtype='float64' )\n",
    "    inputs = tf.keras.layers.Input(shape=(train_data.element_spec[0].shape[1], train_data.element_spec[0].shape[2]), dtype='float64' )\n",
    "    x = tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
    "                                    output_dim=vocab_size,\n",
    "                                    input_length=train_data.element_spec[0].shape[2],\n",
    "                                    weights = [embedding_weights],\n",
    "                                    )(inputs)\n",
    "    for _ in range(conv1d_set1):\n",
    "        x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "    if maxpool_1:\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(1, train_data.element_spec[0].shape[2]))(x)\n",
    "        x = tf.reshape(x, (B, train_data.element_spec[0].shape[1], filters))        \n",
    "        for _ in range(conv1d_set2):\n",
    "            x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "        x = tf.keras.layers.MaxPooling1D(pool_size=(train_data.element_spec[0].shape[1]) )(x)\n",
    "        x = tf.reshape(x, (B, filters))\n",
    "    if not maxpool_1:\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "    if dense_activation is None:\n",
    "        x = tf.keras.layers.Dense(dense_neurons)(x)\n",
    "    else:\n",
    "        x = tf.keras.layers.Dense(dense_neurons, activation=dense_activation)(x)\n",
    "    outputs = tf.keras.layers.Dense(train_data.element_spec[1].shape[1], activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    print(model.summary())\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    hist = model.fit(train_data, validation_data=test_data, epochs=epochs) \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650cf579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we  feed  xi  to  a dense layer h to get the log-sequence representation zi∈RD:\n",
    "#     zi= h(xi) =σ(Whxi+bh) ............................(2)\n",
    "# in our case zi can be obtained from the dense layer before the softmax\n",
    "# Lets see how to ger it from the train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7d49704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we pre-train the model with labeled known intent samples. \n",
    "# In order to better reflect the effectiveness of the learned decision boundary, \n",
    "# we learn the feature representation zi with the simple softmax loss Ls to perform classification:\n",
    "\n",
    "# trained_model, hist = model(epochs=6,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd98e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model, hist = model(epochs=6, dense_neurons=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598670b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the decision boundary of each class constraining the known labels within a ball area\n",
    "# how to get zi and how to know that zi belongs to which yi ?\n",
    "# from there we will have to calculate the Ck , centroid for the class k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54fbf537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d888a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_6 = trained_model.get_layer(index=(len(trained_model.layers)-1))\n",
    "# print(dense_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a2d7160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the log sequence embedding from the last layer\n",
    "# we can treat this as the features from the logs\n",
    "# dense_6.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e51ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we use the pre-trained model to extract intent features for \n",
    "# learning the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef1a2b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n",
      "sample_x_train.shape: (32, 32, 64)\n",
      "loglineEmbedding.shape: (32, 32, 64)\n",
      "Model: \"log_line_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  2550      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              multiple                  9664      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            multiple                  12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            multiple                  12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "=================================================================\n",
      "Total params: 36,918\n",
      "Trainable params: 36,918\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class LogLineEncoder(tf.keras.Model):\n",
    "    def __init__(self, num_of_conv1d=3,  \n",
    "                 filters=64,\n",
    "                 kernel_size=3, ):\n",
    "        super().__init__()            \n",
    "        self.num_of_conv1d = num_of_conv1d       \n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size           \n",
    "        self.embedding_weights, self.vocab_size, self.char_onehot = get_embedding_layer(bglog)       \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size+1,\n",
    "                                    output_dim=self.vocab_size,\n",
    "                                    input_length=train_data.element_spec[0].shape[2],\n",
    "                                    weights = [self.embedding_weights],\n",
    "                                    )\n",
    "        self.conv1d_layers = [tf.keras.layers.Conv1D(filters=filters, \n",
    "                                                kernel_size=kernel_size, \n",
    "                                                padding='same')  \n",
    "                       for _ in range(self.num_of_conv1d)]\n",
    "        self.maxpool2d = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size=(1, train_data.element_spec[0].shape[2]))\n",
    "                  \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        for conv1d_layer in self.conv1d_layers:\n",
    "            x = conv1d_layer(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = tf.reshape(x, (inputs.shape[0], inputs.shape[1], self.filters))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "# \n",
    "line_encoder =   LogLineEncoder()\n",
    "# the model doesn't have a state unless it is called at least once\n",
    "# in order to initialize the model we need a sample data \n",
    "sample_train_data = next(iter(train_data))\n",
    "sample_x_train = sample_train_data[0]\n",
    "print('sample_x_train.shape:', sample_x_train.shape)\n",
    "# now we will initialize the model with the sample data\n",
    "loglineEmbedding = line_encoder(sample_x_train)\n",
    "print('loglineEmbedding.shape:', loglineEmbedding.shape)\n",
    "# Now the model have a state and can be inspected        \n",
    "line_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1603d084",
   "metadata": {},
   "source": [
    "LOG SEQUENCE EMBEDDING TAKES LOGLINE EMBEDDING AS INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef28da8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logSeqEmbedding.shape: (32, 16)\n",
      "Model: \"log_seq_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            multiple                  12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            multiple                  12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            multiple                  12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1040      \n",
      "=================================================================\n",
      "Total params: 38,096\n",
      "Trainable params: 38,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class LogSeqEncoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, num_of_conv1d=3,  filters=64,\n",
    "                 kernel_size=3, maxpool_1=True,\n",
    "                 dense_neurons=16, dense_activation='relu',):\n",
    "        super().__init__()\n",
    "        self.num_of_conv1d = num_of_conv1d\n",
    "        self.dense_neurons = dense_neurons\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.maxpool_1 = maxpool_1\n",
    "        self.dense_activation = dense_activation\n",
    "        self.conv1d_layers = [tf.keras.layers.Conv1D(filters=filters, \n",
    "                                                kernel_size=kernel_size, \n",
    "                                                padding='same')  \n",
    "                       for _ in range(self.num_of_conv1d)]\n",
    "        self.maxpool1d = tf.keras.layers.MaxPooling1D(pool_size=(train_data.element_spec[0].shape[1]) )\n",
    "        \n",
    "        self.Dense = tf.keras.layers.Dense(self.dense_neurons, \n",
    "                                           activation=self.dense_activation)\n",
    "       \n",
    "        \n",
    "    def call(self, inputs):       \n",
    "        for conv1d_layer in self.conv1d_layers:\n",
    "            x = conv1d_layer(inputs)\n",
    "        x = self.maxpool1d(x)        \n",
    "        x = tf.reshape(x, (inputs.shape[0], self.filters))\n",
    "        x = self.Dense(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "logSeqencer =   LogSeqEncoder()\n",
    "# the model doesn't have a state unless it is called at least once\n",
    "logSeqEmbedding = logSeqencer(loglineEmbedding)\n",
    "print('logSeqEmbedding.shape:', logSeqEmbedding.shape)\n",
    "# Now the model have a state and can be inspected        \n",
    "logSeqencer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f56088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2da4477b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       "array([[0.3362508 , 0.18392177, 0.25280538, 0.22702198],\n",
       "       [0.3259221 , 0.17259048, 0.25523707, 0.24625033],\n",
       "       [0.33589986, 0.17154121, 0.2527363 , 0.23982258],\n",
       "       [0.31977898, 0.18768497, 0.24569227, 0.2468438 ],\n",
       "       [0.32673177, 0.19432285, 0.24594125, 0.23300415],\n",
       "       [0.33127734, 0.17444712, 0.24941857, 0.24485695],\n",
       "       [0.34088168, 0.18399805, 0.24740067, 0.22771955],\n",
       "       [0.35052803, 0.17589073, 0.25080392, 0.2227773 ],\n",
       "       [0.3301531 , 0.19087662, 0.25464252, 0.22432776],\n",
       "       [0.32286835, 0.19903256, 0.23758425, 0.24051486],\n",
       "       [0.33854622, 0.17458344, 0.24335903, 0.24351132],\n",
       "       [0.34005564, 0.17529859, 0.24966821, 0.23497763],\n",
       "       [0.3234403 , 0.20333713, 0.24460691, 0.22861567],\n",
       "       [0.3295585 , 0.17948176, 0.24202996, 0.24892984],\n",
       "       [0.33527887, 0.18222594, 0.23787557, 0.2446196 ],\n",
       "       [0.33527887, 0.18222594, 0.23787557, 0.2446196 ],\n",
       "       [0.33407888, 0.19174811, 0.2519575 , 0.22221549],\n",
       "       [0.33337113, 0.18000375, 0.24473459, 0.24189052],\n",
       "       [0.31938365, 0.1863365 , 0.24471486, 0.24956496],\n",
       "       [0.3283441 , 0.19291012, 0.24431148, 0.23443434],\n",
       "       [0.32871324, 0.1763968 , 0.24448268, 0.2504073 ],\n",
       "       [0.32908282, 0.20005623, 0.24377911, 0.22708184],\n",
       "       [0.32656512, 0.17922133, 0.24514723, 0.24906634],\n",
       "       [0.3363649 , 0.17603418, 0.24502747, 0.24257357],\n",
       "       [0.3122783 , 0.20633852, 0.25199327, 0.22938995],\n",
       "       [0.3420484 , 0.18132277, 0.24344954, 0.23317932],\n",
       "       [0.32103145, 0.18004665, 0.24432096, 0.25460097],\n",
       "       [0.34232587, 0.17749855, 0.25138485, 0.22879075],\n",
       "       [0.33227316, 0.19606794, 0.24972276, 0.22193608],\n",
       "       [0.3200402 , 0.18649593, 0.24278906, 0.25067475],\n",
       "       [0.3328023 , 0.17646989, 0.2423851 , 0.24834274],\n",
       "       [0.33527887, 0.18222594, 0.23787557, 0.2446196 ]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LogClassifier(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,  **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.log_line_encoder = LogLineEncoder()\n",
    "        self.log_seq_encoder = LogSeqEncoder()\n",
    "        self.classifier = tf.keras.layers.Dense(\n",
    "            train_data.element_spec[1].shape[1], activation='softmax')\n",
    "#         self.extract_feature = extract_feature\n",
    "    \n",
    "    def call(self, inputs, extract_feature=False,):\n",
    "#         x_data, y_data = inputs\n",
    "        x = self.log_line_encoder(inputs)\n",
    "        seq_embedding = self.log_seq_encoder(x)\n",
    "        \n",
    "        if  extract_feature:\n",
    "            output = seq_embedding\n",
    "        else:\n",
    "            output = self.classifier(seq_embedding)\n",
    "        return output\n",
    "    \n",
    "log_classifier = LogClassifier()\n",
    "log_classifier(sample_x_train)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e8cfdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classifier assigned low probability to all the classes since it is untrained\n",
    "# TODO: the mode should accept a single sequence. At present it is accepting only a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49716473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"log_classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_line_encoder_1 (LogLineE multiple                  36918     \n",
      "_________________________________________________________________\n",
      "log_seq_encoder_1 (LogSeqEnc multiple                  38096     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  68        \n",
      "=================================================================\n",
      "Total params: 75,082\n",
      "Trainable params: 75,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "log_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df0c264a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method LogLineEncoder.call of <__main__.LogLineEncoder object at 0x000001A45F2752E0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method LogLineEncoder.call of <__main__.LogLineEncoder object at 0x000001A45F2752E0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LogSeqEncoder.call of <__main__.LogSeqEncoder object at 0x000001A45F275EE0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method LogSeqEncoder.call of <__main__.LogSeqEncoder object at 0x000001A45F275EE0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier/log_seq_encoder_1/conv1d_9/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_9/bias:0', 'log_classifier/log_seq_encoder_1/conv1d_10/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_10/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier/log_seq_encoder_1/conv1d_9/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_9/bias:0', 'log_classifier/log_seq_encoder_1/conv1d_10/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_10/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier/log_seq_encoder_1/conv1d_9/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_9/bias:0', 'log_classifier/log_seq_encoder_1/conv1d_10/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_10/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier/log_seq_encoder_1/conv1d_9/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_9/bias:0', 'log_classifier/log_seq_encoder_1/conv1d_10/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_10/bias:0'] when minimizing the loss.\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.4113 - accuracy: 0.8644 - precision: 0.9704 - recall: 0.7172 - val_loss: 0.0197 - val_accuracy: 0.9970 - val_precision: 0.9985 - val_recall: 0.9955\n"
     ]
    }
   ],
   "source": [
    "# This is to check that the model's built in  complile and fit is working well\n",
    "log_classifier.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "hist = log_classifier.fit(train_data, validation_data=test_data, epochs=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5034247b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       "array([[7.60580369e-05, 2.69009047e-06, 1.02337904e-03, 9.98897791e-01],\n",
       "       [9.99056160e-01, 5.29905141e-04, 8.74223915e-05, 3.26555717e-04],\n",
       "       [7.98910558e-01, 3.62408906e-02, 2.36578919e-02, 1.41190618e-01],\n",
       "       [9.99064624e-01, 5.99953171e-04, 8.24591043e-05, 2.53109116e-04],\n",
       "       [2.71843077e-04, 1.46409031e-03, 9.95238781e-01, 3.02519766e-03],\n",
       "       [1.31694088e-03, 9.98520672e-01, 3.33402349e-05, 1.29078122e-04],\n",
       "       [2.46036245e-04, 7.63872988e-04, 9.91047323e-01, 7.94285163e-03],\n",
       "       [4.08728738e-05, 1.02642689e-05, 8.79703730e-04, 9.99069154e-01],\n",
       "       [6.60562073e-05, 4.30192704e-05, 3.03573534e-03, 9.96855140e-01],\n",
       "       [2.94254348e-03, 4.72355224e-02, 8.44164714e-02, 8.65405440e-01],\n",
       "       [1.23585924e-03, 9.98609424e-01, 3.16517253e-05, 1.22916113e-04],\n",
       "       [9.98518765e-01, 8.18154440e-05, 4.18232870e-04, 9.81201883e-04],\n",
       "       [4.19493852e-04, 2.11013737e-03, 9.60133038e-03, 9.87868965e-01],\n",
       "       [1.37044908e-03, 9.98458385e-01, 3.16590122e-05, 1.39533935e-04],\n",
       "       [9.97715354e-01, 7.35495123e-05, 3.38888000e-04, 1.87226187e-03],\n",
       "       [9.97715354e-01, 7.35495123e-05, 3.38888000e-04, 1.87226187e-03],\n",
       "       [4.00857571e-05, 1.42308591e-05, 1.24531658e-03, 9.98700380e-01],\n",
       "       [1.29641313e-03, 9.98534679e-01, 3.40942970e-05, 1.34864851e-04],\n",
       "       [9.99072909e-01, 5.94245794e-04, 8.13293809e-05, 2.51464546e-04],\n",
       "       [1.03405066e-04, 4.62728894e-06, 1.23246072e-03, 9.98659492e-01],\n",
       "       [9.99110043e-01, 5.48975426e-04, 7.58168608e-05, 2.65173265e-04],\n",
       "       [4.34115413e-04, 1.21453160e-03, 9.83072519e-01, 1.52787799e-02],\n",
       "       [9.99116480e-01, 5.58284984e-04, 7.83588912e-05, 2.46880285e-04],\n",
       "       [2.43744489e-05, 9.99946356e-01, 8.95569701e-06, 2.03954860e-05],\n",
       "       [2.56771127e-05, 9.97699082e-01, 1.28944684e-03, 9.85768973e-04],\n",
       "       [1.45037076e-04, 4.15414805e-04, 1.98940397e-03, 9.97450173e-01],\n",
       "       [9.99060571e-01, 5.69024705e-04, 8.48007257e-05, 2.85615126e-04],\n",
       "       [3.09004012e-04, 1.04067463e-03, 9.96437669e-01, 2.21269205e-03],\n",
       "       [6.92645903e-04, 2.23520515e-03, 1.42816767e-01, 8.54255319e-01],\n",
       "       [9.99108255e-01, 5.66824398e-04, 7.72411804e-05, 2.47658318e-04],\n",
       "       [1.34311605e-03, 9.98493314e-01, 3.16870028e-05, 1.31880064e-04],\n",
       "       [9.97715354e-01, 7.35495123e-05, 3.38888000e-04, 1.87226187e-03]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now after the training the predeicitoin will show higher probability to the \n",
    "# a class and lesser probability to other classes\n",
    "log_classifier(sample_x_train)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8a47dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape: (32, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 16), dtype=float32, numpy=\n",
       "array([[ 0.        ,  0.5871825 ,  0.        ,  0.        ,  0.34673932,\n",
       "         0.        ,  8.606613  ,  2.5149047 ,  0.        ,  0.        ,\n",
       "        10.062949  ,  3.454819  , 12.330506  ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 5.323514  ,  8.875267  ,  0.        ,  0.        ,  4.44558   ,\n",
       "         0.        ,  5.3081484 , 10.493349  ,  0.        ,  7.499896  ,\n",
       "         1.7070572 ,  3.0301955 ,  3.6977694 ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 3.8707469 ,  5.8908477 ,  0.        ,  0.        ,  2.8829777 ,\n",
       "         0.        ,  5.878939  ,  7.3715367 ,  0.        ,  5.5164213 ,\n",
       "         3.551658  ,  4.6453    ,  7.011702  ,  0.        ,  0.        ,\n",
       "         0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = log_classifier(sample_x_train, extract_feature=True ) \n",
    "print('features.shape:', features.shape)\n",
    "features[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18d8e2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e22b5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]\n",
      "\n",
      " [[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]\n",
      "\n",
      " [[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]\n",
      "\n",
      " [[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]\n",
      "\n",
      " [[ 3 20  3 ...  3  8  9]\n",
      "  [10  8  7 ...  8  4 14]\n",
      "  [12  3  6 ... 12  6 18]\n",
      "  ...\n",
      "  [ 3 20  3 ...  3  8  9]\n",
      "  [10  8  7 ...  8  4 14]\n",
      "  [12  3  6 ... 12  6 18]]], shape=(32, 32, 64), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]], shape=(32, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_data:\n",
    "    x_train, y_train = batch\n",
    "    print(x_train)\n",
    "    print(y_train)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da1ac59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centriods initialized: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "total_labels initialized: [0. 0. 0. 0.]\n",
      "centroids: [[ 4.46113159  8.66170288  0.          0.          4.52110077  0.\n",
      "   5.7082959   9.75568176  0.          7.23651123  2.17397827  3.18548706\n",
      "   4.32208893  0.          0.          0.        ]\n",
      " [ 7.16514893  2.00884033  0.          0.          1.42561722  0.\n",
      "   2.87550415  8.80388062  0.          6.78546265  0.40732346  6.28099854\n",
      "   7.50482544  0.          0.          0.03961719]\n",
      " [ 0.19467258  0.02143901  0.          0.          1.57748123  0.\n",
      "   4.63262024  0.77323769  0.          3.89771362  6.93959778  7.18499756\n",
      "   7.57732971  0.          0.          4.32237976]\n",
      " [ 0.56491795  0.38422638  0.          0.          0.34734833  0.\n",
      "   7.69043091  3.06733826  0.          0.70252678  8.42969543  4.10188232\n",
      "  11.40448486  0.          0.          0.37472347]]\n",
      "total_labels: [[800.]\n",
      " [800.]\n",
      " [800.]\n",
      " [800.]]\n"
     ]
    }
   ],
   "source": [
    "centroids = np.zeros((train_data.element_spec[1].shape[1],   16))\n",
    "print('centriods initialized:', centroids)\n",
    "total_labels = np.zeros(train_data.element_spec[1].shape[1]) # it was 4\n",
    "# total_labels[2] += 1\n",
    "# total_labels[2] += 1\n",
    "print('total_labels initialized:', total_labels)\n",
    "for batch in train_data: # Remember <BatchDataset shapes: ((32, 32, 64), (32, 4)), types: (tf.int32, tf.float32)>\n",
    "    logseq_batch, label_batch = batch\n",
    "    # (32, 32, 64), (32, 4)\n",
    "    features = log_classifier(logseq_batch, extract_feature=True )\n",
    "    # (32, 16) features - 32 sequence of line each haaving 64 characrers\n",
    "    # produces a feaure vector of dimension 16. \n",
    "    for i in range(len(label_batch)): # (32, 4) --> here length is 32\n",
    "        label = label_batch[i] # label looks like [0 0 0 1]\n",
    "        numeric_label = np.argmax(label) # index position of the label = 3 , so it is actually class =3\n",
    "        ##total_labels = [0 0 0 0] each col representing a class \n",
    "        ## count the number for each class\n",
    "        total_labels[numeric_label] += 1 \n",
    "        centroids[numeric_label] += features[i] \n",
    "        # each row index in the centroid array is a class\n",
    "        # we add first identify the feature belonging to which class by the numeric_label\n",
    "        # Then add all the features belonging to the class in the corresponding row of the centroid array\n",
    "\n",
    "### shape of centroids is (4, 16) whereas shape of total_labels is (1, 4)\n",
    "### reshape the total_labels as 4,1 ==> [[0], [0], [0], [0]]==> 4 rows \n",
    "## so that we can divide the centroids array by the total_labels\n",
    "total_label_reshaped = np.reshape(total_labels, (train_data.element_spec[1].shape[1], 1))\n",
    "centroids /= total_label_reshaped\n",
    "print('centroids:',centroids)\n",
    "print('total_labels:',total_label_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07596a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n2 is 3 rows and each row has a vector of 4 cols:\n",
      " [[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "n3, is one single row:\n",
      "  [2 2 2]\n",
      "one single row is now converted to three rows, n4:\n",
      " [[2]\n",
      " [2]\n",
      " [2]]\n",
      "now division between n2: (3, 4) and n4: (3, 1) is possible\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.5, 1. , 1.5],\n",
       "       [2. , 2.5, 3. , 3.5],\n",
       "       [4. , 4.5, 5. , 5.5]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to understand the np divide operation\n",
    "n1 = np.arange(12)\n",
    "n2 = n1.reshape((3, 4))\n",
    "print('n2 is 3 rows and each row has a vector of 4 cols:\\n', n2)\n",
    "n3 = np.array([2, 2, 2])\n",
    "print('n3, is one single row:\\n ', n3)\n",
    "n4 = np.reshape(n3, (3, 1))\n",
    "print('one single row is now converted to three rows, n4:\\n', n4)\n",
    "print(f'now division between n2: {n2.shape} and n4: {n4.shape} is possible')\n",
    "n2/n4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad831f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_x_train[0] tf.Tensor(\n",
      "[[10  5 14 ...  2  2 11]\n",
      " [10  5 14 ... 26  2 19]\n",
      " [10  5 14 ... 23  2 23]\n",
      " ...\n",
      " [ 4 27 19 ...  9  0  0]\n",
      " [12  3  6 ... 12  6 18]\n",
      " [ 4 27 19 ...  9  0  0]], shape=(32, 64), dtype=int32)\n",
      "sample_y_train[0] tf.Tensor([0. 0. 0. 1.], shape=(4,), dtype=float32)\n",
      "feature for the same: tf.Tensor(\n",
      "[3.7446022 0.5150217 0.        0.        0.6712336 0.        2.7540977\n",
      " 5.176922  0.        4.8775744 2.0351896 6.470668  7.589819  0.\n",
      " 0.        0.4365957], shape=(16,), dtype=float32)\n",
      "centroid for the class 3 : [ 0.56491795  0.38422638  0.          0.          0.34734833  0.\n",
      "  7.69043091  3.06733826  0.          0.70252678  8.42969543  4.10188232\n",
      " 11.40448486  0.          0.          0.37472347]\n"
     ]
    }
   ],
   "source": [
    "#take zi and a ck \n",
    "# from sample_x_train the first sample belongs to class 3\n",
    "print('sample_x_train[0]', sample_x_train[0])\n",
    "sample_y_train = sample_train_data[1]\n",
    "print('sample_y_train[0]', sample_y_train[0])\n",
    "print('feature for the same:', features[0])\n",
    "print('centroid for the class 3 :', centroids[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d5f7eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eucladian distance: 117.537506\n"
     ]
    }
   ],
   "source": [
    "# eucladian distance \n",
    "#first sample belonging to class 3 = z_0_3, dimension of it is same as the dense neuron=16\n",
    "z_0_3= features[0] # [16], earlier [2048]\n",
    "C_3 = centroids[3] # [16], earlier [2048]\n",
    "ED = np.sum(np.square(z_0_3 - C_3 ))\n",
    "print('eucladian distance:', ED)\n",
    "# InvalidArgumentError: Incompatible shapes: [32,64] vs. [2048] [Op:Sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66ab11e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one feature with dimension 5 , f1:\n",
      " [20 21 22 23 24]\n",
      "centroid, ctd with 4 class :\n",
      " [[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]]\n",
      "\n",
      "sub_result, for each feature we have 4 rows after substraction:\n",
      " [[20 20 20 20 20]\n",
      " [15 15 15 15 15]\n",
      " [10 10 10 10 10]\n",
      " [ 5  5  5  5  5]]\n",
      "the 4 rows of the result are the distance of the feature from the centroid of each class\n",
      "distance of f1 from centroid of class_0: [20 20 20 20 20]\n",
      "distance of f1 from centroid of class_1: [15 15 15 15 15]\n",
      "distance of f1 from centroid of class_2: [10 10 10 10 10]\n",
      "distance of f1 from centroid of class_3: [5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "# lets f1 is one feature from a batch of 32\n",
    "# instead of 16, lets say the dimension of f1 is 5\n",
    "f1 = np.arange(20, 25)\n",
    "# a1 = np.reshape(a1, (4, 3) )\n",
    "print('one feature with dimension 5 , f1:\\n', f1)\n",
    "### lets say ctd is the centroids with 4 class , each row is a class \n",
    "ctd = np.arange(20)\n",
    "ctd = np.reshape(ctd, (4, 5))\n",
    "print('centroid, ctd with 4 class :\\n', ctd)\n",
    "sub_result = f1 - ctd\n",
    "print()\n",
    "print('sub_result, for each feature we have 4 rows after substraction:\\n', sub_result)\n",
    "print('the 4 rows of the result are the distance of the feature from the centroid of each class')\n",
    "for i, row in enumerate(sub_result):\n",
    "    print(f'distance of f1 from centroid of class_{i}: {row}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56b4c9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squared_substraction:\n",
      " [[400 400 400 400 400]\n",
      " [225 225 225 225 225]\n",
      " [100 100 100 100 100]\n",
      " [ 25  25  25  25  25]]\n",
      "sum_squared_substraction:\n",
      " [2000 1125  500  125]\n"
     ]
    }
   ],
   "source": [
    "# to get the eucladian distance, calculate squared substraction\n",
    "squared_substraction = np.square(sub_result)\n",
    "print('squared_substraction:\\n', squared_substraction)\n",
    "#### eucladian distance of f1 from each class represented by a vector of 5 dimension\n",
    "### those 5 values from the vector is summed up tp get a scalar value \n",
    "sum_squared_substraction = np.sum(np.square(sub_result), axis=1)\n",
    "print('sum_squared_substraction:\\n', sum_squared_substraction )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3eadff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape (32, 16)\n",
      "centroids.shape (4, 16)\n",
      "np.expand_dims(features, axis=1) : (32, 1, 16)\n",
      "np.expand_dims(centroids, axis=0): (1, 4, 16)\n",
      "sub_z_C , for each feature 4 results: (32, 4, 16)\n",
      "squred_sum (32, 4)\n",
      "Eucaldian distance of first feature from the 4 classes:\n",
      " [138.6405687   34.1610741   77.21127719 117.537506  ]\n"
     ]
    }
   ],
   "source": [
    "### the abobe example is for a single feature , how to do this for all the features\n",
    "# can we substract centroids array from the entire feature array? \n",
    "# we can not substract different shaped arrays , see the error\n",
    "print('features.shape', features.shape) # ## features.shape (32, 16)\n",
    "print('centroids.shape', centroids.shape)  ##centroids.shape (4, 16)\n",
    "# features - centroids # InvalidArgumentError: Incompatible shapes: [32,16] vs. [4,16] [Op:Sub]\n",
    "#### substraction is elementwise substraction. so we both the array have to equal shape\n",
    "z = np.expand_dims(features, axis=1) ## (32, 1, 16)\n",
    "C =  np.expand_dims(centroids, axis=0) ### (1, 4, 16)\n",
    "print('np.expand_dims(features, axis=1) :', z.shape)\n",
    "print('np.expand_dims(centroids, axis=0):', C.shape)\n",
    "# print('first dimenstion of C:',C[0])\n",
    "# Now we can substract\n",
    "sub_z_C = z - C\n",
    "print('sub_z_C , for each feature 4 results:', sub_z_C.shape)\n",
    "squred_sum = np.sum(np.square(z- C), axis=2)\n",
    "print('squred_sum', squred_sum.shape)\n",
    "print('Eucaldian distance of first feature from the 4 classes:\\n',squred_sum[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "babc7032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th element from the last bath retrieved from data iteration previously:\n",
      " tf.Tensor(\n",
      "[3.7446022 0.5150217 0.        0.        0.6712336 0.        2.7540977\n",
      " 5.176922  0.        4.8775744 2.0351896 6.470668  7.589819  0.\n",
      " 0.        0.4365957], shape=(16,), dtype=float32)\n",
      "label for the feature_0:\n",
      " tf.Tensor([0. 1. 0. 0.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# from the data iteration done beforem we will have the last features and the last label_batch\n",
    "## lets see what is the label for the 0th element in that batch\n",
    "print('0th element from the last bath retrieved from data iteration previously:\\n', features[0])\n",
    "print('label for the feature_0:\\n', label_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35282970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here eucladian distance of the first feature is least from the class_0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e629b35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED_logits (32, 4)\n",
      "ED_logits_sample [-138.6405687   -34.1610741   -77.21127719 -117.537506  ]\n"
     ]
    }
   ],
   "source": [
    "# make the dimensions same for substraction\n",
    "def euclidean_metric(a, b):\n",
    "    a = np.expand_dims(a, 1)\n",
    "    b = np.expand_dims(b, 0)\n",
    "#     logits = -((a - b)**2).sum(dim=2)\n",
    "    logits = np.sum(-np.square(a - b), axis=2)\n",
    "    return logits  \n",
    "\n",
    "ED_logits = euclidean_metric(features, centroids)\n",
    "print('ED_logits', ED_logits.shape)\n",
    "print('ED_logits_sample', ED_logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "361e71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### we got the same result only in negative sign \n",
    "# these four eucladian values can be taken as softmax \n",
    "# to convert it as probability amonghst the four\n",
    "# Then the max value ( that is why -ve sign will help)\n",
    "# will represent the class with highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52f2328b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]], shape=(2, 5), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([4, 4], dtype=int64)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.range(10)\n",
    "t = tf.reshape(t, (2, 5))\n",
    "print(t)\n",
    "tf.argmax(t, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6326a5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 9])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can we get the max value instead of the index\n",
    "tf.reduce_max(t, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d662059e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smax.shape: (32, 4)\n",
      "smax_sample: [4.21824716e-46 1.00000000e+00 2.01156632e-19 6.16702497e-37]\n",
      "class_idx_having_minimum_distance: 1\n",
      "smax_sample: [1.00000000e+000 6.53537337e-043 5.75224427e-095 1.32068225e-102]\n",
      "class_idx_having_minimum_distance: 0\n",
      "smax_sample: [1.01619355e-71 1.00000000e+00 3.10280417e-79 5.70993531e-97]\n",
      "class_idx_having_minimum_distance: 1\n",
      "smax_sample: [2.12776013e-123 2.48075853e-092 1.00000000e+000 2.08047429e-021]\n",
      "class_idx_having_minimum_distance: 2\n",
      "smax_sample: [1.87884160e-019 1.00000000e+000 5.70233072e-119 5.26682800e-132]\n",
      "class_idx_having_minimum_distance: 1\n"
     ]
    }
   ],
   "source": [
    "# smax = tf.nn.softmax(ED_logits, axis=1)\n",
    "smax = tf.nn.softmax(ED_logits, )\n",
    "print('smax.shape:', smax.shape)\n",
    "class_idx_having_minimum_distance = tf.math.argmax(smax, axis=1)\n",
    "for i in range(5):    \n",
    "    print('smax_sample:', smax[i].numpy())\n",
    "    print('class_idx_having_minimum_distance:', class_idx_having_minimum_distance[i].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea7ba418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for the feature_0:\n",
      " tf.Tensor([0. 1. 0. 0.], shape=(4,), dtype=float32)\n",
      "label_indexs.shape (32,)\n",
      "sample label_indexes [1 0 1 2 1]\n",
      "centroids.shape: (4, 16)\n",
      "c.shape: (32, 16)\n",
      "[7.16514893 2.00884033 0.         0.         1.42561722 0.\n",
      " 2.87550415 8.80388062 0.         6.78546265 0.40732346 6.28099854\n",
      " 7.50482544 0.         0.         0.03961719]\n"
     ]
    }
   ],
   "source": [
    "print('label for the feature_0:\\n', label_batch[0])\n",
    "label_indexs = np.argmax(label_batch, axis=1)\n",
    "print('label_indexs.shape', label_indexs.shape)\n",
    "print('sample label_indexes',label_indexs[:5])\n",
    "print('centroids.shape:', centroids.shape)\n",
    "c = centroids[label_indexs]\n",
    "print('c.shape:', c.shape)\n",
    "print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "986d553d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n",
      "a[0]:\n",
      " [0 1 2]\n",
      "\n",
      "b.shape:\n",
      " (16,)\n",
      "b:\n",
      " [0 1 2 3 0 1 2 3 0 1 2 3 0 1 2 3]\n",
      "\n",
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "### To understand this lets take simple example\n",
    "a = np.arange(12).reshape((4, 3))\n",
    "print('a:\\n',a)\n",
    "# print(a.shape)\n",
    "print('a[0]:\\n',a[0])\n",
    "print()\n",
    "# we create a index whose dimension is higher than a \n",
    "b = np.tile([0, 1, 2, 3], (4))\n",
    "print('b.shape:\\n',b.shape)\n",
    "# b = 16 but a is having 4 rows\n",
    "print('b:\\n',b)\n",
    "#Notice that each element of b is wihin 0-3 , matching with the max row of a.\n",
    "# the slicing can be done now as:\n",
    "print()\n",
    "print(a[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44e01a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 16)\n",
      "euc_dis (32,)\n",
      "distance: [-3.4205465  -1.4938186   0.          0.         -0.7543836   0.\n",
      " -0.12140656 -3.6269588   0.         -1.9078884   1.6278661   0.18966913\n",
      "  0.08499336  0.          0.          0.39697853]\n",
      " eucladian distance:5.844747543334961\n",
      "\n",
      "distance: [-1.2603054  -0.23462582  0.          0.          0.1492467   0.\n",
      "  0.605216   -1.0990686   0.         -0.25971603  0.7028725   0.24417925\n",
      "  0.42120457  0.          0.          0.        ]\n",
      " eucladian distance:2.009589672088623\n",
      "\n",
      "distance: [ 0.7309618  -2.0088403   0.          0.         -1.4256172   0.\n",
      " -0.9356859  -0.90286875  0.         -0.47712517 -0.40732345  2.0228868\n",
      "  1.4808378   0.          0.         -0.03961718]\n",
      " eucladian distance:3.8694825172424316\n",
      "\n",
      "distance: [-0.07835517 -0.02143901  0.          0.          0.29268885  0.\n",
      "  1.1425757  -0.37526575  0.         -0.67999434  0.69184303  0.35110903\n",
      "  1.0615816   0.          0.         -0.5192516 ]\n",
      " eucladian distance:1.999866008758545\n",
      "\n",
      "distance: [ 1.2735462   2.2546427   0.          0.          1.3629808   0.\n",
      "  0.3292539   2.5911865   0.          1.2869325  -0.40732345 -1.0949335\n",
      " -0.8094425   0.          0.         -0.03961718]\n",
      " eucladian distance:4.366171836853027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remeber c = centroids[label_indexs]\n",
    "# only the centroid of the class corresponding to the feature\n",
    "# earlier we had to expand dimension becuase centroid contained all the \n",
    "# four classes\n",
    "dis = features - c \n",
    "print(dis.shape)\n",
    "euc_dis = tf.norm(features - c, ord='euclidean', axis=1,)\n",
    "print('euc_dis', euc_dis.shape)\n",
    "for d, ed in zip(dis[:5], euc_dis[:5]):\n",
    "    print(f'distance: {d.numpy()}\\n eucladian distance:{ed.numpy()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5e7f1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d <tf.Variable 'Variable:0' shape=(4, 1) dtype=float32, numpy=\n",
      "array([[-0.00879526],\n",
      "       [-0.01946589],\n",
      "       [ 0.00327438],\n",
      "       [-0.00953929]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# # torch.randn, Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 (also called the standard normal distribution).\n",
    "# w_init = tf.random.normal([4],0, 1, tf.float32)\n",
    "# print('w_init Outputs random values from a normal distribution.', w_init)\n",
    "# w_init = tf.random.normal((4),0, 1, tf.float32)\n",
    "\n",
    "### shape (4, 1 ) for delta  = 4 rows for the four classes\n",
    "w_init = tf.random_normal_initializer()\n",
    "w_init(shape=(4, 1), dtype='float32')\n",
    "\n",
    "d = tf.Variable(\n",
    "    initial_value=w_init(shape=(4, 1), dtype='float32'),\n",
    "    trainable=True,\n",
    ")\n",
    "print('d', d)\n",
    "\n",
    "# w_init = tf.random_normal_initializer()\n",
    "# self.w = tf.Variable(\n",
    "#     initial_value=w_init(shape=(input_shape[-1], self.units),\n",
    "#                          dtype='float32'),\n",
    "#     trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c202b6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_mask tf.Tensor(\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False], shape=(32,), dtype=bool)\n",
      "neg_mask tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(32,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "neg_mask = euc_dis < 1\n",
    "print('neg_mask', neg_mask)\n",
    "neg_mask = tf.dtypes.cast(neg_mask, tf.float32)\n",
    "print('neg_mask', neg_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a34de3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_loss tf.Tensor(\n",
      "[[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      "  -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      "  -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      "  -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      "  -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]], shape=(4, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# neg_loss = neg_loss * neg_mask\n",
    "# InvalidArgumentError: cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a bool tensor [Op:Mul]\n",
    "neg_loss = (d - euc_dis) * neg_mask\n",
    "print('neg_loss', neg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29b10573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_mask tf.Tensor(\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True], shape=(32,), dtype=bool)\n",
      "pos_mask tf.Tensor(\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.], shape=(32,), dtype=float32)\n",
      "pos_mask tf.Tensor(\n",
      "[[ 5.853543   2.018385   3.8782778  2.0086613  4.374967   2.0525532\n",
      "   1.7472624  4.395158   2.0699341  1.5119164  2.4587846  4.973954\n",
      "   2.4292662  2.4587846  4.3594375  1.9662555  4.2746615  2.4587846\n",
      "   2.4587846  3.8782778  1.6274182  2.4292662  1.6723603  2.4292662\n",
      "   1.8506229  2.2431033  2.0823798  1.8593949 10.188647   2.4608955\n",
      "   3.8782778  2.207465 ]\n",
      " [ 5.8642135  2.0290556  3.8889484  2.019332   4.3856378  2.0632238\n",
      "   1.757933   4.4058285  2.0806048  1.5225871  2.4694552  4.984625\n",
      "   2.4399369  2.4694552  4.370108   1.9769262  4.285332   2.4694552\n",
      "   2.4694552  3.8889484  1.6380888  2.4399369  1.683031   2.4399369\n",
      "   1.8612936  2.253774   2.0930505  1.8700656 10.199318   2.4715662\n",
      "   3.8889484  2.2181356]\n",
      " [ 5.841473   2.0063152  3.866208   1.9965916  4.3628974  2.0404835\n",
      "   1.7351928  4.383088   2.0578644  1.4998467  2.4467149  4.9618845\n",
      "   2.4171965  2.4467149  4.347368   1.954186   4.262592   2.4467149\n",
      "   2.4467149  3.866208   1.6153486  2.4171965  1.6602907  2.4171965\n",
      "   1.8385532  2.2310336  2.07031    1.8473253 10.1765785  2.4488258\n",
      "   3.866208   2.1953952]\n",
      " [ 5.8542867  2.019129   3.879022   2.0094054  4.375711   2.0532973\n",
      "   1.7480063  4.3959017  2.0706782  1.5126604  2.4595287  4.974698\n",
      "   2.4300103  2.4595287  4.3601813  1.9669995  4.2754054  2.4595287\n",
      "   2.4595287  3.879022   1.6281621  2.4300103  1.6731043  2.4300103\n",
      "   1.8513669  2.2438474  2.083124   1.8601389 10.189392   2.4616396\n",
      "   3.879022   2.208209 ]], shape=(4, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pos_mask = euc_dis > 1\n",
    "print('pos_mask', pos_mask)\n",
    "pos_mask = tf.dtypes.cast(pos_mask, tf.float32)\n",
    "print('pos_mask', pos_mask)\n",
    "pos_loss = (euc_dis - d) * pos_mask\n",
    "print('pos_mask', pos_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48c1eb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([3.017399 , 3.0280685, 3.0053294, 3.0181422], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(pos_loss, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55b1753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundaryLoss(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_labels=train_data.element_spec[1].shape[1], \n",
    "                feat_dim = 16):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.feat_dim = feat_dim\n",
    "        # initializing the delta boundary (4,1 shape is for 4 classes 4 number of scaler value)\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.delta = tf.Variable(\n",
    "                            initial_value=w_init(shape=(4, 1), dtype='float32'),\n",
    "                            trainable=True,\n",
    "                        )\n",
    "        \n",
    "    def call(self, features, centroids, labels):\n",
    "        logits =  euclidean_metric(features, centroids)  \n",
    "        ######### Why softmax before softplus#########\n",
    "        smax = tf.nn.softmax(logits, )\n",
    "        # this is equivallent to predicting the feature belong to which class\n",
    "        preds = tf.math.argmax(smax, axis=1)\n",
    "        # This is equivallent to obtaining the max probabiliy of a feature belonging to a calss\n",
    "        probs = tf.reduce_max(smax, 1)        \n",
    "        ############################\n",
    "        # delta =  log(1 + e ^ delta_k) , delta_k =self.delta = parameters for the boundary\n",
    "        delta = tf.nn.softplus(self.delta)  \n",
    "#         label_indexs = np.argmax(label_batch, axis=1)\n",
    "        label_indexs = np.argmax(labels, axis=1)\n",
    "        # centroids are having only 4 rows , whereas labels are rows equivallent to batch\n",
    "        # pick-up the centroid for each class \n",
    "        # label_index from the data set will have all the classes, 32 for a batch\n",
    "        # for each class cetroid[class_index] will give the centroid of the calss\n",
    "        # it is basically : [centroids[class_idx] for class_idx in label_indexes]\n",
    "        c = centroids[label_indexs]\n",
    "        # similarly get the delta for each class, \n",
    "        # although delta is now randomly intialized \n",
    "        # delta parameters will be learned through the training\n",
    "        d = delta[label_indexs]\n",
    "        x = features\n",
    "        # x-c = vector of (32, 16) dimension , euc_dis  = scalar value\n",
    "        euc_dis = tf.norm(x - c, ord='euclidean', axis=1)        \n",
    "        ##If axis is None (the default), the input is considered a vector and a \n",
    "        ## single vector norm is computed over the entire set of values in the tensor, \n",
    "        ## i.e. norm(tensor, ord=ord) is equivalent to norm(reshape(tensor, [-1]), ord=ord). \n",
    "        ##If axis is a Python integer, the input is considered a batch of vectors, and axis determines the axis in tensor over which to compute vector norms.\n",
    "        pos_mask = tf.dtypes.cast(euc_dis > d, tf.int32)\n",
    "        neg_mask = tf.dtypes.cast(euc_dis < d, tf.int32)\n",
    "        # euc_dis > d should be ==>1 and euc_dis <= d should be ==>0\n",
    "        # but the expression here will it retrun True , False or 1 and 0. \n",
    "        pos_loss = (euc_dis - d) * pos_mask\n",
    "        neg_loss = (d - euc_dis) * neg_mask\n",
    "        loss = tf.reduce_mean(pos_loss, axis=1) + tf.reduce_mean(neg_loss, axis=1)\n",
    "        \n",
    "        return loss, delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0eec2e",
   "metadata": {},
   "source": [
    "## Boundary Loss looks good - every line we have tested and found a logic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a288a51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f42b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand this , a= features(batch_size, 2048) , b = centroids (4, 2048)\n",
    "def euclidean_metric_torch(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    a = a.unsqueeze(1).expand(n, m, -1)\n",
    "    b = b.unsqueeze(0).expand(n, m, -1)\n",
    "    logits = -((a - b)**2).sum(dim=2)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcf46955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [[0 1 2]\n",
      " [3 4 5]]\n",
      "a.shape (2, 3)\n",
      "b [ 8  9 10 11 12 13 14 15]\n",
      "b [[ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]]\n",
      "b.shape: (4, 2)\n",
      "tfa tf.Tensor(\n",
      "[[0 1 2]\n",
      " [3 4 5]], shape=(2, 3), dtype=int32)\n",
      "tfb tf.Tensor(\n",
      "[[ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]], shape=(4, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "a = np.arange(6)\n",
    "a = a.reshape((2, -1))\n",
    "print('a:', a)\n",
    "print('a.shape', a.shape)\n",
    "b = np.arange(8, 16)\n",
    "print('b',b)\n",
    "b = np.reshape(b, (4, -1))\n",
    "print('b',b)\n",
    "print('b.shape:',b.shape)\n",
    "tfa = tf.constant(a)\n",
    "tfb = tf.constant(b)\n",
    "print('tfa',tfa)\n",
    "print('tfb',tfb)\n",
    "# n = tfa.shape[0]\n",
    "# m = b.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b05e05cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.expand_dims(tfa, 0) : tf.Tensor(\n",
      "[[[0 1 2]\n",
      "  [3 4 5]]], shape=(1, 2, 3), dtype=int32)\n",
      "\n",
      "tf.expand_dims(tfa, 1) : tf.Tensor(\n",
      "[[[0 1 2]]\n",
      "\n",
      " [[3 4 5]]], shape=(2, 1, 3), dtype=int32)\n",
      "\n",
      "tf.expand_dims(tfa, 1) : tf.Tensor(\n",
      "[[[0]\n",
      "  [1]\n",
      "  [2]]\n",
      "\n",
      " [[3]\n",
      "  [4]\n",
      "  [5]]], shape=(2, 3, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print('tf.expand_dims(tfa, 0) :',tf.expand_dims(tfa, 0))\n",
    "print()\n",
    "print('tf.expand_dims(tfa, 1) :',tf.expand_dims(tfa, 1))\n",
    "print()\n",
    "print('tf.expand_dims(tfa, 1) :',tf.expand_dims(tfa, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22bda5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.shape(tfa): [2 1 3]\n",
      "tf.shape(tfb): [1 4 2]\n"
     ]
    }
   ],
   "source": [
    "tfa = tf.expand_dims(tfa, 1)\n",
    "print(f'tf.shape(tfa): {tf.shape(tfa)}')\n",
    "tfb = tf.expand_dims(tfb, 0)\n",
    "print(f'tf.shape(tfb): {tf.shape(tfb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45f35f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfa_broadcast tf.Tensor(\n",
      "[[[0 1 2]\n",
      "  [0 1 2]\n",
      "  [0 1 2]\n",
      "  [0 1 2]]\n",
      "\n",
      " [[3 4 5]\n",
      "  [3 4 5]\n",
      "  [3 4 5]\n",
      "  [3 4 5]]], shape=(2, 4, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "n = a.shape[0]\n",
    "m = b.shape[0]\n",
    "tfa_broadcast = tf.broadcast_to(tfa, [2, 4, 3])\n",
    "tf.shape(tfa_broadcast)\n",
    "print('tfa_broadcast',tfa_broadcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc5011e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "\n",
    "# The equivalent function for pytorch expand is tensorflow tf.broadcast_to\n",
    "\n",
    "# Docs: https://www.tensorflow.org/api_docs/python/tf/broadcast_to\n",
    "\n",
    "# Share\n",
    "# Follow\n",
    "# edited Oct 23, 2021 at 18:22\n",
    "\n",
    "# M.Innat\n",
    "# 12.2k66 gold badges3434 silver badges6767 bronze badges\n",
    "# answered Jan 4, 2019 at 9:12\n",
    "\n",
    "# funkyyyyyy\n",
    "# 6111 silver badge22 bronze badges\n",
    "# Add a comment\n",
    "\n",
    "# 0\n",
    "\n",
    "# Tensorflow automatically broadcasts, so in general you don't need to do any of this. Suppose you have a y' of shape 6x2x3 and your x is of shape 2x3, then you can already do y'*x or y'+x will already behave as if you had expanded it. But if for some other reason you really need to do it, then the command in tensorflow is tile:\n",
    "\n",
    "# y = tf.tile(tf.reshape(x, (1,2,3)), multiples=(6,1,1))\n",
    "# Docs: https://www.tensorflow.org/api_docs/python/tf/tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66c1e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def euclidean_metric(a, b):\n",
    "#     n = a.shape[0]\n",
    "#     m = b.shape[0]\n",
    "#     a = tf.expand_dims(a, 1)\n",
    "#     b = tf.expand_dims(b, 0)\n",
    "#     logits = -((a - b)**2).sum(dim=2)\n",
    "#     return logits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92988871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3076a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0fa24cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centriods initialized: tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(4, 16), dtype=float32)\n",
      "total_labels initialized: tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "centroids = tf.zeros((train_data.element_spec[1].shape[1],   16))\n",
    "print('centriods initialized:', centroids)\n",
    "total_labels = tf.zeros(train_data.element_spec[1].shape[1]) # it was 4\n",
    "# total_labels[2] += 1\n",
    "# total_labels[2] += 1\n",
    "print('total_labels initialized:', total_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef0be68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       "array([[-176.72165, -176.72165, -176.72165, -176.72165],\n",
       "       [-309.08383, -309.08383, -309.08383, -309.08383],\n",
       "       [-318.02924, -318.02924, -318.02924, -318.02924],\n",
       "       [-251.50241, -251.50241, -251.50241, -251.50241],\n",
       "       [-374.17014, -374.17014, -374.17014, -374.17014],\n",
       "       [-310.32132, -310.32132, -310.32132, -310.32132],\n",
       "       [-259.6144 , -259.6144 , -259.6144 , -259.6144 ],\n",
       "       [-376.63464, -376.63464, -376.63464, -376.63464],\n",
       "       [-256.6905 , -256.6905 , -256.6905 , -256.6905 ],\n",
       "       [-223.96918, -223.96918, -223.96918, -223.96918],\n",
       "       [-316.77362, -316.77362, -316.77362, -316.77362],\n",
       "       [-208.27956, -208.27956, -208.27956, -208.27956],\n",
       "       [-165.30278, -165.30278, -165.30278, -165.30278],\n",
       "       [-316.77362, -316.77362, -316.77362, -316.77362],\n",
       "       [-375.8573 , -375.8573 , -375.8573 , -375.8573 ],\n",
       "       [-309.35577, -309.35577, -309.35577, -309.35577],\n",
       "       [-371.0056 , -371.0056 , -371.0056 , -371.0056 ],\n",
       "       [-316.77362, -316.77362, -316.77362, -316.77362],\n",
       "       [-316.77362, -316.77362, -316.77362, -316.77362],\n",
       "       [-318.02924, -318.02924, -318.02924, -318.02924],\n",
       "       [-235.94925, -235.94925, -235.94925, -235.94925],\n",
       "       [-165.30278, -165.30278, -165.30278, -165.30278],\n",
       "       [-349.6338 , -349.6338 , -349.6338 , -349.6338 ],\n",
       "       [-165.30278, -165.30278, -165.30278, -165.30278],\n",
       "       [-257.72803, -257.72803, -257.72803, -257.72803],\n",
       "       [-352.1959 , -352.1959 , -352.1959 , -352.1959 ],\n",
       "       [-344.4232 , -344.4232 , -344.4232 , -344.4232 ],\n",
       "       [-333.1325 , -333.1325 , -333.1325 , -333.1325 ],\n",
       "       [-211.41093, -211.41093, -211.41093, -211.41093],\n",
       "       [-361.48364, -361.48364, -361.48364, -361.48364],\n",
       "       [-318.02924, -318.02924, -318.02924, -318.02924],\n",
       "       [-329.97244, -329.97244, -329.97244, -329.97244]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.expand_dims(features, 1)\n",
    "b = tf.expand_dims(centroids, 0)\n",
    "dis = a - b\n",
    "squred_dis = tf.math.square(a - b)\n",
    "logits = tf.math.reduce_sum(-squred_dis, axis=2)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da71ed16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       "array([[-176.72165, -176.72165, -176.72165, -176.72165],\n",
       "       [-309.08383, -309.08383, -309.08383, -309.08383],\n",
       "       [-318.02924, -318.02924, -318.02924, -318.02924],\n",
       "       [-251.50241, -251.50241, -251.50241, -251.50241],\n",
       "       [-374.17014, -374.17014, -374.17014, -374.17014],\n",
       "       [-310.32132, -310.32132, -310.32132, -310.32132],\n",
       "       [-259.6144 , -259.6144 , -259.6144 , -259.6144 ],\n",
       "       [-376.63464, -376.63464, -376.63464, -376.63464],\n",
       "       [-256.6905 , -256.6905 , -256.6905 , -256.6905 ],\n",
       "       [-223.96918, -223.96918, -223.96918, -223.96918],\n",
       "       [-316.77362, -316.77362, -316.77362, -316.77362],\n",
       "       [-208.27956, -208.27956, -208.27956, -208.27956],\n",
       "       [-165.30278, -165.30278, -165.30278, -165.30278],\n",
       "       [-316.77362, -316.77362, -316.77362, -316.77362],\n",
       "       [-375.8573 , -375.8573 , -375.8573 , -375.8573 ],\n",
       "       [-309.35577, -309.35577, -309.35577, -309.35577],\n",
       "       [-371.0056 , -371.0056 , -371.0056 , -371.0056 ],\n",
       "       [-316.77362, -316.77362, -316.77362, -316.77362],\n",
       "       [-316.77362, -316.77362, -316.77362, -316.77362],\n",
       "       [-318.02924, -318.02924, -318.02924, -318.02924],\n",
       "       [-235.94925, -235.94925, -235.94925, -235.94925],\n",
       "       [-165.30278, -165.30278, -165.30278, -165.30278],\n",
       "       [-349.6338 , -349.6338 , -349.6338 , -349.6338 ],\n",
       "       [-165.30278, -165.30278, -165.30278, -165.30278],\n",
       "       [-257.72803, -257.72803, -257.72803, -257.72803],\n",
       "       [-352.1959 , -352.1959 , -352.1959 , -352.1959 ],\n",
       "       [-344.4232 , -344.4232 , -344.4232 , -344.4232 ],\n",
       "       [-333.1325 , -333.1325 , -333.1325 , -333.1325 ],\n",
       "       [-211.41093, -211.41093, -211.41093, -211.41093],\n",
       "       [-361.48364, -361.48364, -361.48364, -361.48364],\n",
       "       [-318.02924, -318.02924, -318.02924, -318.02924],\n",
       "       [-329.97244, -329.97244, -329.97244, -329.97244]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def euclidean_metric(a, b):\n",
    "    a = tf.expand_dims(a, 1)\n",
    "    b = tf.expand_dims(b, 0)\n",
    "#     logits = -((a - b)**2).sum(dim=2)\n",
    "    logits = tf.math.reduce_sum(-tf.math.square(a - b), axis=2)\n",
    "    return logits\n",
    "euclidean_metric(features, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98f81c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to assign a new value to index position of a tensor\n",
    "total_labels # is a tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9155cf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.unstack(total_labels) # unstack it to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5297a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = tf.unstack(total_labels)\n",
    "## now assign values to index position of the list\n",
    "lst =  [1, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6077e3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 0, 0, 0])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert them to tensor again\n",
    "newtf = tf.stack(lst)\n",
    "newtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1718e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0a95a69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centroids: tf.Tensor(\n",
      "[[2.2333534  4.336265   0.         0.         2.2633772  0.\n",
      "  2.8577154  4.883939   0.         3.6227775  1.0883478  1.5947356\n",
      "  2.1637454  0.         0.         0.        ]\n",
      " [3.5870562  1.0056759  0.         0.         0.7136998  0.\n",
      "  1.439549   4.4074416  0.         3.396974   0.2039164  3.1444259\n",
      "  3.7571042  0.         0.         0.01983335]\n",
      " [0.09745792 0.01073291 0.         0.         0.7897265  0.\n",
      "  2.3192055  0.38710183 0.         1.9512906  3.4741373  3.5969954\n",
      "  3.7934008  0.         0.         2.1638904 ]\n",
      " [0.2828121  0.1923533  0.         0.         0.17389129 0.\n",
      "  3.8500261  1.5355862  0.         0.35170245 4.220116   2.0535035\n",
      "  5.7093763  0.         0.         0.18759584]], shape=(4, 16), dtype=float32)\n",
      "total_labels: [[1600.]\n",
      " [1600.]\n",
      " [1600.]\n",
      " [1600.]]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_data: # Remember <BatchDataset shapes: ((32, 32, 64), (32, 4)), types: (tf.int32, tf.float32)>\n",
    "    logseq_batch, label_batch = batch\n",
    "    # (32, 32, 64), (32, 4)\n",
    "    features = log_classifier(logseq_batch, extract_feature=True )\n",
    "    # (32, 16) features - 32 sequence of line each haaving 64 characrers\n",
    "    # produces a feaure vector of dimension 16. \n",
    "    for i in range(len(label_batch)): # (32, 4) --> here length is 32\n",
    "        label = label_batch[i] # label looks like [0 0 0 1]\n",
    "        numeric_label = np.argmax(label) # index position of the label = 3 , so it is actually class =3\n",
    "        ##total_labels = [0 0 0 0] each col representing a class \n",
    "        ## count the number for each class\n",
    "        total_labels_lst = tf.unstack(total_labels)\n",
    "        total_labels_lst[numeric_label] += 1 \n",
    "        total_labels = tf.stack(total_labels_lst)\n",
    "        centroids_lst = tf.unstack(centroids)\n",
    "        centroids_lst[numeric_label] += features[i]\n",
    "        centroids = tf.stack(centroids_lst)\n",
    "        # each row index in the centroid array is a class\n",
    "        # we add first identify the feature belonging to which class by the numeric_label\n",
    "        # Then add all the features belonging to the class in the corresponding row of the centroid array\n",
    "\n",
    "# ### shape of centroids is (4, 16) whereas shape of total_labels is (1, 4)\n",
    "# ### reshape the total_labels as 4,1 ==> [[0], [0], [0], [0]]==> 4 rows \n",
    "# ## so that we can divide the centroids array by the total_labels\n",
    "total_label_reshaped = np.reshape(total_labels, (train_data.element_spec[1].shape[1], 1))\n",
    "centroids /= total_label_reshaped\n",
    "print('centroids:',centroids)\n",
    "print('total_labels:',total_label_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b5b7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1867764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
       "array([1, 0, 0, 1, 3, 0, 0, 0, 1, 3, 3, 3, 1, 2, 1, 1, 3, 1, 0, 1, 0, 2,\n",
       "       0, 2, 2, 2, 1, 0, 1, 3, 2, 2], dtype=int64)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_indexes = tf.math.argmax(label_batch, axis=1)\n",
    "label_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67796502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 3, 0, 0, 0, 1, 3, 3, 3, 1, 2, 1, 1, 3, 1, 0, 1, 0, 2,\n",
       "       0, 2, 2, 2, 1, 0, 1, 3, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_indexes.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e7ba97aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 16), dtype=float32, numpy=\n",
       "array([[2.2333534 , 4.336265  , 0.        , 0.        , 2.2633772 ,\n",
       "        0.        , 2.8577154 , 4.883939  , 0.        , 3.6227775 ,\n",
       "        1.0883478 , 1.5947356 , 2.1637454 , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [3.5870562 , 1.0056759 , 0.        , 0.        , 0.7136998 ,\n",
       "        0.        , 1.439549  , 4.4074416 , 0.        , 3.396974  ,\n",
       "        0.2039164 , 3.1444259 , 3.7571042 , 0.        , 0.        ,\n",
       "        0.01983335],\n",
       "       [0.09745792, 0.01073291, 0.        , 0.        , 0.7897265 ,\n",
       "        0.        , 2.3192055 , 0.38710183, 0.        , 1.9512906 ,\n",
       "        3.4741373 , 3.5969954 , 3.7934008 , 0.        , 0.        ,\n",
       "        2.1638904 ],\n",
       "       [0.2828121 , 0.1923533 , 0.        , 0.        , 0.17389129,\n",
       "        0.        , 3.8500261 , 1.5355862 , 0.        , 0.35170245,\n",
       "        4.220116  , 2.0535035 , 5.7093763 , 0.        , 0.        ,\n",
       "        0.18759584]], dtype=float32)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = centroids\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef5662db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 16), dtype=float32, numpy=\n",
       "array([[3.5870562 , 1.0056759 , 0.        , 0.        , 0.7136998 ,\n",
       "        0.        , 1.439549  , 4.4074416 , 0.        , 3.396974  ,\n",
       "        0.2039164 , 3.1444259 , 3.7571042 , 0.        , 0.        ,\n",
       "        0.01983335],\n",
       "       [2.2333534 , 4.336265  , 0.        , 0.        , 2.2633772 ,\n",
       "        0.        , 2.8577154 , 4.883939  , 0.        , 3.6227775 ,\n",
       "        1.0883478 , 1.5947356 , 2.1637454 , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [2.2333534 , 4.336265  , 0.        , 0.        , 2.2633772 ,\n",
       "        0.        , 2.8577154 , 4.883939  , 0.        , 3.6227775 ,\n",
       "        1.0883478 , 1.5947356 , 2.1637454 , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [3.5870562 , 1.0056759 , 0.        , 0.        , 0.7136998 ,\n",
       "        0.        , 1.439549  , 4.4074416 , 0.        , 3.396974  ,\n",
       "        0.2039164 , 3.1444259 , 3.7571042 , 0.        , 0.        ,\n",
       "        0.01983335],\n",
       "       [0.2828121 , 0.1923533 , 0.        , 0.        , 0.17389129,\n",
       "        0.        , 3.8500261 , 1.5355862 , 0.        , 0.35170245,\n",
       "        4.220116  , 2.0535035 , 5.7093763 , 0.        , 0.        ,\n",
       "        0.18759584],\n",
       "       [2.2333534 , 4.336265  , 0.        , 0.        , 2.2633772 ,\n",
       "        0.        , 2.8577154 , 4.883939  , 0.        , 3.6227775 ,\n",
       "        1.0883478 , 1.5947356 , 2.1637454 , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [2.2333534 , 4.336265  , 0.        , 0.        , 2.2633772 ,\n",
       "        0.        , 2.8577154 , 4.883939  , 0.        , 3.6227775 ,\n",
       "        1.0883478 , 1.5947356 , 2.1637454 , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [2.2333534 , 4.336265  , 0.        , 0.        , 2.2633772 ,\n",
       "        0.        , 2.8577154 , 4.883939  , 0.        , 3.6227775 ,\n",
       "        1.0883478 , 1.5947356 , 2.1637454 , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [3.5870562 , 1.0056759 , 0.        , 0.        , 0.7136998 ,\n",
       "        0.        , 1.439549  , 4.4074416 , 0.        , 3.396974  ,\n",
       "        0.2039164 , 3.1444259 , 3.7571042 , 0.        , 0.        ,\n",
       "        0.01983335],\n",
       "       [0.2828121 , 0.1923533 , 0.        , 0.        , 0.17389129,\n",
       "        0.        , 3.8500261 , 1.5355862 , 0.        , 0.35170245,\n",
       "        4.220116  , 2.0535035 , 5.7093763 , 0.        , 0.        ,\n",
       "        0.18759584],\n",
       "       [0.2828121 , 0.1923533 , 0.        , 0.        , 0.17389129,\n",
       "        0.        , 3.8500261 , 1.5355862 , 0.        , 0.35170245,\n",
       "        4.220116  , 2.0535035 , 5.7093763 , 0.        , 0.        ,\n",
       "        0.18759584],\n",
       "       [0.2828121 , 0.1923533 , 0.        , 0.        , 0.17389129,\n",
       "        0.        , 3.8500261 , 1.5355862 , 0.        , 0.35170245,\n",
       "        4.220116  , 2.0535035 , 5.7093763 , 0.        , 0.        ,\n",
       "        0.18759584],\n",
       "       [3.5870562 , 1.0056759 , 0.        , 0.        , 0.7136998 ,\n",
       "        0.        , 1.439549  , 4.4074416 , 0.        , 3.396974  ,\n",
       "        0.2039164 , 3.1444259 , 3.7571042 , 0.        , 0.        ,\n",
       "        0.01983335],\n",
       "       [0.09745792, 0.01073291, 0.        , 0.        , 0.7897265 ,\n",
       "        0.        , 2.3192055 , 0.38710183, 0.        , 1.9512906 ,\n",
       "        3.4741373 , 3.5969954 , 3.7934008 , 0.        , 0.        ,\n",
       "        2.1638904 ],\n",
       "       [3.5870562 , 1.0056759 , 0.        , 0.        , 0.7136998 ,\n",
       "        0.        , 1.439549  , 4.4074416 , 0.        , 3.396974  ,\n",
       "        0.2039164 , 3.1444259 , 3.7571042 , 0.        , 0.        ,\n",
       "        0.01983335],\n",
       "       [3.5870562 , 1.0056759 , 0.        , 0.        , 0.7136998 ,\n",
       "        0.        , 1.439549  , 4.4074416 , 0.        , 3.396974  ,\n",
       "        0.2039164 , 3.1444259 , 3.7571042 , 0.        , 0.        ,\n",
       "        0.01983335],\n",
       "       [0.2828121 , 0.1923533 , 0.        , 0.        , 0.17389129,\n",
       "        0.        , 3.8500261 , 1.5355862 , 0.        , 0.35170245,\n",
       "        4.220116  , 2.0535035 , 5.7093763 , 0.        , 0.        ,\n",
       "        0.18759584],\n",
       "       [3.5870562 , 1.0056759 , 0.        , 0.        , 0.7136998 ,\n",
       "        0.        , 1.439549  , 4.4074416 , 0.        , 3.396974  ,\n",
       "        0.2039164 , 3.1444259 , 3.7571042 , 0.        , 0.        ,\n",
       "        0.01983335],\n",
       "       [2.2333534 , 4.336265  , 0.        , 0.        , 2.2633772 ,\n",
       "        0.        , 2.8577154 , 4.883939  , 0.        , 3.6227775 ,\n",
       "        1.0883478 , 1.5947356 , 2.1637454 , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [3.5870562 , 1.0056759 , 0.        , 0.        , 0.7136998 ,\n",
       "        0.        , 1.439549  , 4.4074416 , 0.        , 3.396974  ,\n",
       "        0.2039164 , 3.1444259 , 3.7571042 , 0.        , 0.        ,\n",
       "        0.01983335],\n",
       "       [2.2333534 , 4.336265  , 0.        , 0.        , 2.2633772 ,\n",
       "        0.        , 2.8577154 , 4.883939  , 0.        , 3.6227775 ,\n",
       "        1.0883478 , 1.5947356 , 2.1637454 , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.09745792, 0.01073291, 0.        , 0.        , 0.7897265 ,\n",
       "        0.        , 2.3192055 , 0.38710183, 0.        , 1.9512906 ,\n",
       "        3.4741373 , 3.5969954 , 3.7934008 , 0.        , 0.        ,\n",
       "        2.1638904 ],\n",
       "       [2.2333534 , 4.336265  , 0.        , 0.        , 2.2633772 ,\n",
       "        0.        , 2.8577154 , 4.883939  , 0.        , 3.6227775 ,\n",
       "        1.0883478 , 1.5947356 , 2.1637454 , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.09745792, 0.01073291, 0.        , 0.        , 0.7897265 ,\n",
       "        0.        , 2.3192055 , 0.38710183, 0.        , 1.9512906 ,\n",
       "        3.4741373 , 3.5969954 , 3.7934008 , 0.        , 0.        ,\n",
       "        2.1638904 ],\n",
       "       [0.09745792, 0.01073291, 0.        , 0.        , 0.7897265 ,\n",
       "        0.        , 2.3192055 , 0.38710183, 0.        , 1.9512906 ,\n",
       "        3.4741373 , 3.5969954 , 3.7934008 , 0.        , 0.        ,\n",
       "        2.1638904 ],\n",
       "       [0.09745792, 0.01073291, 0.        , 0.        , 0.7897265 ,\n",
       "        0.        , 2.3192055 , 0.38710183, 0.        , 1.9512906 ,\n",
       "        3.4741373 , 3.5969954 , 3.7934008 , 0.        , 0.        ,\n",
       "        2.1638904 ],\n",
       "       [3.5870562 , 1.0056759 , 0.        , 0.        , 0.7136998 ,\n",
       "        0.        , 1.439549  , 4.4074416 , 0.        , 3.396974  ,\n",
       "        0.2039164 , 3.1444259 , 3.7571042 , 0.        , 0.        ,\n",
       "        0.01983335],\n",
       "       [2.2333534 , 4.336265  , 0.        , 0.        , 2.2633772 ,\n",
       "        0.        , 2.8577154 , 4.883939  , 0.        , 3.6227775 ,\n",
       "        1.0883478 , 1.5947356 , 2.1637454 , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [3.5870562 , 1.0056759 , 0.        , 0.        , 0.7136998 ,\n",
       "        0.        , 1.439549  , 4.4074416 , 0.        , 3.396974  ,\n",
       "        0.2039164 , 3.1444259 , 3.7571042 , 0.        , 0.        ,\n",
       "        0.01983335],\n",
       "       [0.2828121 , 0.1923533 , 0.        , 0.        , 0.17389129,\n",
       "        0.        , 3.8500261 , 1.5355862 , 0.        , 0.35170245,\n",
       "        4.220116  , 2.0535035 , 5.7093763 , 0.        , 0.        ,\n",
       "        0.18759584],\n",
       "       [0.09745792, 0.01073291, 0.        , 0.        , 0.7897265 ,\n",
       "        0.        , 2.3192055 , 0.38710183, 0.        , 1.9512906 ,\n",
       "        3.4741373 , 3.5969954 , 3.7934008 , 0.        , 0.        ,\n",
       "        2.1638904 ],\n",
       "       [0.09745792, 0.01073291, 0.        , 0.        , 0.7897265 ,\n",
       "        0.        , 2.3192055 , 0.38710183, 0.        , 1.9512906 ,\n",
       "        3.4741373 , 3.5969954 , 3.7934008 , 0.        , 0.        ,\n",
       "        2.1638904 ]], dtype=float32)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(centroids, indices=label_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "603ee0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In context of deep learning the logits layer means the layer that feeds in to softmax (or other such normalization). The output of the softmax are the probabilities for the classification task and its input is logits layer. The logits layer typically produces values from -infinity to +infinity and the softmax layer transforms it to values from 0 to 1.\n",
    "\n",
    "# Historical Context\n",
    "\n",
    "# Where does this term comes from? In 1930s and 40s, several people were trying to adapt linear regression to the problem of predicting probabilities. However linear regression produces output from -infinity to +infinity while for probabilities our desired output is 0 to 1. One way to do this is by somehow mapping the probabilities 0 to 1 to -infinity to +infinity and then use linear regression as usual. One such mapping is cumulative normal distribution that was used by Chester Ittner Bliss in 1934 and he called this \"probit\" model, short for \"probability unit\". However this function is computationally expensive while lacking some of the desirable properties for multi-class classification. In 1944 Joseph Berkson used the function log(p/(1-p)) to do this mapping and called it logit, short for \"logistic unit\". The term logistic regression derived from this as well.\n",
    "\n",
    "# The Confusion\n",
    "\n",
    "# Unfortunately the term logits is abused in deep learning. From pure mathematical perspective logit is a function that performs above mapping. In deep learning people started calling the layer \"logits layer\" that feeds in to logit function. Then people started calling the output values of this layer \"logit\" creating the confusion with logit the function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
