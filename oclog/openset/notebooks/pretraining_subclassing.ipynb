{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b942ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bglog import BGLog, get_embedding_layer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6daaa389",
   "metadata": {},
   "outputs": [],
   "source": [
    "bglog = BGLog(save_padded_num_sequences=False, load_from_pkl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8aaed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_num_seq_df loaded from data\\bgl_padded_num_seq_df.pkl\n",
      "trained tokenizer, tk, loaded from data\\bgltk.pkl\n",
      "train_0:, 800\n",
      "test_0:, 200\n",
      "train_1:, 800\n",
      "test_1:, 200\n",
      "train_2:, 800\n",
      "test_2:, 200\n",
      "train_3:, 800\n",
      "test_3:, 102\n",
      "4 class does not have 800 records, it has only 628 records\n",
      "test_4:, 0\n",
      "5 class does not have 800 records, it has only 165 records\n",
      "5 class does not have 200 records, it has only 165 records\n",
      "6 class does not have 800 records, it has only 75 records\n",
      "6 class does not have 200 records, it has only 75 records\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "<BatchDataset shapes: ((32, 32, 64), (32, 4)), types: (tf.int32, tf.float32)>\n",
      "<BatchDataset shapes: ((32, 32, 64), (32, 4)), types: (tf.int32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "train_test = bglog.get_tensor_train_test(ablation=1000)\n",
    "train_data, test_data = train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da939218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(conv1d_set1 = 3, conv1d_set2 = 3, dense_neurons=2048, filters=64,\n",
    "            kernel_size=3,maxpool_1=True,epochs=25, dense_activation='relu'):\n",
    "    embedding_weights, vocab_size, char_onehot = get_embedding_layer(bglog)\n",
    "    B = train_data.element_spec[0].shape[0]\n",
    "#     inputs = tf.keras.layers.Input(batch_shape=(B, train_data.element_spec[0].shape[1], train_data.element_spec[0].shape[2]), dtype='float64' )\n",
    "    inputs = tf.keras.layers.Input(shape=(train_data.element_spec[0].shape[1], train_data.element_spec[0].shape[2]), dtype='float64' )\n",
    "    x = tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
    "                                    output_dim=vocab_size,\n",
    "                                    input_length=train_data.element_spec[0].shape[2],\n",
    "                                    weights = [embedding_weights],\n",
    "                                    )(inputs)\n",
    "    for _ in range(conv1d_set1):\n",
    "        x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "    if maxpool_1:\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(1, train_data.element_spec[0].shape[2]))(x)\n",
    "        x = tf.reshape(x, (B, train_data.element_spec[0].shape[1], filters))        \n",
    "        for _ in range(conv1d_set2):\n",
    "            x = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "        x = tf.keras.layers.MaxPooling1D(pool_size=(train_data.element_spec[0].shape[1]) )(x)\n",
    "        x = tf.reshape(x, (B, filters))\n",
    "    if not maxpool_1:\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "    if dense_activation is None:\n",
    "        x = tf.keras.layers.Dense(dense_neurons)(x)\n",
    "    else:\n",
    "        x = tf.keras.layers.Dense(dense_neurons, activation=dense_activation)(x)\n",
    "    outputs = tf.keras.layers.Dense(train_data.element_spec[1].shape[1], activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    print(model.summary())\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    hist = model.fit(train_data, validation_data=test_data, epochs=epochs) \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74dc6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we  feed  xi  to  a dense layer h to get the log-sequence representation zi∈RD:\n",
    "#     zi= h(xi) =σ(Whxi+bh) ............................(2)\n",
    "# in our case zi can be obtained from the dense layer before the softmax\n",
    "# Lets see how to ger it from the train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35677f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 64)]          0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 32, 64, 50)        2550      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 32, 64, 64)        9664      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 32, 64, 64)        12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 32, 64, 64)        12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 1, 64)         0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(32, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (32, 1, 64)               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (Tenso [(32, 64)]                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 2048)                133120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (32, 4)                   8196      \n",
      "=================================================================\n",
      "Total params: 215,290\n",
      "Trainable params: 215,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.3127 - accuracy: 0.8500 - precision: 0.8920 - recall: 0.8078 - val_loss: 0.0138 - val_accuracy: 0.9881 - val_precision: 0.9881 - val_recall: 0.9881\n",
      "Epoch 2/6\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 0.0563 - accuracy: 0.9797 - precision: 0.9800 - recall: 0.9794 - val_loss: 0.0087 - val_accuracy: 0.9970 - val_precision: 0.9985 - val_recall: 0.9955\n",
      "Epoch 3/6\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0469 - accuracy: 0.9834 - precision: 0.9841 - recall: 0.9834 - val_loss: 0.0092 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9970\n",
      "Epoch 4/6\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.0149 - accuracy: 0.9944 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.0090 - val_accuracy: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 5/6\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 0.0121 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.0070 - val_accuracy: 0.9985 - val_precision: 0.9985 - val_recall: 0.9985\n",
      "Epoch 6/6\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.0058 - accuracy: 0.9978 - precision: 0.9978 - recall: 0.9975 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# we pre-train the model with labeled known intent samples. \n",
    "# In order to better reflect the effectiveness of the learned decision boundary, \n",
    "# we learn the feature representation zi with the simple softmax loss Ls to perform classification:\n",
    "\n",
    "trained_model, hist = model(epochs=6,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eac024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 64)]          0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 32, 64, 50)        2550      \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 32, 64, 64)        9664      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 32, 64, 64)        12352     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 32, 64, 64)        12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 1, 64)         0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (Tenso [(32, 32, 64)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (32, 32, 64)              12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (32, 1, 64)               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (Tenso [(32, 64)]                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (32, 64)                  4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (32, 4)                   260       \n",
      "=================================================================\n",
      "Total params: 78,394\n",
      "Trainable params: 78,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.3393 - accuracy: 0.8659 - precision_1: 0.9306 - recall_1: 0.8041 - val_loss: 0.0731 - val_accuracy: 0.9673 - val_precision_1: 0.9672 - val_recall_1: 0.9643\n",
      "Epoch 2/6\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0488 - accuracy: 0.9822 - precision_1: 0.9825 - recall_1: 0.9816 - val_loss: 0.0086 - val_accuracy: 0.9970 - val_precision_1: 0.9985 - val_recall_1: 0.9940\n",
      "Epoch 3/6\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0259 - accuracy: 0.9894 - precision_1: 0.9903 - recall_1: 0.9887 - val_loss: 0.0151 - val_accuracy: 0.9955 - val_precision_1: 0.9955 - val_recall_1: 0.9955\n",
      "Epoch 4/6\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 0.0184 - accuracy: 0.9941 - precision_1: 0.9941 - recall_1: 0.9941 - val_loss: 0.0025 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000\n",
      "Epoch 5/6\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.0257 - accuracy: 0.9906 - precision_1: 0.9906 - recall_1: 0.9906 - val_loss: 0.0031 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000\n",
      "Epoch 6/6\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.0063 - accuracy: 0.9981 - precision_1: 0.9984 - recall_1: 0.9981 - val_loss: 0.0140 - val_accuracy: 0.9911 - val_precision_1: 0.9940 - val_recall_1: 0.9911\n"
     ]
    }
   ],
   "source": [
    "trained_model, hist = model(epochs=6, dense_neurons=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b092c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the decision boundary of each class constraining the known labels within a ball area\n",
    "# how to get zi and how to know that zi belongs to which yi ?\n",
    "# from there we will have to calculate the Ck , centroid for the class k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a80ff538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x23361f141c0>,\n",
       " <tensorflow.python.keras.layers.embeddings.Embedding at 0x23302378d60>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x23302378d00>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x2330237fdf0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x23302385f40>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x23302ad28b0>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x23302af58e0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x23302ae5940>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x23302af51f0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x23302afc940>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling1D at 0x23302b01ac0>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x23303bd1730>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x23302b018b0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x23303bd1790>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f101fca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Dense object at 0x0000023303BD1790>\n"
     ]
    }
   ],
   "source": [
    "dense_6 = trained_model.get_layer(index=(len(trained_model.layers)-1))\n",
    "print(dense_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72c2410d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_3/Softmax:0' shape=(32, 4) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the log sequence embedding from the last layer\n",
    "# we can treat this as the features from the logs\n",
    "dense_6.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "075a2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we use the pre-trained model to extract intent features for \n",
    "# learning the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06166ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n",
      "sample_x_train.shape: (32, 32, 64)\n",
      "loglineEmbedding.shape: (32, 32, 64)\n",
      "Model: \"log_line_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      multiple                  2550      \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           multiple                  9664      \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           multiple                  12352     \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           multiple                  12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
      "=================================================================\n",
      "Total params: 36,918\n",
      "Trainable params: 36,918\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class LogLineEncoder(tf.keras.Model):\n",
    "    def __init__(self, num_of_conv1d=3,  \n",
    "                 filters=64,\n",
    "                 kernel_size=3, ):\n",
    "        super().__init__()            \n",
    "        self.num_of_conv1d = num_of_conv1d       \n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size           \n",
    "        self.embedding_weights, self.vocab_size, self.char_onehot = get_embedding_layer(bglog)       \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size+1,\n",
    "                                    output_dim=self.vocab_size,\n",
    "                                    input_length=train_data.element_spec[0].shape[2],\n",
    "                                    weights = [self.embedding_weights],\n",
    "                                    )\n",
    "        self.conv1d_layers = [tf.keras.layers.Conv1D(filters=filters, \n",
    "                                                kernel_size=kernel_size, \n",
    "                                                padding='same')  \n",
    "                       for _ in range(self.num_of_conv1d)]\n",
    "        self.maxpool2d = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size=(1, train_data.element_spec[0].shape[2]))\n",
    "                  \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        for conv1d_layer in self.conv1d_layers:\n",
    "            x = conv1d_layer(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = tf.reshape(x, (inputs.shape[0], inputs.shape[1], self.filters))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "# \n",
    "line_encoder =   LogLineEncoder()\n",
    "# the model doesn't have a state unless it is called at least once\n",
    "# in order to initialize the model we need a sample data \n",
    "sample_train_data = next(iter(train_data))\n",
    "sample_x_train = sample_train_data[0]\n",
    "print('sample_x_train.shape:', sample_x_train.shape)\n",
    "# now we will initialize the model with the sample data\n",
    "loglineEmbedding = line_encoder(sample_x_train)\n",
    "print('loglineEmbedding.shape:', loglineEmbedding.shape)\n",
    "# Now the model have a state and can be inspected        \n",
    "line_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18a373b",
   "metadata": {},
   "source": [
    "LOG SEQUENCE EMBEDDING TAKES LOGLINE EMBEDDING AS INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0360c071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logSeqEmbedding.shape: (32, 16)\n",
      "Model: \"log_seq_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           multiple                  12352     \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           multiple                  12352     \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           multiple                  12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  1040      \n",
      "=================================================================\n",
      "Total params: 38,096\n",
      "Trainable params: 38,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class LogSeqEncoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, num_of_conv1d=3,  filters=64,\n",
    "                 kernel_size=3, maxpool_1=True,\n",
    "                 dense_neurons=16, dense_activation='relu',):\n",
    "        super().__init__()\n",
    "        self.num_of_conv1d = num_of_conv1d\n",
    "        self.dense_neurons = dense_neurons\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.maxpool_1 = maxpool_1\n",
    "        self.dense_activation = dense_activation\n",
    "        self.conv1d_layers = [tf.keras.layers.Conv1D(filters=filters, \n",
    "                                                kernel_size=kernel_size, \n",
    "                                                padding='same')  \n",
    "                       for _ in range(self.num_of_conv1d)]\n",
    "        self.maxpool1d = tf.keras.layers.MaxPooling1D(pool_size=(train_data.element_spec[0].shape[1]) )\n",
    "        \n",
    "        self.Dense = tf.keras.layers.Dense(self.dense_neurons, \n",
    "                                           activation=self.dense_activation)\n",
    "       \n",
    "        \n",
    "    def call(self, inputs):       \n",
    "        for conv1d_layer in self.conv1d_layers:\n",
    "            x = conv1d_layer(inputs)\n",
    "        x = self.maxpool1d(x)        \n",
    "        x = tf.reshape(x, (inputs.shape[0], self.filters))\n",
    "        x = self.Dense(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "logSeqencer =   LogSeqEncoder()\n",
    "# the model doesn't have a state unless it is called at least once\n",
    "logSeqEmbedding = logSeqencer(loglineEmbedding)\n",
    "print('logSeqEmbedding.shape:', logSeqEmbedding.shape)\n",
    "# Now the model have a state and can be inspected        \n",
    "logSeqencer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f7026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17253e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       "array([[0.35821474, 0.13428831, 0.24254903, 0.26494795],\n",
       "       [0.35491565, 0.1391793 , 0.24208418, 0.2638209 ],\n",
       "       [0.375133  , 0.1356046 , 0.21780658, 0.27145582],\n",
       "       [0.38075638, 0.12354345, 0.21483545, 0.28086472],\n",
       "       [0.38417214, 0.12913577, 0.21276838, 0.27392364],\n",
       "       [0.3580804 , 0.13689776, 0.23292485, 0.27209705],\n",
       "       [0.35545176, 0.13543256, 0.2281103 , 0.28100547],\n",
       "       [0.39000586, 0.12042741, 0.20709819, 0.28246853],\n",
       "       [0.3608639 , 0.13162096, 0.23645732, 0.2710579 ],\n",
       "       [0.35545176, 0.13543256, 0.2281103 , 0.28100547],\n",
       "       [0.40143406, 0.11165593, 0.20353052, 0.28337947],\n",
       "       [0.369081  , 0.13193883, 0.2124407 , 0.28653944],\n",
       "       [0.35913053, 0.137531  , 0.23262696, 0.27071157],\n",
       "       [0.3781036 , 0.13510987, 0.2082549 , 0.27853167],\n",
       "       [0.34989867, 0.14130919, 0.22489977, 0.28389236],\n",
       "       [0.39720216, 0.11340225, 0.2012538 , 0.28814167],\n",
       "       [0.39713928, 0.10840394, 0.21171153, 0.28274524],\n",
       "       [0.35855198, 0.13689516, 0.2372176 , 0.26733536],\n",
       "       [0.38395277, 0.12527211, 0.21550307, 0.27527204],\n",
       "       [0.35799918, 0.13482493, 0.23909317, 0.26808274],\n",
       "       [0.36090276, 0.13658734, 0.2358468 , 0.26666313],\n",
       "       [0.3570144 , 0.13592023, 0.23620863, 0.27085677],\n",
       "       [0.34989867, 0.14130919, 0.22489977, 0.28389236],\n",
       "       [0.37569454, 0.12540925, 0.2110838 , 0.28781238],\n",
       "       [0.37662882, 0.13381094, 0.21082811, 0.2787321 ],\n",
       "       [0.35834822, 0.13339362, 0.23770761, 0.27055058],\n",
       "       [0.39035118, 0.12015291, 0.20857388, 0.28092206],\n",
       "       [0.35545176, 0.13543256, 0.2281103 , 0.28100547],\n",
       "       [0.37556297, 0.12093321, 0.209709  , 0.29379487],\n",
       "       [0.35545176, 0.13543256, 0.2281103 , 0.28100547],\n",
       "       [0.37675625, 0.13559066, 0.21334848, 0.27430466],\n",
       "       [0.38741708, 0.11640849, 0.2099241 , 0.28625032]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LogClassifier(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,  **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.log_line_encoder = LogLineEncoder()\n",
    "        self.log_seq_encoder = LogSeqEncoder()\n",
    "        self.classifier = tf.keras.layers.Dense(\n",
    "            train_data.element_spec[1].shape[1], activation='softmax')\n",
    "#         self.extract_feature = extract_feature\n",
    "    \n",
    "    def call(self, inputs, extract_feature=False,):\n",
    "#         x_data, y_data = inputs\n",
    "        x = self.log_line_encoder(inputs)\n",
    "        seq_embedding = self.log_seq_encoder(x)\n",
    "        \n",
    "        if  extract_feature:\n",
    "            output = seq_embedding\n",
    "        else:\n",
    "            output = self.classifier(seq_embedding)\n",
    "        return output\n",
    "    \n",
    "log_classifier = LogClassifier()\n",
    "log_classifier(sample_x_train)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "398cba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classifier assigned low probability to all the classes since it is untrained\n",
    "# TODO: the mode should accept a single sequence. At present it is accepting only a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f7dcae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"log_classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_line_encoder_1 (LogLineE multiple                  36918     \n",
      "_________________________________________________________________\n",
      "log_seq_encoder_1 (LogSeqEnc multiple                  38096     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  68        \n",
      "=================================================================\n",
      "Total params: 75,082\n",
      "Trainable params: 75,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "log_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a86d5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method LogLineEncoder.call of <__main__.LogLineEncoder object at 0x000002333BA31F40>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method LogLineEncoder.call of <__main__.LogLineEncoder object at 0x000002333BA31F40>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LogSeqEncoder.call of <__main__.LogSeqEncoder object at 0x000002333B6CDB20>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method LogSeqEncoder.call of <__main__.LogSeqEncoder object at 0x000002333B6CDB20>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier/log_seq_encoder_1/conv1d_21/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_21/bias:0', 'log_classifier/log_seq_encoder_1/conv1d_22/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_22/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier/log_seq_encoder_1/conv1d_21/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_21/bias:0', 'log_classifier/log_seq_encoder_1/conv1d_22/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_22/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier/log_seq_encoder_1/conv1d_21/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_21/bias:0', 'log_classifier/log_seq_encoder_1/conv1d_22/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_22/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['log_classifier/log_seq_encoder_1/conv1d_21/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_21/bias:0', 'log_classifier/log_seq_encoder_1/conv1d_22/kernel:0', 'log_classifier/log_seq_encoder_1/conv1d_22/bias:0'] when minimizing the loss.\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.4103 - accuracy: 0.8784 - precision_2: 0.9772 - recall_2: 0.7234 - val_loss: 0.0270 - val_accuracy: 0.9926 - val_precision_2: 0.9970 - val_recall_2: 0.9896\n"
     ]
    }
   ],
   "source": [
    "# This is to check that the model's built in  complile and fit is working well\n",
    "log_classifier.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "hist = log_classifier.fit(train_data, validation_data=test_data, epochs=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "443a555b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       "array([[9.83800590e-01, 1.59811135e-02, 7.62605996e-05, 1.42064076e-04],\n",
       "       [9.81814444e-01, 1.79334246e-02, 9.93448266e-05, 1.52733337e-04],\n",
       "       [9.96633589e-01, 4.76912275e-04, 1.24792627e-04, 2.76482617e-03],\n",
       "       [1.63851166e-03, 8.47785413e-05, 1.17509440e-02, 9.86525774e-01],\n",
       "       [9.96272326e-01, 4.85389668e-04, 1.45744227e-04, 3.09653906e-03],\n",
       "       [9.85013008e-01, 1.47707565e-02, 7.50642139e-05, 1.41203738e-04],\n",
       "       [9.94609356e-01, 2.36800150e-03, 1.73490393e-04, 2.84919282e-03],\n",
       "       [3.56137866e-06, 7.82679650e-04, 9.98905420e-01, 3.08348332e-04],\n",
       "       [8.14913015e-04, 9.99016285e-01, 1.62149983e-04, 6.53520510e-06],\n",
       "       [9.94609356e-01, 2.36800150e-03, 1.73490393e-04, 2.84919282e-03],\n",
       "       [1.89539969e-06, 4.88373160e-04, 9.99277294e-01, 2.32436854e-04],\n",
       "       [3.45080800e-04, 9.86293708e-06, 1.65420293e-03, 9.97990847e-01],\n",
       "       [9.83729064e-01, 1.60406213e-02, 8.35043174e-05, 1.46816092e-04],\n",
       "       [3.40183557e-04, 2.72511079e-05, 4.03488800e-03, 9.95597661e-01],\n",
       "       [1.64400618e-08, 9.99861956e-01, 1.38059113e-04, 4.74311008e-08],\n",
       "       [3.70142370e-04, 2.60118031e-05, 2.99992505e-03, 9.96603966e-01],\n",
       "       [5.09789788e-06, 1.56117417e-03, 9.97838795e-01, 5.94986952e-04],\n",
       "       [1.00098562e-03, 9.98807669e-01, 1.83891825e-04, 7.49514402e-06],\n",
       "       [3.89279652e-04, 1.37191571e-04, 4.96935612e-03, 9.94504213e-01],\n",
       "       [9.84047830e-01, 1.57328472e-02, 8.45538234e-05, 1.34727918e-04],\n",
       "       [9.85781610e-01, 1.40118767e-02, 7.42244301e-05, 1.32336761e-04],\n",
       "       [8.67961498e-04, 9.98950481e-01, 1.73442371e-04, 8.13147199e-06],\n",
       "       [1.64400618e-08, 9.99861956e-01, 1.38059113e-04, 4.74311008e-08],\n",
       "       [3.32500116e-04, 9.09702339e-06, 1.58711139e-03, 9.98071373e-01],\n",
       "       [2.35707688e-04, 1.49276475e-05, 2.88530695e-03, 9.96864080e-01],\n",
       "       [9.81513798e-01, 1.81638077e-02, 1.08718807e-04, 2.13617372e-04],\n",
       "       [1.57476134e-05, 1.92043907e-03, 9.96070862e-01, 1.99296908e-03],\n",
       "       [9.94609356e-01, 2.36800150e-03, 1.73490393e-04, 2.84919282e-03],\n",
       "       [1.54631516e-06, 9.98125970e-01, 1.83568033e-03, 3.67316425e-05],\n",
       "       [9.94609356e-01, 2.36800150e-03, 1.73490393e-04, 2.84919282e-03],\n",
       "       [3.24892695e-04, 1.61720309e-05, 2.48714001e-03, 9.97171819e-01],\n",
       "       [1.76616559e-05, 1.06092554e-03, 9.97744322e-01, 1.17711641e-03]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now after the training the predeicitoin will show higher probability to the \n",
    "# a class and lesser probability to other classes\n",
    "log_classifier(sample_x_train)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "814e4ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape: (32, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 16), dtype=float32, numpy=\n",
       "array([[16.370695  ,  0.        ,  2.057126  ,  4.2832656 ,  0.        ,\n",
       "         1.3033314 ,  0.31263167,  0.        ,  0.90409607,  0.        ,\n",
       "         0.35633054,  0.        ,  5.6959033 ,  6.7388763 ,  0.        ,\n",
       "         0.        ],\n",
       "       [16.299906  ,  0.        ,  2.1437495 ,  4.3283706 ,  0.        ,\n",
       "         1.3558165 ,  0.38486403,  0.        ,  1.0134336 ,  0.        ,\n",
       "         0.45871457,  0.        ,  5.6253996 ,  6.6684337 ,  0.        ,\n",
       "         0.        ],\n",
       "       [14.986892  ,  0.        ,  2.2317116 ,  8.941614  ,  0.        ,\n",
       "         1.4058796 ,  0.        ,  0.        ,  1.7621404 ,  0.        ,\n",
       "         0.        ,  0.        ,  4.8268437 ,  6.081328  ,  0.        ,\n",
       "         0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = log_classifier(sample_x_train, extract_feature=True ) \n",
    "print('features.shape:', features.shape)\n",
    "features[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01486a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61854eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[13 13 13 ... 11 11 25]\n",
      "  [13 13 13 ... 11 11 25]\n",
      "  [13 13 13 ... 11 11 25]\n",
      "  ...\n",
      "  [13 13 13 ... 11 11 25]\n",
      "  [13 13 22 ... 11 11 25]\n",
      "  [13 13 22 ... 11 11 25]]\n",
      "\n",
      " [[ 2 19 11 ...  8 10  2]\n",
      "  [ 2 19 11 ...  8 10  2]\n",
      "  [ 2 19 11 ...  8 10  2]\n",
      "  ...\n",
      "  [ 2 19 11 ...  8 10  2]\n",
      "  [ 2 19 11 ...  8 10  2]\n",
      "  [ 2 19 11 ...  8 10  2]]\n",
      "\n",
      " [[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[10  5 14 ... 11 14 23]\n",
      "  [10  5 14 ... 23 10 28]\n",
      "  [10  5 14 ... 22 10 13]\n",
      "  ...\n",
      "  [22 30 17 ...  8  4 14]\n",
      "  [12  3  6 ... 12  6 18]\n",
      "  [ 4 22 30 ...  9  0  0]]\n",
      "\n",
      " [[12  3  6 ... 12  6 18]\n",
      "  [ 4 30 30 ...  9  0  0]\n",
      "  [30 30 17 ...  8  4 14]\n",
      "  ...\n",
      "  [30 30 17 ...  8  4 14]\n",
      "  [12  3  6 ... 12  6 18]\n",
      "  [ 4 30 30 ...  9  0  0]]\n",
      "\n",
      " [[18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  ...\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]\n",
      "  [18  2  4 ...  0  0  0]]], shape=(32, 32, 64), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]], shape=(32, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_data:\n",
    "    x_train, y_train = batch\n",
    "    print(x_train)\n",
    "    print(y_train)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cbcab95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centriods initialized: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "total_labels initialized: [0. 0. 0. 0.]\n",
      "centroids: [[1.59228516e+01 0.00000000e+00 2.11870209e+00 5.98598145e+00\n",
      "  0.00000000e+00 1.25047585e+00 2.19539013e-01 0.00000000e+00\n",
      "  1.56062897e+00 0.00000000e+00 2.68166313e-01 0.00000000e+00\n",
      "  5.16910828e+00 6.25313660e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.74468457e+01 0.00000000e+00 3.22822418e-01 2.02313873e+00\n",
      "  0.00000000e+00 3.26722992e+00 2.75704742e+00 0.00000000e+00\n",
      "  8.89736511e+00 0.00000000e+00 4.26681946e+00 0.00000000e+00\n",
      "  1.02011330e+00 2.11967209e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.02403418e+01 0.00000000e+00 3.78646240e+00 1.14958667e+01\n",
      "  0.00000000e+00 1.84005249e+00 2.75890717e+00 0.00000000e+00\n",
      "  1.34137109e+01 0.00000000e+00 6.58589233e+00 0.00000000e+00\n",
      "  2.07575560e-02 1.36120820e-02 0.00000000e+00 0.00000000e+00]\n",
      " [1.11332776e+01 0.00000000e+00 4.36349945e-01 1.46233423e+01\n",
      "  0.00000000e+00 8.60986633e-01 1.89996605e-01 0.00000000e+00\n",
      "  1.06009094e+01 0.00000000e+00 1.73968216e+00 0.00000000e+00\n",
      "  3.39005852e-02 1.14435501e-01 0.00000000e+00 0.00000000e+00]]\n",
      "total_labels: [[800.]\n",
      " [800.]\n",
      " [800.]\n",
      " [800.]]\n"
     ]
    }
   ],
   "source": [
    "centroids = np.zeros((train_data.element_spec[1].shape[1],   16))\n",
    "print('centriods initialized:', centroids)\n",
    "total_labels = np.zeros(train_data.element_spec[1].shape[1]) # it was 4\n",
    "# total_labels[2] += 1\n",
    "# total_labels[2] += 1\n",
    "print('total_labels initialized:', total_labels)\n",
    "for batch in train_data: # Remember <BatchDataset shapes: ((32, 32, 64), (32, 4)), types: (tf.int32, tf.float32)>\n",
    "    logseq_batch, label_batch = batch\n",
    "    # (32, 32, 64), (32, 4)\n",
    "    features = log_classifier(logseq_batch, extract_feature=True )\n",
    "    # (32, 16) features - 32 sequence of line each haaving 64 characrers\n",
    "    # produces a feaure vector of dimension 16. \n",
    "    for i in range(len(label_batch)): # (32, 4) --> here length is 32\n",
    "        label = label_batch[i] # label looks like [0 0 0 1]\n",
    "        numeric_label = np.argmax(label) # index position of the label = 3 , so it is actually class =3\n",
    "        ##total_labels = [0 0 0 0] each col representing a class \n",
    "        ## count the number for each class\n",
    "        total_labels[numeric_label] += 1 \n",
    "        centroids[numeric_label] += features[i] \n",
    "        # each row index in the centroid array is a class\n",
    "        # we add first identify the feature belonging to which class by the numeric_label\n",
    "        # Then add all the features belonging to the class in the corresponding row of the centroid array\n",
    "\n",
    "### shape of centroids is (4, 16) whereas shape of total_labels is (1, 4)\n",
    "### reshape the total_labels as 4,1 ==> [[0], [0], [0], [0]]==> 4 rows \n",
    "## so that we can divide the centroids array by the total_labels\n",
    "total_label_reshaped = np.reshape(total_labels, (train_data.element_spec[1].shape[1], 1))\n",
    "centroids /= total_label_reshaped\n",
    "print('centroids:',centroids)\n",
    "print('total_labels:',total_label_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a0d9ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n2 is 3 rows and each row has a vector of 4 cols:\n",
      " [[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "n3, is one single row:\n",
      "  [2 2 2]\n",
      "one single row is now converted to three rows, n4:\n",
      " [[2]\n",
      " [2]\n",
      " [2]]\n",
      "now division between n2: (3, 4) and n4: (3, 1) is possible\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.5, 1. , 1.5],\n",
       "       [2. , 2.5, 3. , 3.5],\n",
       "       [4. , 4.5, 5. , 5.5]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to understand the np divide operation\n",
    "n1 = np.arange(12)\n",
    "n2 = n1.reshape((3, 4))\n",
    "print('n2 is 3 rows and each row has a vector of 4 cols:\\n', n2)\n",
    "n3 = np.array([2, 2, 2])\n",
    "print('n3, is one single row:\\n ', n3)\n",
    "n4 = np.reshape(n3, (3, 1))\n",
    "print('one single row is now converted to three rows, n4:\\n', n4)\n",
    "print(f'now division between n2: {n2.shape} and n4: {n4.shape} is possible')\n",
    "n2/n4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bb506c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_x_train[0] tf.Tensor(\n",
      "[[18  2  4 ...  0  0  0]\n",
      " [18  2  4 ...  0  0  0]\n",
      " [18  2  4 ...  0  0  0]\n",
      " ...\n",
      " [18  2  4 ...  0  0  0]\n",
      " [18  2  4 ...  0  0  0]\n",
      " [18  2  4 ...  0  0  0]], shape=(32, 64), dtype=int32)\n",
      "sample_y_train[0] tf.Tensor([1. 0. 0. 0.], shape=(4,), dtype=float32)\n",
      "feature for the same: tf.Tensor(\n",
      "[10.185282   0.         3.8696542 12.428818   0.         1.611328\n",
      "  2.503866   0.        14.205777   0.         6.697892   0.\n",
      "  0.         0.         0.         0.       ], shape=(16,), dtype=float32)\n",
      "centroid for the class 3 : [11.13327759  0.          0.43634995 14.62334229  0.          0.86098663\n",
      "  0.1899966   0.         10.60090942  0.          1.73968216  0.\n",
      "  0.03390059  0.1144355   0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "#take zi and a ck \n",
    "# from sample_x_train the first sample belongs to class 3\n",
    "print('sample_x_train[0]', sample_x_train[0])\n",
    "sample_y_train = sample_train_data[1]\n",
    "print('sample_y_train[0]', sample_y_train[0])\n",
    "print('feature for the same:', features[0])\n",
    "print('centroid for the class 3 :', centroids[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f56a2836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eucladian distance: 61.01238\n"
     ]
    }
   ],
   "source": [
    "# eucladian distance \n",
    "#first sample belonging to class 3 = z_0_3, dimension of it is same as the dense neuron=16\n",
    "z_0_3= features[0] # [16], earlier [2048]\n",
    "C_3 = centroids[3] # [16], earlier [2048]\n",
    "ED = np.sum(np.square(z_0_3 - C_3 ))\n",
    "print('eucladian distance:', ED)\n",
    "# InvalidArgumentError: Incompatible shapes: [32,64] vs. [2048] [Op:Sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ed8e0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one feature with dimension 5 , f1:\n",
      " [20 21 22 23 24]\n",
      "centroid, ctd with 4 class :\n",
      " [[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]]\n",
      "\n",
      "sub_result, for each feature we have 4 rows after substraction:\n",
      " [[20 20 20 20 20]\n",
      " [15 15 15 15 15]\n",
      " [10 10 10 10 10]\n",
      " [ 5  5  5  5  5]]\n",
      "the 4 rows of the result are the distance of the feature from the centroid of each class\n",
      "distance of f1 from centroid of class_0: [20 20 20 20 20]\n",
      "distance of f1 from centroid of class_1: [15 15 15 15 15]\n",
      "distance of f1 from centroid of class_2: [10 10 10 10 10]\n",
      "distance of f1 from centroid of class_3: [5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "# lets f1 is one feature from a batch of 32\n",
    "# instead of 16, lets say the dimension of f1 is 5\n",
    "f1 = np.arange(20, 25)\n",
    "# a1 = np.reshape(a1, (4, 3) )\n",
    "print('one feature with dimension 5 , f1:\\n', f1)\n",
    "### lets say ctd is the centroids with 4 class , each row is a class \n",
    "ctd = np.arange(20)\n",
    "ctd = np.reshape(ctd, (4, 5))\n",
    "print('centroid, ctd with 4 class :\\n', ctd)\n",
    "sub_result = f1 - ctd\n",
    "print()\n",
    "print('sub_result, for each feature we have 4 rows after substraction:\\n', sub_result)\n",
    "print('the 4 rows of the result are the distance of the feature from the centroid of each class')\n",
    "for i, row in enumerate(sub_result):\n",
    "    print(f'distance of f1 from centroid of class_{i}: {row}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "602ee4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squared_substraction:\n",
      " [[400 400 400 400 400]\n",
      " [225 225 225 225 225]\n",
      " [100 100 100 100 100]\n",
      " [ 25  25  25  25  25]]\n",
      "sum_squared_substraction:\n",
      " [2000 1125  500  125]\n"
     ]
    }
   ],
   "source": [
    "# to get the eucladian distance, calculate squared substraction\n",
    "squared_substraction = np.square(sub_result)\n",
    "print('squared_substraction:\\n', squared_substraction)\n",
    "#### eucladian distance of f1 from each class represented by a vector of 5 dimension\n",
    "### those 5 values from the vector is summed up tp get a scalar value \n",
    "sum_squared_substraction = np.sum(np.square(sub_result), axis=1)\n",
    "print('sum_squared_substraction:\\n', sum_squared_substraction )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f65ce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape (32, 16)\n",
      "centroids.shape (4, 16)\n",
      "np.expand_dims(features, axis=1) : (32, 1, 16)\n",
      "np.expand_dims(centroids, axis=0): (1, 4, 16)\n",
      "sub_z_C , for each feature 4 results: (32, 4, 16)\n",
      "squred_sum (32, 4)\n",
      "Eucaldian distance of first feature from the 4 classes:\n",
      " [349.90658958 216.0175884    1.6382401   61.01237844]\n"
     ]
    }
   ],
   "source": [
    "### the abobe example is for a single feature , how to do this for all the features\n",
    "# can we substract centroids array from the entire feature array? \n",
    "# we can not substract different shaped arrays , see the error\n",
    "print('features.shape', features.shape) # ## features.shape (32, 16)\n",
    "print('centroids.shape', centroids.shape)  ##centroids.shape (4, 16)\n",
    "# features - centroids # InvalidArgumentError: Incompatible shapes: [32,16] vs. [4,16] [Op:Sub]\n",
    "#### substraction is elementwise substraction. so we both the array have to equal shape\n",
    "z = np.expand_dims(features, axis=1) ## (32, 1, 16)\n",
    "C =  np.expand_dims(centroids, axis=0) ### (1, 4, 16)\n",
    "print('np.expand_dims(features, axis=1) :', z.shape)\n",
    "print('np.expand_dims(centroids, axis=0):', C.shape)\n",
    "# print('first dimenstion of C:',C[0])\n",
    "# Now we can substract\n",
    "sub_z_C = z - C\n",
    "print('sub_z_C , for each feature 4 results:', sub_z_C.shape)\n",
    "squred_sum = np.sum(np.square(z- C), axis=2)\n",
    "print('squred_sum', squred_sum.shape)\n",
    "print('Eucaldian distance of first feature from the 4 classes:\\n',squred_sum[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "034de73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th element from the last bath retrieved from data iteration previously:\n",
      " tf.Tensor(\n",
      "[10.185282   0.         3.8696542 12.428818   0.         1.611328\n",
      "  2.503866   0.        14.205777   0.         6.697892   0.\n",
      "  0.         0.         0.         0.       ], shape=(16,), dtype=float32)\n",
      "label for the feature_0:\n",
      " tf.Tensor([0. 0. 1. 0.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# from the data iteration done beforem we will have the last features and the last label_batch\n",
    "## lets see what is the label for the 0th element in that batch\n",
    "print('0th element from the last bath retrieved from data iteration previously:\\n', features[0])\n",
    "print('label for the feature_0:\\n', label_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90391623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here eucladian distance of the first feature is least from the class_0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4a84138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED_logits (32, 4)\n",
      "ED_logits_sample [-349.90658958 -216.0175884    -1.6382401   -61.01237844]\n"
     ]
    }
   ],
   "source": [
    "# make the dimensions same for substraction\n",
    "def euclidean_metric(a, b):\n",
    "    a = np.expand_dims(a, 1)\n",
    "    b = np.expand_dims(b, 0)\n",
    "#     logits = -((a - b)**2).sum(dim=2)\n",
    "    logits = np.sum(-np.square(a - b), axis=2)\n",
    "    return logits  \n",
    "\n",
    "ED_logits = euclidean_metric(features, centroids)\n",
    "print('ED_logits', ED_logits.shape)\n",
    "print('ED_logits_sample', ED_logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce63a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "### we got the same result only in negative sign \n",
    "# these four eucladian values can be taken as softmax \n",
    "# to convert it as probability amonghst the four\n",
    "# Then the max value ( that is why -ve sign will help)\n",
    "# will represent the class with highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b482d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]], shape=(2, 5), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([4, 4], dtype=int64)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.range(10)\n",
    "t = tf.reshape(t, (2, 5))\n",
    "print(t)\n",
    "tf.argmax(t, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a56eaa01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 9])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can we get the max value instead of the index\n",
    "tf.reduce_max(t, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c14cccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smax.shape: (32, 4)\n",
      "smax_sample: [5.61019037e-152 7.87466337e-094 1.00000000e+000 1.63734180e-026]\n",
      "class_idx_having_minimum_distance: 2\n",
      "smax_sample: [8.85826821e-118 1.78730061e-116 8.36417246e-037 1.00000000e+000]\n",
      "class_idx_having_minimum_distance: 3\n",
      "smax_sample: [6.44885863e-48 1.00000000e+00 5.66201308e-63 3.87784564e-73]\n",
      "class_idx_having_minimum_distance: 1\n",
      "smax_sample: [1.00000000e+000 2.11417181e-069 9.14938496e-117 1.24417711e-078]\n",
      "class_idx_having_minimum_distance: 0\n",
      "smax_sample: [1.08049842e-123 9.96291698e-070 1.00000000e+000 2.96436126e-028]\n",
      "class_idx_having_minimum_distance: 2\n"
     ]
    }
   ],
   "source": [
    "# smax = tf.nn.softmax(ED_logits, axis=1)\n",
    "smax = tf.nn.softmax(ED_logits, )\n",
    "print('smax.shape:', smax.shape)\n",
    "class_idx_having_minimum_distance = tf.math.argmax(smax, axis=1)\n",
    "for i in range(5):    \n",
    "    print('smax_sample:', smax[i].numpy())\n",
    "    print('class_idx_having_minimum_distance:', class_idx_having_minimum_distance[i].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9674545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for the feature_0:\n",
      " tf.Tensor([0. 0. 1. 0.], shape=(4,), dtype=float32)\n",
      "label_indexs.shape (32,)\n",
      "sample label_indexes [2 3 1 0 2]\n",
      "centroids.shape: (4, 16)\n",
      "c.shape: (32, 16)\n",
      "[10.2403418   0.          3.7864624  11.4958667   0.          1.84005249\n",
      "  2.75890717  0.         13.41371094  0.          6.58589233  0.\n",
      "  0.02075756  0.01361208  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('label for the feature_0:\\n', label_batch[0])\n",
    "label_indexs = np.argmax(label_batch, axis=1)\n",
    "print('label_indexs.shape', label_indexs.shape)\n",
    "print('sample label_indexes',label_indexs[:5])\n",
    "print('centroids.shape:', centroids.shape)\n",
    "c = centroids[label_indexs]\n",
    "print('c.shape:', c.shape)\n",
    "print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd687300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n",
      "a[0]:\n",
      " [0 1 2]\n",
      "\n",
      "b.shape:\n",
      " (16,)\n",
      "b:\n",
      " [0 1 2 3 0 1 2 3 0 1 2 3 0 1 2 3]\n",
      "\n",
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "### To understand this lets take simple example\n",
    "a = np.arange(12).reshape((4, 3))\n",
    "print('a:\\n',a)\n",
    "# print(a.shape)\n",
    "print('a[0]:\\n',a[0])\n",
    "print()\n",
    "# we create a index whose dimension is higher than a \n",
    "b = np.tile([0, 1, 2, 3], (4))\n",
    "print('b.shape:\\n',b.shape)\n",
    "# b = 16 but a is having 4 rows\n",
    "print('b:\\n',b)\n",
    "#Notice that each element of b is wihin 0-3 , matching with the max row of a.\n",
    "# the slicing can be done now as:\n",
    "print()\n",
    "print(a[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "493dfa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 16)\n",
      "euc_dis (32,)\n",
      "distance: [-0.05506039  0.          0.08319187  0.932951    0.         -0.22872448\n",
      " -0.25504112  0.          0.7920666   0.          0.11199999  0.\n",
      " -0.02075756 -0.01361208  0.          0.        ]\n",
      " eucladian distance:1.2799376249313354\n",
      "\n",
      "distance: [-0.07839584  0.         -0.43634996  1.3717766   0.         -0.13542652\n",
      " -0.1899966   0.         -0.2310648   0.         -0.8690177   0.\n",
      " -0.03390059 -0.1144355   0.          0.        ]\n",
      " eucladian distance:1.7191815376281738\n",
      "\n",
      "distance: [-3.9668312   0.         -0.30758154 -0.28688192  0.         -1.0577219\n",
      " -0.8485044   0.         -1.6614985   0.         -0.6632192   0.\n",
      " -0.45969117 -1.9281311   0.          0.        ]\n",
      " eucladian distance:4.988069534301758\n",
      "\n",
      "distance: [-0.92845726  0.          0.15833092  2.9910045   0.          0.09033704\n",
      " -0.21953902  0.          0.22963023  0.         -0.2681663   0.\n",
      " -0.36125326 -0.16652346  0.          0.        ]\n",
      " eucladian distance:3.1894264221191406\n",
      "\n",
      "distance: [-1.248992    0.         -0.39884663 -1.8514328   0.         -0.6369655\n",
      " -0.09219217  0.         -1.0805264   0.         -0.07473135  0.\n",
      " -0.02075756 -0.01361208  0.          0.        ]\n",
      " eucladian distance:2.595154285430908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remeber c = centroids[label_indexs]\n",
    "# only the centroid of the class corresponding to the feature\n",
    "# earlier we had to expand dimension becuase centroid contained all the \n",
    "# four classes\n",
    "dis = features - c \n",
    "print(dis.shape)\n",
    "euc_dis = tf.norm(features - c, ord='euclidean', axis=1,)\n",
    "print('euc_dis', euc_dis.shape)\n",
    "for d, ed in zip(dis[:5], euc_dis[:5]):\n",
    "    print(f'distance: {d.numpy()}\\n eucladian distance:{ed.numpy()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb1895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundaryLoss(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_labels=train_data.element_spec[1].shape[1], \n",
    "                feat_dim = 16):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.feat_dim = feat_dim\n",
    "        # initializing the delta boundary \n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.delta = tf.Variable(\n",
    "            initial_value=w_init((self.num_labels), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        \n",
    "    def call(self, features, centroids, labels):\n",
    "        logits =  euclidean_metric(features, centroids)  \n",
    "        ######### Why softmax before softplus#########\n",
    "        smax = tf.nn.softmax(logits, )\n",
    "        # this is equivallent to predicting the feature belong to which class\n",
    "        preds = tf.math.argmax(smax, axis=1)\n",
    "        # This is equivallent to obtaining the max probabiliy of a feature belonging to a calss\n",
    "        probs = tf.reduce_max(smax, 1)        \n",
    "        ############################\n",
    "        # delta =  log(1 + e ^ delta_k) , delta_k =self.delta = parameters for the boundary\n",
    "        delta = tf.nn.softplus(self.delta)  \n",
    "        label_indexs = np.argmax(label_batch, axis=1)\n",
    "        # centroids are having only 4 rows , whereas labels are rows equivallent to batch\n",
    "        # pick-up the centroid for each class \n",
    "        # label_index from the data set will have all the classes, 32 for a batch\n",
    "        # for each class cetroid[class_index] will give the centroid of the calss\n",
    "        # it is basically : [centroids[class_idx] for class_idx in label_indexes]\n",
    "        c = centroids[label_indexs]\n",
    "        # similarly get the delta for each class, \n",
    "        # although delta is now randomly intialized \n",
    "        # delta parameters will be learned through the training\n",
    "        d = delta[label_indexs]\n",
    "        x = features\n",
    "        # x-c = vector of (32, 16) dimension , euc_dis  = scalar value\n",
    "        euc_dis = tf.norm(x - c, ord='euclidean', axis=1)        \n",
    "        ##If axis is None (the default), the input is considered a vector and a \n",
    "        ## single vector norm is computed over the entire set of values in the tensor, \n",
    "        ## i.e. norm(tensor, ord=ord) is equivalent to norm(reshape(tensor, [-1]), ord=ord). \n",
    "        ##If axis is a Python integer, the input is considered a batch of vectors, and axis determines the axis in tensor over which to compute vector norms.\n",
    "        pos_mask = euc_dis > d\n",
    "        neg_mask = euc_dis < d\n",
    "        \n",
    "        pos_loss = (euc_dis - d) * pos_mask\n",
    "        neg_loss = (d - euc_dis) * neg_mask\n",
    "        loss = pos_loss.mean() + neg_loss.mean()\n",
    "        \n",
    "        return loss, delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f14b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f492f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand this , a= features(batch_size, 2048) , b = centroids (4, 2048)\n",
    "def euclidean_metric_torch(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    a = a.unsqueeze(1).expand(n, m, -1)\n",
    "    b = b.unsqueeze(0).expand(n, m, -1)\n",
    "    logits = -((a - b)**2).sum(dim=2)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbb123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "a = np.arange(6)\n",
    "a = a.reshape((2, -1))\n",
    "print('a:', a)\n",
    "print('a.shape', a.shape)\n",
    "b = np.arange(8, 16)\n",
    "print('b',b)\n",
    "b = np.reshape(b, (4, -1))\n",
    "print('b',b)\n",
    "print('b.shape:',b.shape)\n",
    "tfa = tf.constant(a)\n",
    "tfb = tf.constant(b)\n",
    "print('tfa',tfa)\n",
    "print('tfb',tfb)\n",
    "# n = tfa.shape[0]\n",
    "# m = b.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7323f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tf.expand_dims(tfa, 0) :',tf.expand_dims(tfa, 0))\n",
    "print()\n",
    "print('tf.expand_dims(tfa, 1) :',tf.expand_dims(tfa, 1))\n",
    "print()\n",
    "print('tf.expand_dims(tfa, 1) :',tf.expand_dims(tfa, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b761be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfa = tf.expand_dims(tfa, 1)\n",
    "print(f'tf.shape(tfa): {tf.shape(tfa)}')\n",
    "tfb = tf.expand_dims(tfb, 0)\n",
    "print(f'tf.shape(tfb): {tf.shape(tfb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00406b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = a.shape[0]\n",
    "m = b.shape[0]\n",
    "tfa_broadcast = tf.broadcast_to(tfa, [2, 4, 3])\n",
    "tf.shape(tfa_broadcast)\n",
    "print('tfa_broadcast',tfa_broadcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "\n",
    "# The equivalent function for pytorch expand is tensorflow tf.broadcast_to\n",
    "\n",
    "# Docs: https://www.tensorflow.org/api_docs/python/tf/broadcast_to\n",
    "\n",
    "# Share\n",
    "# Follow\n",
    "# edited Oct 23, 2021 at 18:22\n",
    "\n",
    "# M.Innat\n",
    "# 12.2k66 gold badges3434 silver badges6767 bronze badges\n",
    "# answered Jan 4, 2019 at 9:12\n",
    "\n",
    "# funkyyyyyy\n",
    "# 6111 silver badge22 bronze badges\n",
    "# Add a comment\n",
    "\n",
    "# 0\n",
    "\n",
    "# Tensorflow automatically broadcasts, so in general you don't need to do any of this. Suppose you have a y' of shape 6x2x3 and your x is of shape 2x3, then you can already do y'*x or y'+x will already behave as if you had expanded it. But if for some other reason you really need to do it, then the command in tensorflow is tile:\n",
    "\n",
    "# y = tf.tile(tf.reshape(x, (1,2,3)), multiples=(6,1,1))\n",
    "# Docs: https://www.tensorflow.org/api_docs/python/tf/tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fba7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_metric(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    a = tf.expand_dims(a, 1)\n",
    "    b = tf.expand_dims(b, 0)\n",
    "    logits = -((a - b)**2).sum(dim=2)\n",
    "    return logits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70dbcca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e357c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e43d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c4ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e2516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec4e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenSet:\n",
    "    def __init__(self, data, pretrained_model):\n",
    "        \n",
    "        self.model = pretrained_model\n",
    "        self.best_eval_score = 0\n",
    "        self.delta = None\n",
    "        self.delta_points = []\n",
    "        self.centroids = None\n",
    "        self.test_results = None\n",
    "        self.predictions = None\n",
    "        self.true_labels = None\n",
    "        \n",
    "    def centroids_cal(self):\n",
    "        centriods = np.zeros(train_data.element_spec[1].shape[1], embedding_size)\n",
    "        total_labels = np.empty(0, dtype=longdouble)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86fb45",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing the training step to get centroid for each class\n",
    "class OpenSet:\n",
    "    def __init__(self, data, pretrained_model=log_classifier):\n",
    "#         super().__init__():\n",
    "        self.model = pretrained_model        \n",
    "        self.centroids = None\n",
    "        self.num_labels = train_data.element_spec[1].shape[1]\n",
    "        \n",
    "    def centroids_cal(self):\n",
    "        centriods = np.zeros(self.num_labels, embedding_size)\n",
    "        total_labels = np.empty(0, dtype=longdouble)\n",
    "        for batch in data:\n",
    "            logseq_batch, label_batch = batch\n",
    "            features = self.model(logseq_batch, extract_feature=True ) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f1c98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0094a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c777869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e031826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In context of deep learning the logits layer means the layer that feeds in to softmax (or other such normalization). The output of the softmax are the probabilities for the classification task and its input is logits layer. The logits layer typically produces values from -infinity to +infinity and the softmax layer transforms it to values from 0 to 1.\n",
    "\n",
    "# Historical Context\n",
    "\n",
    "# Where does this term comes from? In 1930s and 40s, several people were trying to adapt linear regression to the problem of predicting probabilities. However linear regression produces output from -infinity to +infinity while for probabilities our desired output is 0 to 1. One way to do this is by somehow mapping the probabilities 0 to 1 to -infinity to +infinity and then use linear regression as usual. One such mapping is cumulative normal distribution that was used by Chester Ittner Bliss in 1934 and he called this \"probit\" model, short for \"probability unit\". However this function is computationally expensive while lacking some of the desirable properties for multi-class classification. In 1944 Joseph Berkson used the function log(p/(1-p)) to do this mapping and called it logit, short for \"logistic unit\". The term logistic regression derived from this as well.\n",
    "\n",
    "# The Confusion\n",
    "\n",
    "# Unfortunately the term logits is abused in deep learning. From pure mathematical perspective logit is a function that performs above mapping. In deep learning people started calling the layer \"logits layer\" that feeds in to logit function. Then people started calling the output values of this layer \"logit\" creating the confusion with logit the function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
